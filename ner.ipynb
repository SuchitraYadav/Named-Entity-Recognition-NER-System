{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\syadav18\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\syadav18\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\syadav18\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\syadav18\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# Download necessary NLTK data packages\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename = 'nltk_log', level=logging.DEBUG, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load JSON data\n",
    "    with open('Corona2.json', 'r', encoding='utf-8') as f:\n",
    "        df = json.load(f)\n",
    "    logging.info(\"JSON data loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading JSON data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "try:\n",
    "    for example in df['examples']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['content'] = example['content']\n",
    "        temp_dict['entities'] = []\n",
    "        \n",
    "        for annotation in example['annotations']:\n",
    "            start = annotation['start']\n",
    "            end = annotation['end']\n",
    "            label = annotation['tag_name'].upper()\n",
    "            temp_dict['entities'].append((start, end, label))\n",
    "        \n",
    "        training_data.append(temp_dict)\n",
    "\n",
    "    logging.info(f\"Training data created with {len(training_data)} examples.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error processing examples: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(f\"Training data sample: {training_data[:1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\syadav18\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.download('punkt')\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error downloading 'punkt' tokenizer: {e}\")\n",
    "\n",
    "for item in training_data:\n",
    "    try:\n",
    "        item['tokens'] = word_tokenize(item['content'])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error tokenizing content: {item['content'][:30]}... - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\syadav18\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "if training_data:\n",
    "    logging.debug(f\"Tokens for the first item: {training_data[0]['tokens']}\")\n",
    "\n",
    "try:\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error downloading 'averaged_perceptron_tagger': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in training_data:\n",
    "    try:\n",
    "        item['pos_tags'] = nltk.pos_tag(item['tokens'])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error tagging POS for tokens: {item['tokens'][:10]}... - {e}\")\n",
    "\n",
    "if training_data:\n",
    "    logging.debug(f\"POS tags for the first item: {training_data[0]['pos_tags']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "try:\n",
    "    for item in training_data:\n",
    "        item['chunks'] = ne_chunk(item['pos_tags'])\n",
    "    logging.info(\"Named entity chunks created successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during named entity chunking: {e}\")\n",
    "    raise\n",
    "\n",
    "# Show chunks for the first item\n",
    "if training_data:\n",
    "    logging.debug(f\"Chunks for the first item: {training_data[0]['chunks']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_ner(training_data):\n",
    "    formatted_data = []\n",
    "    for item in training_data:\n",
    "        content = item['content']\n",
    "        tokens = item['tokens']\n",
    "        pos_tags = item['pos_tags']\n",
    "        entities = item['entities']\n",
    "\n",
    "        ner_tags = ['O'] * len(tokens)\n",
    "        try:\n",
    "            for start, end, label in entities:\n",
    "                for i in range(len(tokens)):\n",
    "                    token_start = content.find(tokens[i])\n",
    "                    token_end = token_start + len(tokens[i])\n",
    "                    if token_start == start:\n",
    "                        ner_tags[i] = 'B-' + label\n",
    "                    elif start < token_start < end:\n",
    "                        ner_tags[i] = 'I-' + label\n",
    "\n",
    "            formatted_data.append(list(zip(tokens, pos_tags, ner_tags)))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing item {content[:30]}...: {e}\")\n",
    "    \n",
    "    logging.info(\"Formatted data for NER created successfully.\")\n",
    "    return formatted_data\n",
    "\n",
    "try:\n",
    "    formatted_data = prepare_data_for_ner(training_data)\n",
    "    logging.info(\"NER data prepared.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error preparing NER data: {e}\")\n",
    "    raise\n",
    "\n",
    "if formatted_data:\n",
    "    logging.debug(f\"Formatted data for the first item: {formatted_data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_overlapping_entities(entities):\n",
    "    sorted_entities = sorted(entities, key=lambda x: x[0])\n",
    "    filtered_entities = []\n",
    "\n",
    "    for current in sorted_entities:\n",
    "        if not filtered_entities:\n",
    "            filtered_entities.append(current)\n",
    "        else:\n",
    "            last = filtered_entities[-1]\n",
    "            if current[0] < last[1]:  \n",
    "                if current[1] <= last[1]:  \n",
    "                    continue\n",
    "                else:  #\n",
    "                    new_entity = (last[0], current[1], last[2])\n",
    "                    filtered_entities[-1] = new_entity\n",
    "            else:\n",
    "                filtered_entities.append(current)\n",
    "    \n",
    "    return filtered_entities\n",
    "\n",
    "try:\n",
    "    for item in training_data:\n",
    "        item['entities'] = filter_overlapping_entities(item['entities'])\n",
    "    logging.info(\"Overlapping entities filtered successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error filtering overlapping entities: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "try:\n",
    "    for item in training_data:\n",
    "        entities = [(start, end, label) for start, end, label in item['entities']]\n",
    "        train_data.append((item['content'], {\"entities\": entities}))\n",
    "    logging.info(\"Training data prepared successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error preparing training data: {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "if train_data:\n",
    "    logging.debug(f\"Sample training data: {train_data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nlp = spacy.blank('en')\n",
    "    logging.info(\"SpaCy model initialized successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error initializing SpaCy model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.add_pipe('ner')\n",
    "        logging.info(\"NER pipe added to the model.\")\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "        logging.info(\"Using existing NER pipe.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error adding/getting NER pipe: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for item in training_data:\n",
    "        for start, end, label in item['entities']:\n",
    "            ner.add_label(label)\n",
    "    logging.info(\"Labels added to NER pipe.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error adding labels to NER pipe: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-07-26 20:35:10,492] [DEBUG] No 'get_examples' callback provided to 'Language.initialize', creating dummy examples\n",
      "[2024-07-26 20:35:10,495] [INFO] Created vocabulary\n",
      "[2024-07-26 20:35:10,496] [INFO] Finished initializing nlp object\n",
      "[2024-07-26 20:35:10,498] [DEBUG] [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed and load the table in your config. The languages with lexeme normalization tables are currently: cs, da, de, el, en, grc, id, lb, mk, pt, ru, sr, ta, th\n",
      "\n",
      "Load the table in your config with:\n",
      "\n",
      "[initialize.lookups]\n",
      "@misc = \"spacy.LookupsDataLoader.v1\"\n",
      "lang = ${nlp.lang}\n",
      "tables = [\"lexeme_norm\"]\n",
      "\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Carbamazepine is an approved treatment for bipolar...\" with entities \"[(0, 14, 'MEDICINE'), (43, 59, 'MEDICALCONDITION')...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"In 2003, following the outbreak of severe acute re...\" with entities \"[(35, 68, 'MEDICALCONDITION'), (70, 74, 'MEDICALCO...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"One of the bacterial diseases with the highest dis...\" with entities \"[(65, 77, 'MEDICALCONDITION'), (89, 115, 'PATHOGEN...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"While bismuth compounds (Pepto-Bismol) decreased t...\" with entities \"[(6, 23, 'MEDICINE'), (25, 37, 'MEDICINE'), (104, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Gabapentin, approved for treatment of seizures and...\" with entities \"[(0, 10, 'MEDICINE'), (38, 46, 'MEDICALCONDITION')...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Losses: {'ner': 105.85713315010071}\n",
      "Iteration 0, Losses: {'ner': 149.59978940337896}\n",
      "Iteration 0, Losses: {'ner': 225.6424277499318}\n",
      "Iteration 0, Losses: {'ner': 314.3035279735923}\n",
      "Iteration 0, Losses: {'ner': 437.78517973423004}\n",
      "Iteration 0, Losses: {'ner': 472.65077036619186}\n",
      "Iteration 0, Losses: {'ner': 504.29091411828995}\n",
      "Iteration 0, Losses: {'ner': 557.147925645113}\n",
      "Iteration 0, Losses: {'ner': 636.8428419828415}\n",
      "Iteration 0, Losses: {'ner': 683.5559456646442}\n",
      "Iteration 0, Losses: {'ner': 712.8466645628214}\n",
      "Iteration 0, Losses: {'ner': 723.2823398262262}\n",
      "Iteration 0, Losses: {'ner': 760.0178983733058}\n",
      "Iteration 0, Losses: {'ner': 788.2395605635829}\n",
      "Iteration 0, Losses: {'ner': 801.0309896113831}\n",
      "Iteration 0, Losses: {'ner': 808.6461646389544}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"A number of factors make people more susceptible t...\" with entities \"[(279, 283, 'PATHOGEN')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The two classes of antiviral drugs used against in...\" with entities \"[(48, 58, 'MEDICALCONDITION'), (88, 99, 'MEDICINE'...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"If a tuberculosis infection does become active, it...\" with entities \"[(138, 148, 'MEDICALCONDITION'), (155, 170, 'MEDIC...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Bupropion (Wellbutrin), an anti-depressant, is als...\" with entities \"[(0, 9, 'MEDICINE'), (11, 21, 'MEDICINE'), (170, 1...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Latent TB is treated with either isoniazid or rifa...\" with entities \"[(33, 43, 'MEDICINE'), (46, 54, 'MEDICINE'), (82, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The following drugs are considered as DMARDs: meth...\" with entities \"[(38, 44, 'MEDICINE'), (46, 58, 'MEDICINE'), (60, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Losses: {'ner': 858.8345167761327}\n",
      "Iteration 0, Losses: {'ner': 882.3201907986117}\n",
      "Iteration 0, Losses: {'ner': 895.6233971312412}\n",
      "Iteration 0, Losses: {'ner': 911.3729111920641}\n",
      "Iteration 0, Losses: {'ner': 913.3841495782253}\n",
      "Iteration 0, Losses: {'ner': 945.0779138991566}\n",
      "Iteration 0, Losses: {'ner': 955.0355760435392}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Although the vast majority of bacteria are harmles...\" with entities \"[(30, 39, 'PATHOGEN'), (87, 106, 'PATHOGEN'), (436...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Buprenorphine has been shown experimentally (1982–...\" with entities \"[(0, 14, 'MEDICINE'), (88, 109, 'MEDICALCONDITION'...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Some antidepressants are used as a treatment for s...\" with entities \"[(48, 72, 'MEDICALCONDITION'), (369, 379, 'MEDICIN...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"All medical applications known so far involve not ...\" with entities \"[(55, 65, 'MEDICINE'), (139, 149, 'MEDICINE'), (23...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Losses: {'ner': 964.8926952167079}\n",
      "Iteration 0, Losses: {'ner': 969.3252444223045}\n",
      "Iteration 0, Losses: {'ner': 1019.6376389561802}\n",
      "Iteration 0, Losses: {'ner': 1027.937494726221}\n",
      "Iteration 0, Losses: {'ner': 1036.0098443260529}\n",
      "Iteration 0, Losses: {'ner': 1050.9123360950455}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"In 15–20% of active cases, the infection spreads o...\" with entities \"[(134, 161, 'MEDICALCONDITION'), (337, 361, 'MEDIC...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Bacterial vaginosis is caused by bacteria that cha...\" with entities \"[(0, 19, 'PATHOGEN'), (33, 42, 'PATHOGEN'), (132, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Although viruses cause disruption of healthy homeo...\" with entities \"[(181, 201, 'PATHOGEN'), (365, 383, 'PATHOGEN'), (...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Influenza, commonly known as \"the flu\", is an infe...\" with entities \"[(0, 9, 'MEDICALCONDITION'), (78, 93, 'PATHOGEN'),...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Losses: {'ner': 1068.6856639114417}\n",
      "Iteration 0, Losses: {'ner': 1068.881487397574}\n",
      "Iteration 1, Losses: {'ner': 12.449503665966404}\n",
      "Iteration 1, Losses: {'ner': 18.373450451091458}\n",
      "Iteration 1, Losses: {'ner': 50.172202935119685}\n",
      "Iteration 1, Losses: {'ner': 100.1531293996643}\n",
      "Iteration 1, Losses: {'ner': 122.77389598775085}\n",
      "Iteration 1, Losses: {'ner': 149.64858075138267}\n",
      "Iteration 1, Losses: {'ner': 160.32454086456067}\n",
      "Iteration 1, Losses: {'ner': 173.83027291746197}\n",
      "Iteration 1, Losses: {'ner': 189.30337563382722}\n",
      "Iteration 1, Losses: {'ner': 206.6341965102559}\n",
      "Iteration 1, Losses: {'ner': 216.0308275811053}\n",
      "Iteration 1, Losses: {'ner': 217.56103477712227}\n",
      "Iteration 1, Losses: {'ner': 234.19080304253353}\n",
      "Iteration 1, Losses: {'ner': 235.5920475842219}\n",
      "Iteration 1, Losses: {'ner': 244.4853890692165}\n",
      "Iteration 1, Losses: {'ner': 253.6495894624376}\n",
      "Iteration 1, Losses: {'ner': 261.57490028082145}\n",
      "Iteration 1, Losses: {'ner': 269.62821584779056}\n",
      "Iteration 1, Losses: {'ner': 277.01000280507367}\n",
      "Iteration 1, Losses: {'ner': 286.3831658521205}\n",
      "Iteration 1, Losses: {'ner': 290.4567261346835}\n",
      "Iteration 1, Losses: {'ner': 296.3375086191993}\n",
      "Iteration 1, Losses: {'ner': 305.8781733497369}\n",
      "Iteration 1, Losses: {'ner': 307.81454206782314}\n",
      "Iteration 1, Losses: {'ner': 331.4766921843369}\n",
      "Iteration 1, Losses: {'ner': 339.25744446216936}\n",
      "Iteration 1, Losses: {'ner': 354.6086478965499}\n",
      "Iteration 1, Losses: {'ner': 362.2629544572012}\n",
      "Iteration 1, Losses: {'ner': 410.2908786406225}\n",
      "Iteration 1, Losses: {'ner': 423.68790493686186}\n",
      "Iteration 1, Losses: {'ner': 429.2931350059599}\n",
      "Iteration 2, Losses: {'ner': 11.659083899234247}\n",
      "Iteration 2, Losses: {'ner': 20.772658764708467}\n",
      "Iteration 2, Losses: {'ner': 22.67960314696029}\n",
      "Iteration 2, Losses: {'ner': 52.97289500360159}\n",
      "Iteration 2, Losses: {'ner': 95.92041928079072}\n",
      "Iteration 2, Losses: {'ner': 113.64153331746454}\n",
      "Iteration 2, Losses: {'ner': 124.53707541969473}\n",
      "Iteration 2, Losses: {'ner': 141.0382899075221}\n",
      "Iteration 2, Losses: {'ner': 146.57715539837866}\n",
      "Iteration 2, Losses: {'ner': 155.6008053616658}\n",
      "Iteration 2, Losses: {'ner': 204.8677488563387}\n",
      "Iteration 2, Losses: {'ner': 214.23543043310357}\n",
      "Iteration 2, Losses: {'ner': 223.68295818850794}\n",
      "Iteration 2, Losses: {'ner': 251.6858759158825}\n",
      "Iteration 2, Losses: {'ner': 256.8325240471589}\n",
      "Iteration 2, Losses: {'ner': 261.2617161201691}\n",
      "Iteration 2, Losses: {'ner': 262.0551728340182}\n",
      "Iteration 2, Losses: {'ner': 271.07407964158006}\n",
      "Iteration 2, Losses: {'ner': 284.3496291144186}\n",
      "Iteration 2, Losses: {'ner': 291.1698849088532}\n",
      "Iteration 2, Losses: {'ner': 304.27305734327706}\n",
      "Iteration 2, Losses: {'ner': 312.09041722261003}\n",
      "Iteration 2, Losses: {'ner': 321.7789811156652}\n",
      "Iteration 2, Losses: {'ner': 328.05616291234264}\n",
      "Iteration 2, Losses: {'ner': 328.7112009376078}\n",
      "Iteration 2, Losses: {'ner': 343.4056728244991}\n",
      "Iteration 2, Losses: {'ner': 362.2230187549444}\n",
      "Iteration 2, Losses: {'ner': 376.4202394382054}\n",
      "Iteration 2, Losses: {'ner': 390.0077967226521}\n",
      "Iteration 2, Losses: {'ner': 398.21291521060925}\n",
      "Iteration 2, Losses: {'ner': 405.82392954921346}\n",
      "Iteration 3, Losses: {'ner': 7.454363170341878}\n",
      "Iteration 3, Losses: {'ner': 33.65346261477515}\n",
      "Iteration 3, Losses: {'ner': 52.714587588515485}\n",
      "Iteration 3, Losses: {'ner': 61.326171322729664}\n",
      "Iteration 3, Losses: {'ner': 74.4089936401273}\n",
      "Iteration 3, Losses: {'ner': 82.68279405393505}\n",
      "Iteration 3, Losses: {'ner': 96.66425169784827}\n",
      "Iteration 3, Losses: {'ner': 102.61750844915802}\n",
      "Iteration 3, Losses: {'ner': 110.71992202899565}\n",
      "Iteration 3, Losses: {'ner': 154.83807188169595}\n",
      "Iteration 3, Losses: {'ner': 155.0647989150312}\n",
      "Iteration 3, Losses: {'ner': 155.40220551554478}\n",
      "Iteration 3, Losses: {'ner': 164.7063808050288}\n",
      "Iteration 3, Losses: {'ner': 166.64033562989724}\n",
      "Iteration 3, Losses: {'ner': 173.31027459323803}\n",
      "Iteration 3, Losses: {'ner': 182.53127478002148}\n",
      "Iteration 3, Losses: {'ner': 188.9215337822765}\n",
      "Iteration 3, Losses: {'ner': 196.55484396709514}\n",
      "Iteration 3, Losses: {'ner': 204.8730127404882}\n",
      "Iteration 3, Losses: {'ner': 221.83434504425531}\n",
      "Iteration 3, Losses: {'ner': 247.3668193184828}\n",
      "Iteration 3, Losses: {'ner': 299.1273705333376}\n",
      "Iteration 3, Losses: {'ner': 313.06602937193844}\n",
      "Iteration 3, Losses: {'ner': 318.4430968505709}\n",
      "Iteration 3, Losses: {'ner': 323.8528193412629}\n",
      "Iteration 3, Losses: {'ner': 329.89833496802413}\n",
      "Iteration 3, Losses: {'ner': 345.1887085640349}\n",
      "Iteration 3, Losses: {'ner': 355.2294004892313}\n",
      "Iteration 3, Losses: {'ner': 364.2414885527135}\n",
      "Iteration 3, Losses: {'ner': 378.0870792769181}\n",
      "Iteration 3, Losses: {'ner': 387.36366627229927}\n",
      "Iteration 4, Losses: {'ner': 6.794191621599566}\n",
      "Iteration 4, Losses: {'ner': 13.816515654192937}\n",
      "Iteration 4, Losses: {'ner': 18.905615658366308}\n",
      "Iteration 4, Losses: {'ner': 24.3784474911674}\n",
      "Iteration 4, Losses: {'ner': 28.944068650503795}\n",
      "Iteration 4, Losses: {'ner': 34.82681975901958}\n",
      "Iteration 4, Losses: {'ner': 43.90156955090036}\n",
      "Iteration 4, Losses: {'ner': 44.493408818685666}\n",
      "Iteration 4, Losses: {'ner': 71.94851135385225}\n",
      "Iteration 4, Losses: {'ner': 79.09622651941487}\n",
      "Iteration 4, Losses: {'ner': 84.58335591765399}\n",
      "Iteration 4, Losses: {'ner': 98.56915364668313}\n",
      "Iteration 4, Losses: {'ner': 107.39575005864015}\n",
      "Iteration 4, Losses: {'ner': 120.788008035405}\n",
      "Iteration 4, Losses: {'ner': 146.42381373869281}\n",
      "Iteration 4, Losses: {'ner': 188.35572885003103}\n",
      "Iteration 4, Losses: {'ner': 190.25909125210515}\n",
      "Iteration 4, Losses: {'ner': 205.31748266377025}\n",
      "Iteration 4, Losses: {'ner': 215.36005696535952}\n",
      "Iteration 4, Losses: {'ner': 223.41972579183164}\n",
      "Iteration 4, Losses: {'ner': 224.22680641176495}\n",
      "Iteration 4, Losses: {'ner': 270.156223744041}\n",
      "Iteration 4, Losses: {'ner': 307.9086293796798}\n",
      "Iteration 4, Losses: {'ner': 311.7484838847819}\n",
      "Iteration 4, Losses: {'ner': 319.4474309468561}\n",
      "Iteration 4, Losses: {'ner': 333.140086494811}\n",
      "Iteration 4, Losses: {'ner': 341.59456779462215}\n",
      "Iteration 4, Losses: {'ner': 355.1686788613613}\n",
      "Iteration 4, Losses: {'ner': 367.03666866114014}\n",
      "Iteration 4, Losses: {'ner': 380.62528859026594}\n",
      "Iteration 4, Losses: {'ner': 388.0288077175877}\n",
      "Iteration 5, Losses: {'ner': 8.578909313858219}\n",
      "Iteration 5, Losses: {'ner': 23.399646200639065}\n",
      "Iteration 5, Losses: {'ner': 31.859002282764376}\n",
      "Iteration 5, Losses: {'ner': 39.88937866795092}\n",
      "Iteration 5, Losses: {'ner': 47.79369885851842}\n",
      "Iteration 5, Losses: {'ner': 55.11025294542849}\n",
      "Iteration 5, Losses: {'ner': 61.530201307696544}\n",
      "Iteration 5, Losses: {'ner': 70.45193102522758}\n",
      "Iteration 5, Losses: {'ner': 72.184581611546}\n",
      "Iteration 5, Losses: {'ner': 88.31136506981586}\n",
      "Iteration 5, Losses: {'ner': 98.77109553825863}\n",
      "Iteration 5, Losses: {'ner': 103.90994757620584}\n",
      "Iteration 5, Losses: {'ner': 104.41070097182377}\n",
      "Iteration 5, Losses: {'ner': 105.58997700995735}\n",
      "Iteration 5, Losses: {'ner': 117.31052351107425}\n",
      "Iteration 5, Losses: {'ner': 123.08054306031823}\n",
      "Iteration 5, Losses: {'ner': 136.3251665807396}\n",
      "Iteration 5, Losses: {'ner': 142.71011243344032}\n",
      "Iteration 5, Losses: {'ner': 146.41571112996942}\n",
      "Iteration 5, Losses: {'ner': 155.3050518568719}\n",
      "Iteration 5, Losses: {'ner': 196.27468703482825}\n",
      "Iteration 5, Losses: {'ner': 220.0068710838103}\n",
      "Iteration 5, Losses: {'ner': 233.21707646747927}\n",
      "Iteration 5, Losses: {'ner': 247.3201143261009}\n",
      "Iteration 5, Losses: {'ner': 252.34098422201384}\n",
      "Iteration 5, Losses: {'ner': 259.6064576600704}\n",
      "Iteration 5, Losses: {'ner': 285.04600519540804}\n",
      "Iteration 5, Losses: {'ner': 292.2503608667006}\n",
      "Iteration 5, Losses: {'ner': 298.98612733424727}\n",
      "Iteration 5, Losses: {'ner': 303.8893130948923}\n",
      "Iteration 5, Losses: {'ner': 334.9121301545043}\n",
      "Iteration 6, Losses: {'ner': 36.05651443584793}\n",
      "Iteration 6, Losses: {'ner': 42.32358657903174}\n",
      "Iteration 6, Losses: {'ner': 47.98168924977796}\n",
      "Iteration 6, Losses: {'ner': 55.15250679702665}\n",
      "Iteration 6, Losses: {'ner': 55.291881638179255}\n",
      "Iteration 6, Losses: {'ner': 63.85713117913169}\n",
      "Iteration 6, Losses: {'ner': 71.78648292572214}\n",
      "Iteration 6, Losses: {'ner': 80.3188381466257}\n",
      "Iteration 6, Losses: {'ner': 87.81749937171853}\n",
      "Iteration 6, Losses: {'ner': 89.38014850369944}\n",
      "Iteration 6, Losses: {'ner': 96.82632656432187}\n",
      "Iteration 6, Losses: {'ner': 110.05613345151133}\n",
      "Iteration 6, Losses: {'ner': 114.06662295978263}\n",
      "Iteration 6, Losses: {'ner': 117.35797785699948}\n",
      "Iteration 6, Losses: {'ner': 134.7134603684978}\n",
      "Iteration 6, Losses: {'ner': 139.34722173942743}\n",
      "Iteration 6, Losses: {'ner': 154.32481108553867}\n",
      "Iteration 6, Losses: {'ner': 197.7232853042554}\n",
      "Iteration 6, Losses: {'ner': 205.03568941870714}\n",
      "Iteration 6, Losses: {'ner': 212.86693939452118}\n",
      "Iteration 6, Losses: {'ner': 228.91442177106674}\n",
      "Iteration 6, Losses: {'ner': 250.36768271434883}\n",
      "Iteration 6, Losses: {'ner': 250.51842887984958}\n",
      "Iteration 6, Losses: {'ner': 259.4834947230025}\n",
      "Iteration 6, Losses: {'ner': 268.6957749280051}\n",
      "Iteration 6, Losses: {'ner': 273.7461836411595}\n",
      "Iteration 6, Losses: {'ner': 293.6140010500918}\n",
      "Iteration 6, Losses: {'ner': 302.5406264612344}\n",
      "Iteration 6, Losses: {'ner': 309.8654555947729}\n",
      "Iteration 6, Losses: {'ner': 324.6496412323771}\n",
      "Iteration 6, Losses: {'ner': 336.8736766593603}\n",
      "Iteration 7, Losses: {'ner': 6.530164494216929}\n",
      "Iteration 7, Losses: {'ner': 7.867666461252408}\n",
      "Iteration 7, Losses: {'ner': 26.80218079875697}\n",
      "Iteration 7, Losses: {'ner': 34.43160133534185}\n",
      "Iteration 7, Losses: {'ner': 66.71738730247861}\n",
      "Iteration 7, Losses: {'ner': 88.47005962612386}\n",
      "Iteration 7, Losses: {'ner': 93.34147646652107}\n",
      "Iteration 7, Losses: {'ner': 96.9018040043355}\n",
      "Iteration 7, Losses: {'ner': 103.34691367547639}\n",
      "Iteration 7, Losses: {'ner': 112.50521600454367}\n",
      "Iteration 7, Losses: {'ner': 127.30538301896016}\n",
      "Iteration 7, Losses: {'ner': 140.37520330541244}\n",
      "Iteration 7, Losses: {'ner': 148.3702766176951}\n",
      "Iteration 7, Losses: {'ner': 148.695736756327}\n",
      "Iteration 7, Losses: {'ner': 154.88511346013172}\n",
      "Iteration 7, Losses: {'ner': 169.2883996516926}\n",
      "Iteration 7, Losses: {'ner': 174.7411302970775}\n",
      "Iteration 7, Losses: {'ner': 179.22769159842468}\n",
      "Iteration 7, Losses: {'ner': 227.47129853775857}\n",
      "Iteration 7, Losses: {'ner': 236.970964131608}\n",
      "Iteration 7, Losses: {'ner': 254.8876474217539}\n",
      "Iteration 7, Losses: {'ner': 266.44320891576683}\n",
      "Iteration 7, Losses: {'ner': 278.28269008324634}\n",
      "Iteration 7, Losses: {'ner': 278.4141097003996}\n",
      "Iteration 7, Losses: {'ner': 286.2028432666293}\n",
      "Iteration 7, Losses: {'ner': 290.4267119210023}\n",
      "Iteration 7, Losses: {'ner': 295.02061972452515}\n",
      "Iteration 7, Losses: {'ner': 299.23602772380633}\n",
      "Iteration 7, Losses: {'ner': 306.0364735838017}\n",
      "Iteration 7, Losses: {'ner': 315.6869351210712}\n",
      "Iteration 7, Losses: {'ner': 323.27646775948534}\n",
      "Iteration 8, Losses: {'ner': 3.679066600673177}\n",
      "Iteration 8, Losses: {'ner': 12.861994914524647}\n",
      "Iteration 8, Losses: {'ner': 18.778923756189094}\n",
      "Iteration 8, Losses: {'ner': 51.27164537165398}\n",
      "Iteration 8, Losses: {'ner': 89.6479426486604}\n",
      "Iteration 8, Losses: {'ner': 108.10047021769297}\n",
      "Iteration 8, Losses: {'ner': 117.59775912050816}\n",
      "Iteration 8, Losses: {'ner': 124.17949057774237}\n",
      "Iteration 8, Losses: {'ner': 125.25592911915386}\n",
      "Iteration 8, Losses: {'ner': 139.85272754983154}\n",
      "Iteration 8, Losses: {'ner': 145.5959135914756}\n",
      "Iteration 8, Losses: {'ner': 150.549380074053}\n",
      "Iteration 8, Losses: {'ner': 168.5449812158179}\n",
      "Iteration 8, Losses: {'ner': 169.7300351382105}\n",
      "Iteration 8, Losses: {'ner': 177.26506669882627}\n",
      "Iteration 8, Losses: {'ner': 182.2388918195925}\n",
      "Iteration 8, Losses: {'ner': 184.3517747606962}\n",
      "Iteration 8, Losses: {'ner': 199.11770459998598}\n",
      "Iteration 8, Losses: {'ner': 205.5082715396657}\n",
      "Iteration 8, Losses: {'ner': 216.00751858084263}\n",
      "Iteration 8, Losses: {'ner': 220.76957981903132}\n",
      "Iteration 8, Losses: {'ner': 227.46128458543538}\n",
      "Iteration 8, Losses: {'ner': 236.05633690784245}\n",
      "Iteration 8, Losses: {'ner': 249.0204097434023}\n",
      "Iteration 8, Losses: {'ner': 249.0707245066149}\n",
      "Iteration 8, Losses: {'ner': 260.5387126748556}\n",
      "Iteration 8, Losses: {'ner': 277.635549890906}\n",
      "Iteration 8, Losses: {'ner': 291.84141532405397}\n",
      "Iteration 8, Losses: {'ner': 297.4651361688891}\n",
      "Iteration 8, Losses: {'ner': 301.04305114241373}\n",
      "Iteration 8, Losses: {'ner': 306.7278472022923}\n",
      "Iteration 9, Losses: {'ner': 0.9488136313221717}\n",
      "Iteration 9, Losses: {'ner': 12.889391912021479}\n",
      "Iteration 9, Losses: {'ner': 20.142363687250604}\n",
      "Iteration 9, Losses: {'ner': 27.168648938345683}\n",
      "Iteration 9, Losses: {'ner': 68.07720983053431}\n",
      "Iteration 9, Losses: {'ner': 75.66283899758793}\n",
      "Iteration 9, Losses: {'ner': 81.1736208845112}\n",
      "Iteration 9, Losses: {'ner': 87.14431106258915}\n",
      "Iteration 9, Losses: {'ner': 109.51987271888761}\n",
      "Iteration 9, Losses: {'ner': 118.92293413228383}\n",
      "Iteration 9, Losses: {'ner': 131.05599313797535}\n",
      "Iteration 9, Losses: {'ner': 137.26860545695646}\n",
      "Iteration 9, Losses: {'ner': 141.0442113043136}\n",
      "Iteration 9, Losses: {'ner': 147.7017416978379}\n",
      "Iteration 9, Losses: {'ner': 153.25618782151}\n",
      "Iteration 9, Losses: {'ner': 167.1562818085438}\n",
      "Iteration 9, Losses: {'ner': 179.8472588459472}\n",
      "Iteration 9, Losses: {'ner': 180.18022947625755}\n",
      "Iteration 9, Losses: {'ner': 182.58778870406408}\n",
      "Iteration 9, Losses: {'ner': 184.51984333341696}\n",
      "Iteration 9, Losses: {'ner': 188.25952107437908}\n",
      "Iteration 9, Losses: {'ner': 201.45466684049757}\n",
      "Iteration 9, Losses: {'ner': 206.19703851783305}\n",
      "Iteration 9, Losses: {'ner': 219.82206109842906}\n",
      "Iteration 9, Losses: {'ner': 240.50296428452313}\n",
      "Iteration 9, Losses: {'ner': 255.89476071184473}\n",
      "Iteration 9, Losses: {'ner': 282.95302907950656}\n",
      "Iteration 9, Losses: {'ner': 288.19253636014054}\n",
      "Iteration 9, Losses: {'ner': 288.61280245834894}\n",
      "Iteration 9, Losses: {'ner': 294.0189048127545}\n",
      "Iteration 9, Losses: {'ner': 295.19891404220976}\n",
      "Iteration 10, Losses: {'ner': 42.13786924419378}\n",
      "Iteration 10, Losses: {'ner': 42.54189686010427}\n",
      "Iteration 10, Losses: {'ner': 50.33172762241381}\n",
      "Iteration 10, Losses: {'ner': 65.16498501065743}\n",
      "Iteration 10, Losses: {'ner': 66.00834478347026}\n",
      "Iteration 10, Losses: {'ner': 72.81319641448549}\n",
      "Iteration 10, Losses: {'ner': 79.58733276509986}\n",
      "Iteration 10, Losses: {'ner': 85.51593177959842}\n",
      "Iteration 10, Losses: {'ner': 100.67274353323855}\n",
      "Iteration 10, Losses: {'ner': 106.00487241454277}\n",
      "Iteration 10, Losses: {'ner': 106.89508188198445}\n",
      "Iteration 10, Losses: {'ner': 113.38148394368933}\n",
      "Iteration 10, Losses: {'ner': 138.11717493975485}\n",
      "Iteration 10, Losses: {'ner': 142.73208997859524}\n",
      "Iteration 10, Losses: {'ner': 144.939184094164}\n",
      "Iteration 10, Losses: {'ner': 152.73293698084922}\n",
      "Iteration 10, Losses: {'ner': 166.15918869375625}\n",
      "Iteration 10, Losses: {'ner': 178.45246174677868}\n",
      "Iteration 10, Losses: {'ner': 182.01466393621143}\n",
      "Iteration 10, Losses: {'ner': 188.04297660607}\n",
      "Iteration 10, Losses: {'ner': 202.94570560094002}\n",
      "Iteration 10, Losses: {'ner': 218.65345357321632}\n",
      "Iteration 10, Losses: {'ner': 228.8275197210714}\n",
      "Iteration 10, Losses: {'ner': 239.77800367211003}\n",
      "Iteration 10, Losses: {'ner': 245.24879383631358}\n",
      "Iteration 10, Losses: {'ner': 256.91463758101804}\n",
      "Iteration 10, Losses: {'ner': 263.1454838629934}\n",
      "Iteration 10, Losses: {'ner': 266.90013840526905}\n",
      "Iteration 10, Losses: {'ner': 268.2280046059184}\n",
      "Iteration 10, Losses: {'ner': 317.83449360723614}\n",
      "Iteration 10, Losses: {'ner': 318.16643553653375}\n",
      "Iteration 11, Losses: {'ner': 0.12636629403466354}\n",
      "Iteration 11, Losses: {'ner': 5.440373349365632}\n",
      "Iteration 11, Losses: {'ner': 13.543547140982449}\n",
      "Iteration 11, Losses: {'ner': 17.171196653093347}\n",
      "Iteration 11, Losses: {'ner': 38.822040740050966}\n",
      "Iteration 11, Losses: {'ner': 49.16381455708777}\n",
      "Iteration 11, Losses: {'ner': 53.03874286903455}\n",
      "Iteration 11, Losses: {'ner': 61.83003023751989}\n",
      "Iteration 11, Losses: {'ner': 66.9806639799417}\n",
      "Iteration 11, Losses: {'ner': 80.93737276508493}\n",
      "Iteration 11, Losses: {'ner': 89.7717931600189}\n",
      "Iteration 11, Losses: {'ner': 89.77520319110506}\n",
      "Iteration 11, Losses: {'ner': 106.87234536578597}\n",
      "Iteration 11, Losses: {'ner': 110.67361044484153}\n",
      "Iteration 11, Losses: {'ner': 114.89711347557956}\n",
      "Iteration 11, Losses: {'ner': 125.68133589882542}\n",
      "Iteration 11, Losses: {'ner': 130.69023146952358}\n",
      "Iteration 11, Losses: {'ner': 135.092022240752}\n",
      "Iteration 11, Losses: {'ner': 147.9307026427738}\n",
      "Iteration 11, Losses: {'ner': 163.0113449927095}\n",
      "Iteration 11, Losses: {'ner': 179.5654918757864}\n",
      "Iteration 11, Losses: {'ner': 179.89197281726086}\n",
      "Iteration 11, Losses: {'ner': 180.65484036709438}\n",
      "Iteration 11, Losses: {'ner': 184.67127522350836}\n",
      "Iteration 11, Losses: {'ner': 187.58567398776538}\n",
      "Iteration 11, Losses: {'ner': 190.39579285277455}\n",
      "Iteration 11, Losses: {'ner': 232.03829910539562}\n",
      "Iteration 11, Losses: {'ner': 243.2845163392136}\n",
      "Iteration 11, Losses: {'ner': 254.72274894717313}\n",
      "Iteration 11, Losses: {'ner': 258.30893528591565}\n",
      "Iteration 11, Losses: {'ner': 264.96970176842467}\n",
      "Iteration 12, Losses: {'ner': 6.354288495492901}\n",
      "Iteration 12, Losses: {'ner': 16.472945609304773}\n",
      "Iteration 12, Losses: {'ner': 21.829470368208785}\n",
      "Iteration 12, Losses: {'ner': 39.19062053558176}\n",
      "Iteration 12, Losses: {'ner': 52.916846766713626}\n",
      "Iteration 12, Losses: {'ner': 58.21636276611992}\n",
      "Iteration 12, Losses: {'ner': 59.22426952521692}\n",
      "Iteration 12, Losses: {'ner': 59.22559672738036}\n",
      "Iteration 12, Losses: {'ner': 65.77299865121809}\n",
      "Iteration 12, Losses: {'ner': 73.34291705398162}\n",
      "Iteration 12, Losses: {'ner': 79.68606963325564}\n",
      "Iteration 12, Losses: {'ner': 88.99041639309864}\n",
      "Iteration 12, Losses: {'ner': 92.02184522154637}\n",
      "Iteration 12, Losses: {'ner': 93.35177540969781}\n",
      "Iteration 12, Losses: {'ner': 116.05857947662824}\n",
      "Iteration 12, Losses: {'ner': 118.5190709890324}\n",
      "Iteration 12, Losses: {'ner': 131.10338759698251}\n",
      "Iteration 12, Losses: {'ner': 131.99608143006415}\n",
      "Iteration 12, Losses: {'ner': 139.15531072364348}\n",
      "Iteration 12, Losses: {'ner': 144.3655383283012}\n",
      "Iteration 12, Losses: {'ner': 150.34162985858853}\n",
      "Iteration 12, Losses: {'ner': 167.17109416031604}\n",
      "Iteration 12, Losses: {'ner': 180.1794939952669}\n",
      "Iteration 12, Losses: {'ner': 185.67816343360036}\n",
      "Iteration 12, Losses: {'ner': 200.08779993212315}\n",
      "Iteration 12, Losses: {'ner': 210.70295864443005}\n",
      "Iteration 12, Losses: {'ner': 251.01412023981675}\n",
      "Iteration 12, Losses: {'ner': 253.6685520545595}\n",
      "Iteration 12, Losses: {'ner': 262.1837985279975}\n",
      "Iteration 12, Losses: {'ner': 265.71213960944675}\n",
      "Iteration 12, Losses: {'ner': 284.3966983124913}\n",
      "Iteration 13, Losses: {'ner': 5.856323334069092}\n",
      "Iteration 13, Losses: {'ner': 13.948115795055259}\n",
      "Iteration 13, Losses: {'ner': 15.73844285560433}\n",
      "Iteration 13, Losses: {'ner': 20.579783914215948}\n",
      "Iteration 13, Losses: {'ner': 36.31199242528571}\n",
      "Iteration 13, Losses: {'ner': 39.76480288535596}\n",
      "Iteration 13, Losses: {'ner': 44.84710900963651}\n",
      "Iteration 13, Losses: {'ner': 51.49018696422559}\n",
      "Iteration 13, Losses: {'ner': 57.920365119569944}\n",
      "Iteration 13, Losses: {'ner': 70.77876287489673}\n",
      "Iteration 13, Losses: {'ner': 73.16938189296405}\n",
      "Iteration 13, Losses: {'ner': 83.5210167769957}\n",
      "Iteration 13, Losses: {'ner': 83.52723370944709}\n",
      "Iteration 13, Losses: {'ner': 94.41481099519582}\n",
      "Iteration 13, Losses: {'ner': 112.71054250718376}\n",
      "Iteration 13, Losses: {'ner': 119.47495814561586}\n",
      "Iteration 13, Losses: {'ner': 126.42421656091292}\n",
      "Iteration 13, Losses: {'ner': 126.45277802490509}\n",
      "Iteration 13, Losses: {'ner': 127.6302561474417}\n",
      "Iteration 13, Losses: {'ner': 131.65708060295805}\n",
      "Iteration 13, Losses: {'ner': 142.02200594769653}\n",
      "Iteration 13, Losses: {'ner': 148.14301396542817}\n",
      "Iteration 13, Losses: {'ner': 162.65122212945678}\n",
      "Iteration 13, Losses: {'ner': 162.8277438548724}\n",
      "Iteration 13, Losses: {'ner': 166.91675102685838}\n",
      "Iteration 13, Losses: {'ner': 169.920344036016}\n",
      "Iteration 13, Losses: {'ner': 172.09192116956962}\n",
      "Iteration 13, Losses: {'ner': 182.57775043305523}\n",
      "Iteration 13, Losses: {'ner': 216.4268070445842}\n",
      "Iteration 13, Losses: {'ner': 233.5541067591419}\n",
      "Iteration 13, Losses: {'ner': 240.38981664055387}\n",
      "Iteration 14, Losses: {'ner': 8.53063327355171}\n",
      "Iteration 14, Losses: {'ner': 21.946827342846927}\n",
      "Iteration 14, Losses: {'ner': 24.7215543848247}\n",
      "Iteration 14, Losses: {'ner': 32.884981142605305}\n",
      "Iteration 14, Losses: {'ner': 33.162684347625884}\n",
      "Iteration 14, Losses: {'ner': 48.41042578078766}\n",
      "Iteration 14, Losses: {'ner': 49.38986383972405}\n",
      "Iteration 14, Losses: {'ner': 64.81818124048996}\n",
      "Iteration 14, Losses: {'ner': 70.95605521958352}\n",
      "Iteration 14, Losses: {'ner': 77.26517915311753}\n",
      "Iteration 14, Losses: {'ner': 77.26898534724295}\n",
      "Iteration 14, Losses: {'ner': 89.61419838689656}\n",
      "Iteration 14, Losses: {'ner': 93.91407666040627}\n",
      "Iteration 14, Losses: {'ner': 96.85581996334567}\n",
      "Iteration 14, Losses: {'ner': 101.93930029951416}\n",
      "Iteration 14, Losses: {'ner': 104.42370655578057}\n",
      "Iteration 14, Losses: {'ner': 104.92902034073691}\n",
      "Iteration 14, Losses: {'ner': 105.28462342117635}\n",
      "Iteration 14, Losses: {'ner': 111.11624873524879}\n",
      "Iteration 14, Losses: {'ner': 152.885444587263}\n",
      "Iteration 14, Losses: {'ner': 159.07907713097688}\n",
      "Iteration 14, Losses: {'ner': 170.94732551953075}\n",
      "Iteration 14, Losses: {'ner': 174.09851492573426}\n",
      "Iteration 14, Losses: {'ner': 174.36378153012163}\n",
      "Iteration 14, Losses: {'ner': 176.04324898020423}\n",
      "Iteration 14, Losses: {'ner': 189.95189964061058}\n",
      "Iteration 14, Losses: {'ner': 202.47746894455614}\n",
      "Iteration 14, Losses: {'ner': 216.3169506416369}\n",
      "Iteration 14, Losses: {'ner': 217.15165423951993}\n",
      "Iteration 14, Losses: {'ner': 227.63792332337567}\n",
      "Iteration 14, Losses: {'ner': 234.2277390104627}\n",
      "Iteration 15, Losses: {'ner': 5.616635082908374}\n",
      "Iteration 15, Losses: {'ner': 17.9171951344332}\n",
      "Iteration 15, Losses: {'ner': 31.060993098428817}\n",
      "Iteration 15, Losses: {'ner': 35.903734616267045}\n",
      "Iteration 15, Losses: {'ner': 37.34979668259378}\n",
      "Iteration 15, Losses: {'ner': 43.319029286416985}\n",
      "Iteration 15, Losses: {'ner': 54.09929695606177}\n",
      "Iteration 15, Losses: {'ner': 63.34105555913421}\n",
      "Iteration 15, Losses: {'ner': 67.11967554463024}\n",
      "Iteration 15, Losses: {'ner': 80.57748310581712}\n",
      "Iteration 15, Losses: {'ner': 85.14044602649504}\n",
      "Iteration 15, Losses: {'ner': 88.53480012579429}\n",
      "Iteration 15, Losses: {'ner': 99.0289138397755}\n",
      "Iteration 15, Losses: {'ner': 103.20944482972214}\n",
      "Iteration 15, Losses: {'ner': 103.4969221646238}\n",
      "Iteration 15, Losses: {'ner': 106.76751064145662}\n",
      "Iteration 15, Losses: {'ner': 106.90057161121331}\n",
      "Iteration 15, Losses: {'ner': 118.74847068926067}\n",
      "Iteration 15, Losses: {'ner': 120.19202297995028}\n",
      "Iteration 15, Losses: {'ner': 126.80185483304076}\n",
      "Iteration 15, Losses: {'ner': 129.5035586749136}\n",
      "Iteration 15, Losses: {'ner': 139.4413806001097}\n",
      "Iteration 15, Losses: {'ner': 147.4796741185135}\n",
      "Iteration 15, Losses: {'ner': 149.49693775711867}\n",
      "Iteration 15, Losses: {'ner': 153.29501665051424}\n",
      "Iteration 15, Losses: {'ner': 154.5523682493364}\n",
      "Iteration 15, Losses: {'ner': 154.55790599568684}\n",
      "Iteration 15, Losses: {'ner': 170.75830169020136}\n",
      "Iteration 15, Losses: {'ner': 170.75881320698085}\n",
      "Iteration 15, Losses: {'ner': 203.58350030424683}\n",
      "Iteration 15, Losses: {'ner': 222.2573660502711}\n",
      "Iteration 16, Losses: {'ner': 8.572105360941075}\n",
      "Iteration 16, Losses: {'ner': 19.604964094670308}\n",
      "Iteration 16, Losses: {'ner': 24.178931060557844}\n",
      "Iteration 16, Losses: {'ner': 26.233297831752925}\n",
      "Iteration 16, Losses: {'ner': 28.000774286432584}\n",
      "Iteration 16, Losses: {'ner': 38.22917089855006}\n",
      "Iteration 16, Losses: {'ner': 48.817309677749726}\n",
      "Iteration 16, Losses: {'ner': 54.98281969565661}\n",
      "Iteration 16, Losses: {'ner': 62.17660610307033}\n",
      "Iteration 16, Losses: {'ner': 66.58426502229163}\n",
      "Iteration 16, Losses: {'ner': 75.14857223713136}\n",
      "Iteration 16, Losses: {'ner': 76.86637412668095}\n",
      "Iteration 16, Losses: {'ner': 76.87396601344977}\n",
      "Iteration 16, Losses: {'ner': 87.66594837141962}\n",
      "Iteration 16, Losses: {'ner': 92.21578750204694}\n",
      "Iteration 16, Losses: {'ner': 93.02471834324118}\n",
      "Iteration 16, Losses: {'ner': 93.9045498691757}\n",
      "Iteration 16, Losses: {'ner': 104.24095233798101}\n",
      "Iteration 16, Losses: {'ner': 116.759378295224}\n",
      "Iteration 16, Losses: {'ner': 119.42476162705836}\n",
      "Iteration 16, Losses: {'ner': 130.37518749283396}\n",
      "Iteration 16, Losses: {'ner': 143.05636013137683}\n",
      "Iteration 16, Losses: {'ner': 157.93599816876085}\n",
      "Iteration 16, Losses: {'ner': 158.27671389521592}\n",
      "Iteration 16, Losses: {'ner': 158.33803711510842}\n",
      "Iteration 16, Losses: {'ner': 239.28741984600197}\n",
      "Iteration 16, Losses: {'ner': 243.958139708286}\n",
      "Iteration 16, Losses: {'ner': 246.94843326486924}\n",
      "Iteration 16, Losses: {'ner': 248.9476965357213}\n",
      "Iteration 16, Losses: {'ner': 261.0909703981985}\n",
      "Iteration 16, Losses: {'ner': 264.0651016435958}\n",
      "Iteration 17, Losses: {'ner': 4.7642023360635255}\n",
      "Iteration 17, Losses: {'ner': 4.765903353419677}\n",
      "Iteration 17, Losses: {'ner': 6.103551884706976}\n",
      "Iteration 17, Losses: {'ner': 28.567991661323987}\n",
      "Iteration 17, Losses: {'ner': 40.671902236683835}\n",
      "Iteration 17, Losses: {'ner': 44.340607936119184}\n",
      "Iteration 17, Losses: {'ner': 54.976223322482035}\n",
      "Iteration 17, Losses: {'ner': 59.64046228269272}\n",
      "Iteration 17, Losses: {'ner': 71.52246095327932}\n",
      "Iteration 17, Losses: {'ner': 76.01409062814126}\n",
      "Iteration 17, Losses: {'ner': 87.9547062776603}\n",
      "Iteration 17, Losses: {'ner': 94.0114856784953}\n",
      "Iteration 17, Losses: {'ner': 94.02565851267984}\n",
      "Iteration 17, Losses: {'ner': 96.61104687560908}\n",
      "Iteration 17, Losses: {'ner': 101.24987300943714}\n",
      "Iteration 17, Losses: {'ner': 104.11289679453716}\n",
      "Iteration 17, Losses: {'ner': 112.44819861967248}\n",
      "Iteration 17, Losses: {'ner': 113.46762905454266}\n",
      "Iteration 17, Losses: {'ner': 116.42730201556023}\n",
      "Iteration 17, Losses: {'ner': 130.5204239613843}\n",
      "Iteration 17, Losses: {'ner': 137.00438049227438}\n",
      "Iteration 17, Losses: {'ner': 138.3563304450155}\n",
      "Iteration 17, Losses: {'ner': 143.88861623007574}\n",
      "Iteration 17, Losses: {'ner': 183.96498574890393}\n",
      "Iteration 17, Losses: {'ner': 184.6738219468089}\n",
      "Iteration 17, Losses: {'ner': 186.64493326166578}\n",
      "Iteration 17, Losses: {'ner': 200.16990445823694}\n",
      "Iteration 17, Losses: {'ner': 205.13851606300864}\n",
      "Iteration 17, Losses: {'ner': 215.68933586915975}\n",
      "Iteration 17, Losses: {'ner': 215.8147524731919}\n",
      "Iteration 17, Losses: {'ner': 220.93464797700338}\n",
      "Iteration 18, Losses: {'ner': 0.00039485703783575827}\n",
      "Iteration 18, Losses: {'ner': 1.4742147632212128}\n",
      "Iteration 18, Losses: {'ner': 12.178036502999461}\n",
      "Iteration 18, Losses: {'ner': 25.01312165323577}\n",
      "Iteration 18, Losses: {'ner': 28.455022957023786}\n",
      "Iteration 18, Losses: {'ner': 33.55358806537028}\n",
      "Iteration 18, Losses: {'ner': 39.44664792075573}\n",
      "Iteration 18, Losses: {'ner': 41.24617403540306}\n",
      "Iteration 18, Losses: {'ner': 43.19810263004198}\n",
      "Iteration 18, Losses: {'ner': 48.66855473749993}\n",
      "Iteration 18, Losses: {'ner': 54.33008699885335}\n",
      "Iteration 18, Losses: {'ner': 67.98998925559947}\n",
      "Iteration 18, Losses: {'ner': 73.51413289070302}\n",
      "Iteration 18, Losses: {'ner': 87.78147446774304}\n",
      "Iteration 18, Losses: {'ner': 92.91738017932995}\n",
      "Iteration 18, Losses: {'ner': 93.50984333311673}\n",
      "Iteration 18, Losses: {'ner': 95.91408358281898}\n",
      "Iteration 18, Losses: {'ner': 97.69640474824041}\n",
      "Iteration 18, Losses: {'ner': 98.04615870232519}\n",
      "Iteration 18, Losses: {'ner': 106.7828852146677}\n",
      "Iteration 18, Losses: {'ner': 117.56915544272302}\n",
      "Iteration 18, Losses: {'ner': 129.91118749727963}\n",
      "Iteration 18, Losses: {'ner': 149.96257384247846}\n",
      "Iteration 18, Losses: {'ner': 192.62722637294763}\n",
      "Iteration 18, Losses: {'ner': 193.18509627984355}\n",
      "Iteration 18, Losses: {'ner': 193.18822316346166}\n",
      "Iteration 18, Losses: {'ner': 194.30126027849695}\n",
      "Iteration 18, Losses: {'ner': 194.3372762919639}\n",
      "Iteration 18, Losses: {'ner': 197.74774253613316}\n",
      "Iteration 18, Losses: {'ner': 200.4523076614351}\n",
      "Iteration 18, Losses: {'ner': 209.31345713986298}\n",
      "Iteration 19, Losses: {'ner': 0.00016002792822958418}\n",
      "Iteration 19, Losses: {'ner': 11.733349287313988}\n",
      "Iteration 19, Losses: {'ner': 11.846984386457997}\n",
      "Iteration 19, Losses: {'ner': 13.844224705353506}\n",
      "Iteration 19, Losses: {'ner': 13.908659997959907}\n",
      "Iteration 19, Losses: {'ner': 30.26215407572807}\n",
      "Iteration 19, Losses: {'ner': 32.03542816756589}\n",
      "Iteration 19, Losses: {'ner': 43.996933913539266}\n",
      "Iteration 19, Losses: {'ner': 48.073141359689814}\n",
      "Iteration 19, Losses: {'ner': 60.28944814070527}\n",
      "Iteration 19, Losses: {'ner': 60.305981856980786}\n",
      "Iteration 19, Losses: {'ner': 60.320276427408636}\n",
      "Iteration 19, Losses: {'ner': 61.36518997550395}\n",
      "Iteration 19, Losses: {'ner': 77.49162446897871}\n",
      "Iteration 19, Losses: {'ner': 81.08288425585098}\n",
      "Iteration 19, Losses: {'ner': 84.91082166613704}\n",
      "Iteration 19, Losses: {'ner': 93.50197955681956}\n",
      "Iteration 19, Losses: {'ner': 94.86817233146228}\n",
      "Iteration 19, Losses: {'ner': 138.76246283456996}\n",
      "Iteration 19, Losses: {'ner': 148.64621769757886}\n",
      "Iteration 19, Losses: {'ner': 156.1998656899836}\n",
      "Iteration 19, Losses: {'ner': 171.24760733380728}\n",
      "Iteration 19, Losses: {'ner': 178.9466573885395}\n",
      "Iteration 19, Losses: {'ner': 182.4755100958584}\n",
      "Iteration 19, Losses: {'ner': 182.5634812104334}\n",
      "Iteration 19, Losses: {'ner': 182.71135910875944}\n",
      "Iteration 19, Losses: {'ner': 190.69648040117923}\n",
      "Iteration 19, Losses: {'ner': 206.80777452614763}\n",
      "Iteration 19, Losses: {'ner': 215.1450331249465}\n",
      "Iteration 19, Losses: {'ner': 261.61724892567224}\n",
      "Iteration 19, Losses: {'ner': 275.2386365776904}\n",
      "Iteration 20, Losses: {'ner': 1.0765728047422911}\n",
      "Iteration 20, Losses: {'ner': 4.133605123055097}\n",
      "Iteration 20, Losses: {'ner': 6.262043098378622}\n",
      "Iteration 20, Losses: {'ner': 15.160622183536319}\n",
      "Iteration 20, Losses: {'ner': 19.145508027749493}\n",
      "Iteration 20, Losses: {'ner': 19.235485591374225}\n",
      "Iteration 20, Losses: {'ner': 19.25556331093022}\n",
      "Iteration 20, Losses: {'ner': 21.595039542139915}\n",
      "Iteration 20, Losses: {'ner': 22.141296425167067}\n",
      "Iteration 20, Losses: {'ner': 25.4219417424121}\n",
      "Iteration 20, Losses: {'ner': 27.022799756764883}\n",
      "Iteration 20, Losses: {'ner': 27.022821665930202}\n",
      "Iteration 20, Losses: {'ner': 27.411558493538056}\n",
      "Iteration 20, Losses: {'ner': 32.96102452465334}\n",
      "Iteration 20, Losses: {'ner': 33.29093496652711}\n",
      "Iteration 20, Losses: {'ner': 34.56260993783192}\n",
      "Iteration 20, Losses: {'ner': 39.728047126538954}\n",
      "Iteration 20, Losses: {'ner': 51.50820864481072}\n",
      "Iteration 20, Losses: {'ner': 78.16115421292248}\n",
      "Iteration 20, Losses: {'ner': 83.83942876262186}\n",
      "Iteration 20, Losses: {'ner': 90.79066644310497}\n",
      "Iteration 20, Losses: {'ner': 97.58539478122393}\n",
      "Iteration 20, Losses: {'ner': 110.5082543769653}\n",
      "Iteration 20, Losses: {'ner': 116.36492343734382}\n",
      "Iteration 20, Losses: {'ner': 119.52823009299874}\n",
      "Iteration 20, Losses: {'ner': 132.59393334531913}\n",
      "Iteration 20, Losses: {'ner': 141.71044658080848}\n",
      "Iteration 20, Losses: {'ner': 155.71373780703482}\n",
      "Iteration 20, Losses: {'ner': 167.74984481481923}\n",
      "Iteration 20, Losses: {'ner': 181.12844511974112}\n",
      "Iteration 20, Losses: {'ner': 185.94385337272135}\n",
      "Iteration 21, Losses: {'ner': 2.362063373095146}\n",
      "Iteration 21, Losses: {'ner': 2.6338360200260675}\n",
      "Iteration 21, Losses: {'ner': 5.7686765190150195}\n",
      "Iteration 21, Losses: {'ner': 9.203252590008104}\n",
      "Iteration 21, Losses: {'ner': 14.151637471317825}\n",
      "Iteration 21, Losses: {'ner': 23.90475270399614}\n",
      "Iteration 21, Losses: {'ner': 37.95575092272431}\n",
      "Iteration 21, Losses: {'ner': 37.993363193891874}\n",
      "Iteration 21, Losses: {'ner': 40.780488199685955}\n",
      "Iteration 21, Losses: {'ner': 40.862944126805694}\n",
      "Iteration 21, Losses: {'ner': 56.978820114418255}\n",
      "Iteration 21, Losses: {'ner': 57.4026107822065}\n",
      "Iteration 21, Losses: {'ner': 62.18698817503935}\n",
      "Iteration 21, Losses: {'ner': 68.41732132222171}\n",
      "Iteration 21, Losses: {'ner': 75.47861504997427}\n",
      "Iteration 21, Losses: {'ner': 79.73237087968099}\n",
      "Iteration 21, Losses: {'ner': 79.84934955284498}\n",
      "Iteration 21, Losses: {'ner': 93.51315730038431}\n",
      "Iteration 21, Losses: {'ner': 102.79249593704125}\n",
      "Iteration 21, Losses: {'ner': 102.79269080323056}\n",
      "Iteration 21, Losses: {'ner': 104.50614375108796}\n",
      "Iteration 21, Losses: {'ner': 115.60317568193744}\n",
      "Iteration 21, Losses: {'ner': 117.353415343244}\n",
      "Iteration 21, Losses: {'ner': 125.7511678422315}\n",
      "Iteration 21, Losses: {'ner': 139.6729481442588}\n",
      "Iteration 21, Losses: {'ner': 141.91781171085645}\n",
      "Iteration 21, Losses: {'ner': 172.318290341054}\n",
      "Iteration 21, Losses: {'ner': 187.48107988201028}\n",
      "Iteration 21, Losses: {'ner': 191.36668264976535}\n",
      "Iteration 21, Losses: {'ner': 201.7546401674515}\n",
      "Iteration 21, Losses: {'ner': 202.05859789588314}\n",
      "Iteration 22, Losses: {'ner': 9.669512966266375}\n",
      "Iteration 22, Losses: {'ner': 13.827746875504307}\n",
      "Iteration 22, Losses: {'ner': 21.626963388896296}\n",
      "Iteration 22, Losses: {'ner': 21.952787397106558}\n",
      "Iteration 22, Losses: {'ner': 22.080642853632114}\n",
      "Iteration 22, Losses: {'ner': 34.259468823433075}\n",
      "Iteration 22, Losses: {'ner': 35.84478179577421}\n",
      "Iteration 22, Losses: {'ner': 35.86753574128114}\n",
      "Iteration 22, Losses: {'ner': 39.40931756237583}\n",
      "Iteration 22, Losses: {'ner': 43.06885278047078}\n",
      "Iteration 22, Losses: {'ner': 51.33811617372134}\n",
      "Iteration 22, Losses: {'ner': 69.41352903399405}\n",
      "Iteration 22, Losses: {'ner': 74.61248546097568}\n",
      "Iteration 22, Losses: {'ner': 76.50424119998317}\n",
      "Iteration 22, Losses: {'ner': 151.16432514318618}\n",
      "Iteration 22, Losses: {'ner': 153.34146067470047}\n",
      "Iteration 22, Losses: {'ner': 164.86676576950623}\n",
      "Iteration 22, Losses: {'ner': 167.08760060070728}\n",
      "Iteration 22, Losses: {'ner': 169.28780462350102}\n",
      "Iteration 22, Losses: {'ner': 169.28809443587187}\n",
      "Iteration 22, Losses: {'ner': 169.28816994150367}\n",
      "Iteration 22, Losses: {'ner': 172.1528792810889}\n",
      "Iteration 22, Losses: {'ner': 183.67327092814705}\n",
      "Iteration 22, Losses: {'ner': 184.33045960909925}\n",
      "Iteration 22, Losses: {'ner': 186.8439597957304}\n",
      "Iteration 22, Losses: {'ner': 193.1659628477334}\n",
      "Iteration 22, Losses: {'ner': 193.24913358106392}\n",
      "Iteration 22, Losses: {'ner': 236.58938158083674}\n",
      "Iteration 22, Losses: {'ner': 248.90927792609912}\n",
      "Iteration 22, Losses: {'ner': 261.29021244910473}\n",
      "Iteration 22, Losses: {'ner': 272.82864684692095}\n",
      "Iteration 23, Losses: {'ner': 3.8241824519452354}\n",
      "Iteration 23, Losses: {'ner': 4.376268555626616}\n",
      "Iteration 23, Losses: {'ner': 14.766385551698905}\n",
      "Iteration 23, Losses: {'ner': 25.910242859875364}\n",
      "Iteration 23, Losses: {'ner': 25.911474054651485}\n",
      "Iteration 23, Losses: {'ner': 36.229952489746026}\n",
      "Iteration 23, Losses: {'ner': 36.940085822932595}\n",
      "Iteration 23, Losses: {'ner': 49.6668278780665}\n",
      "Iteration 23, Losses: {'ner': 54.88865183502563}\n",
      "Iteration 23, Losses: {'ner': 57.67489817313809}\n",
      "Iteration 23, Losses: {'ner': 57.739956456338206}\n",
      "Iteration 23, Losses: {'ner': 70.10608827869905}\n",
      "Iteration 23, Losses: {'ner': 79.96258997198547}\n",
      "Iteration 23, Losses: {'ner': 88.20191459175724}\n",
      "Iteration 23, Losses: {'ner': 104.03426521344389}\n",
      "Iteration 23, Losses: {'ner': 149.00991761753298}\n",
      "Iteration 23, Losses: {'ner': 156.11274661010887}\n",
      "Iteration 23, Losses: {'ner': 156.11455958015247}\n",
      "Iteration 23, Losses: {'ner': 166.6864766110503}\n",
      "Iteration 23, Losses: {'ner': 167.7218989834767}\n",
      "Iteration 23, Losses: {'ner': 171.88010448427272}\n",
      "Iteration 23, Losses: {'ner': 173.33312835571073}\n",
      "Iteration 23, Losses: {'ner': 174.1012833850312}\n",
      "Iteration 23, Losses: {'ner': 193.12675502431304}\n",
      "Iteration 23, Losses: {'ner': 198.47338955895313}\n",
      "Iteration 23, Losses: {'ner': 200.7230759123719}\n",
      "Iteration 23, Losses: {'ner': 202.0359031252915}\n",
      "Iteration 23, Losses: {'ner': 202.8946362199754}\n",
      "Iteration 23, Losses: {'ner': 202.94501958785713}\n",
      "Iteration 23, Losses: {'ner': 203.21617237660013}\n",
      "Iteration 23, Losses: {'ner': 209.31041790016567}\n",
      "Iteration 24, Losses: {'ner': 4.54967564957208}\n",
      "Iteration 24, Losses: {'ner': 4.600303390310169}\n",
      "Iteration 24, Losses: {'ner': 11.519807290438099}\n",
      "Iteration 24, Losses: {'ner': 19.5608028562837}\n",
      "Iteration 24, Losses: {'ner': 19.959161671706998}\n",
      "Iteration 24, Losses: {'ner': 19.98746253234909}\n",
      "Iteration 24, Losses: {'ner': 26.96186186482616}\n",
      "Iteration 24, Losses: {'ner': 28.72741675108839}\n",
      "Iteration 24, Losses: {'ner': 29.746041400450057}\n",
      "Iteration 24, Losses: {'ner': 29.9128148581229}\n",
      "Iteration 24, Losses: {'ner': 32.92369832777322}\n",
      "Iteration 24, Losses: {'ner': 35.198776074260245}\n",
      "Iteration 24, Losses: {'ner': 40.695125328686295}\n",
      "Iteration 24, Losses: {'ner': 51.20237909489892}\n",
      "Iteration 24, Losses: {'ner': 68.4359744159407}\n",
      "Iteration 24, Losses: {'ner': 68.43612721873575}\n",
      "Iteration 24, Losses: {'ner': 68.45720205177538}\n",
      "Iteration 24, Losses: {'ner': 76.20450408615359}\n",
      "Iteration 24, Losses: {'ner': 76.20466199432828}\n",
      "Iteration 24, Losses: {'ner': 83.15433254268729}\n",
      "Iteration 24, Losses: {'ner': 88.45833365426431}\n",
      "Iteration 24, Losses: {'ner': 92.1673979438664}\n",
      "Iteration 24, Losses: {'ner': 109.77421827857248}\n",
      "Iteration 24, Losses: {'ner': 113.10609423278302}\n",
      "Iteration 24, Losses: {'ner': 154.33095368095977}\n",
      "Iteration 24, Losses: {'ner': 154.35353677430268}\n",
      "Iteration 24, Losses: {'ner': 156.01177655902595}\n",
      "Iteration 24, Losses: {'ner': 172.0233966639985}\n",
      "Iteration 24, Losses: {'ner': 184.08167470498782}\n",
      "Iteration 24, Losses: {'ner': 194.1367668065869}\n",
      "Iteration 24, Losses: {'ner': 206.13802324429304}\n",
      "Iteration 25, Losses: {'ner': 11.698997659945416}\n",
      "Iteration 25, Losses: {'ner': 24.898561425631378}\n",
      "Iteration 25, Losses: {'ner': 28.495576332245804}\n",
      "Iteration 25, Losses: {'ner': 28.62765334787065}\n",
      "Iteration 25, Losses: {'ner': 30.453489572664413}\n",
      "Iteration 25, Losses: {'ner': 43.35214398682676}\n",
      "Iteration 25, Losses: {'ner': 45.27936519403553}\n",
      "Iteration 25, Losses: {'ner': 45.53138562006136}\n",
      "Iteration 25, Losses: {'ner': 51.327587684552306}\n",
      "Iteration 25, Losses: {'ner': 89.67876561805065}\n",
      "Iteration 25, Losses: {'ner': 99.23610224524286}\n",
      "Iteration 25, Losses: {'ner': 102.43362605690831}\n",
      "Iteration 25, Losses: {'ner': 103.3185248734282}\n",
      "Iteration 25, Losses: {'ner': 103.45014363522381}\n",
      "Iteration 25, Losses: {'ner': 108.31418597735788}\n",
      "Iteration 25, Losses: {'ner': 109.94475875126108}\n",
      "Iteration 25, Losses: {'ner': 111.00937104224228}\n",
      "Iteration 25, Losses: {'ner': 111.01612704557613}\n",
      "Iteration 25, Losses: {'ner': 114.17418920698972}\n",
      "Iteration 25, Losses: {'ner': 121.45419406817133}\n",
      "Iteration 25, Losses: {'ner': 124.32496656113389}\n",
      "Iteration 25, Losses: {'ner': 131.9286821394786}\n",
      "Iteration 25, Losses: {'ner': 132.06400717947952}\n",
      "Iteration 25, Losses: {'ner': 140.37852950310102}\n",
      "Iteration 25, Losses: {'ner': 140.749902003311}\n",
      "Iteration 25, Losses: {'ner': 148.66098238459298}\n",
      "Iteration 25, Losses: {'ner': 159.30751588439625}\n",
      "Iteration 25, Losses: {'ner': 159.81671124127354}\n",
      "Iteration 25, Losses: {'ner': 162.68462144204162}\n",
      "Iteration 25, Losses: {'ner': 162.8427341942308}\n",
      "Iteration 25, Losses: {'ner': 174.80823680881755}\n",
      "Iteration 26, Losses: {'ner': 0.0017119049425469472}\n",
      "Iteration 26, Losses: {'ner': 7.555489209751195}\n",
      "Iteration 26, Losses: {'ner': 18.394623936795366}\n",
      "Iteration 26, Losses: {'ner': 18.486783702379316}\n",
      "Iteration 26, Losses: {'ner': 23.647215123056046}\n",
      "Iteration 26, Losses: {'ner': 25.128569317270774}\n",
      "Iteration 26, Losses: {'ner': 29.044853260465864}\n",
      "Iteration 26, Losses: {'ner': 35.159527329750084}\n",
      "Iteration 26, Losses: {'ner': 39.327483513644566}\n",
      "Iteration 26, Losses: {'ner': 44.46215511250456}\n",
      "Iteration 26, Losses: {'ner': 47.14345893684874}\n",
      "Iteration 26, Losses: {'ner': 58.36913967886785}\n",
      "Iteration 26, Losses: {'ner': 60.58705981046872}\n",
      "Iteration 26, Losses: {'ner': 64.57153410128336}\n",
      "Iteration 26, Losses: {'ner': 81.20934095792926}\n",
      "Iteration 26, Losses: {'ner': 81.21155750733591}\n",
      "Iteration 26, Losses: {'ner': 81.53044817567344}\n",
      "Iteration 26, Losses: {'ner': 126.78814723049436}\n",
      "Iteration 26, Losses: {'ner': 138.26899953110632}\n",
      "Iteration 26, Losses: {'ner': 138.96319613678537}\n",
      "Iteration 26, Losses: {'ner': 141.0264038167839}\n",
      "Iteration 26, Losses: {'ner': 141.0264846228564}\n",
      "Iteration 26, Losses: {'ner': 147.67611907210454}\n",
      "Iteration 26, Losses: {'ner': 153.68590450959016}\n",
      "Iteration 26, Losses: {'ner': 154.8602497160398}\n",
      "Iteration 26, Losses: {'ner': 155.4250026747151}\n",
      "Iteration 26, Losses: {'ner': 155.44218187274646}\n",
      "Iteration 26, Losses: {'ner': 165.95841848982027}\n",
      "Iteration 26, Losses: {'ner': 180.5882541796806}\n",
      "Iteration 26, Losses: {'ner': 197.249667217228}\n",
      "Iteration 26, Losses: {'ner': 197.30872536220178}\n",
      "Iteration 27, Losses: {'ner': 0.016628140292740654}\n",
      "Iteration 27, Losses: {'ner': 2.397230250659083}\n",
      "Iteration 27, Losses: {'ner': 7.92791625256181}\n",
      "Iteration 27, Losses: {'ner': 7.940775883583673}\n",
      "Iteration 27, Losses: {'ner': 16.262230618808886}\n",
      "Iteration 27, Losses: {'ner': 16.55885051534189}\n",
      "Iteration 27, Losses: {'ner': 18.654880784722163}\n",
      "Iteration 27, Losses: {'ner': 31.19883163532248}\n",
      "Iteration 27, Losses: {'ner': 33.35812084445972}\n",
      "Iteration 27, Losses: {'ner': 33.39436846636861}\n",
      "Iteration 27, Losses: {'ner': 33.398725190102205}\n",
      "Iteration 27, Losses: {'ner': 44.86148720774198}\n",
      "Iteration 27, Losses: {'ner': 54.67279326658768}\n",
      "Iteration 27, Losses: {'ner': 57.56758889447848}\n",
      "Iteration 27, Losses: {'ner': 66.33162269801095}\n",
      "Iteration 27, Losses: {'ner': 66.33182458835624}\n",
      "Iteration 27, Losses: {'ner': 76.03784934967099}\n",
      "Iteration 27, Losses: {'ner': 78.18691674319571}\n",
      "Iteration 27, Losses: {'ner': 80.65309488712356}\n",
      "Iteration 27, Losses: {'ner': 108.05592265802723}\n",
      "Iteration 27, Losses: {'ner': 119.87953837910221}\n",
      "Iteration 27, Losses: {'ner': 127.5958047630149}\n",
      "Iteration 27, Losses: {'ner': 130.13307740498212}\n",
      "Iteration 27, Losses: {'ner': 130.13326234116246}\n",
      "Iteration 27, Losses: {'ner': 134.27040125177837}\n",
      "Iteration 27, Losses: {'ner': 134.98802431793143}\n",
      "Iteration 27, Losses: {'ner': 136.19870219222992}\n",
      "Iteration 27, Losses: {'ner': 146.54717674823135}\n",
      "Iteration 27, Losses: {'ner': 152.4467188192665}\n",
      "Iteration 27, Losses: {'ner': 162.90502654197266}\n",
      "Iteration 27, Losses: {'ner': 163.05545266775462}\n",
      "Iteration 28, Losses: {'ner': 2.55356025143461}\n",
      "Iteration 28, Losses: {'ner': 14.59638817952608}\n",
      "Iteration 28, Losses: {'ner': 14.694661160327623}\n",
      "Iteration 28, Losses: {'ner': 17.8748298477211}\n",
      "Iteration 28, Losses: {'ner': 39.78461877035978}\n",
      "Iteration 28, Losses: {'ner': 41.42552161589812}\n",
      "Iteration 28, Losses: {'ner': 49.59795588929865}\n",
      "Iteration 28, Losses: {'ner': 53.398900174691114}\n",
      "Iteration 28, Losses: {'ner': 53.62312385616484}\n",
      "Iteration 28, Losses: {'ner': 53.62468962000524}\n",
      "Iteration 28, Losses: {'ner': 54.744552716564506}\n",
      "Iteration 28, Losses: {'ner': 57.4574746676616}\n",
      "Iteration 28, Losses: {'ner': 60.436500576722146}\n",
      "Iteration 28, Losses: {'ner': 64.57467994716116}\n",
      "Iteration 28, Losses: {'ner': 69.57660214675566}\n",
      "Iteration 28, Losses: {'ner': 78.60332411563192}\n",
      "Iteration 28, Losses: {'ner': 79.56988494538929}\n",
      "Iteration 28, Losses: {'ner': 79.63171571246656}\n",
      "Iteration 28, Losses: {'ner': 94.40429868516182}\n",
      "Iteration 28, Losses: {'ner': 108.41619683690966}\n",
      "Iteration 28, Losses: {'ner': 112.57817001161165}\n",
      "Iteration 28, Losses: {'ner': 112.58261678778567}\n",
      "Iteration 28, Losses: {'ner': 112.72869446924994}\n",
      "Iteration 28, Losses: {'ner': 124.3098266360503}\n",
      "Iteration 28, Losses: {'ner': 131.51627562975474}\n",
      "Iteration 28, Losses: {'ner': 132.96042113832632}\n",
      "Iteration 28, Losses: {'ner': 143.37322521278642}\n",
      "Iteration 28, Losses: {'ner': 143.37334473208432}\n",
      "Iteration 28, Losses: {'ner': 146.26491533641973}\n",
      "Iteration 28, Losses: {'ner': 151.52506736096845}\n",
      "Iteration 28, Losses: {'ner': 158.82154258763666}\n",
      "Iteration 29, Losses: {'ner': 5.464579882179261}\n",
      "Iteration 29, Losses: {'ner': 5.629984313841695}\n",
      "Iteration 29, Losses: {'ner': 13.579593454295445}\n",
      "Iteration 29, Losses: {'ner': 13.59458909026947}\n",
      "Iteration 29, Losses: {'ner': 40.226296875696356}\n",
      "Iteration 29, Losses: {'ner': 40.22630096190301}\n",
      "Iteration 29, Losses: {'ner': 40.41365405734604}\n",
      "Iteration 29, Losses: {'ner': 40.44066576770403}\n",
      "Iteration 29, Losses: {'ner': 48.938696308954306}\n",
      "Iteration 29, Losses: {'ner': 51.13017113540971}\n",
      "Iteration 29, Losses: {'ner': 55.886007620691835}\n",
      "Iteration 29, Losses: {'ner': 56.62788068913463}\n",
      "Iteration 29, Losses: {'ner': 63.28477757389612}\n",
      "Iteration 29, Losses: {'ner': 64.89325834548286}\n",
      "Iteration 29, Losses: {'ner': 64.89341635366762}\n",
      "Iteration 29, Losses: {'ner': 74.26540165498508}\n",
      "Iteration 29, Losses: {'ner': 75.42175775545519}\n",
      "Iteration 29, Losses: {'ner': 78.69118499853766}\n",
      "Iteration 29, Losses: {'ner': 87.45020271817428}\n",
      "Iteration 29, Losses: {'ner': 96.53183205861883}\n",
      "Iteration 29, Losses: {'ner': 97.3966291116212}\n",
      "Iteration 29, Losses: {'ner': 97.70233316312209}\n",
      "Iteration 29, Losses: {'ner': 98.61745212847816}\n",
      "Iteration 29, Losses: {'ner': 98.6180614666641}\n",
      "Iteration 29, Losses: {'ner': 108.6695200867354}\n",
      "Iteration 29, Losses: {'ner': 117.95818068899092}\n",
      "Iteration 29, Losses: {'ner': 122.14522203519093}\n",
      "Iteration 29, Losses: {'ner': 122.5262486167159}\n",
      "Iteration 29, Losses: {'ner': 127.02115464576835}\n",
      "Iteration 29, Losses: {'ner': 129.91102544408363}\n",
      "Iteration 29, Losses: {'ner': 138.36096622048356}\n",
      "Iteration 30, Losses: {'ner': 1.4037489386634108e-05}\n",
      "Iteration 30, Losses: {'ner': 10.060897877359466}\n",
      "Iteration 30, Losses: {'ner': 11.521777601365443}\n",
      "Iteration 30, Losses: {'ner': 15.445342993980516}\n",
      "Iteration 30, Losses: {'ner': 17.08158584575288}\n",
      "Iteration 30, Losses: {'ner': 20.843995175498517}\n",
      "Iteration 30, Losses: {'ner': 22.970786566679944}\n",
      "Iteration 30, Losses: {'ner': 26.02190913822997}\n",
      "Iteration 30, Losses: {'ner': 31.821695606060377}\n",
      "Iteration 30, Losses: {'ner': 35.89022309419079}\n",
      "Iteration 30, Losses: {'ner': 35.900452392669884}\n",
      "Iteration 30, Losses: {'ner': 37.72734168699438}\n",
      "Iteration 30, Losses: {'ner': 37.72790072863184}\n",
      "Iteration 30, Losses: {'ner': 65.03503701599149}\n",
      "Iteration 30, Losses: {'ner': 67.69657050951379}\n",
      "Iteration 30, Losses: {'ner': 81.02028514482048}\n",
      "Iteration 30, Losses: {'ner': 85.71197434922715}\n",
      "Iteration 30, Losses: {'ner': 85.7275908689938}\n",
      "Iteration 30, Losses: {'ner': 85.73903186114843}\n",
      "Iteration 30, Losses: {'ner': 98.78798868641671}\n",
      "Iteration 30, Losses: {'ner': 102.5932867223361}\n",
      "Iteration 30, Losses: {'ner': 109.94925207330242}\n",
      "Iteration 30, Losses: {'ner': 115.57372300941934}\n",
      "Iteration 30, Losses: {'ner': 127.07816400534438}\n",
      "Iteration 30, Losses: {'ner': 132.0543641185639}\n",
      "Iteration 30, Losses: {'ner': 147.36999627778562}\n",
      "Iteration 30, Losses: {'ner': 154.03534770308715}\n",
      "Iteration 30, Losses: {'ner': 154.03566904977998}\n",
      "Iteration 30, Losses: {'ner': 156.78231603950292}\n",
      "Iteration 30, Losses: {'ner': 161.86056129250287}\n",
      "Iteration 30, Losses: {'ner': 161.95970781839878}\n",
      "Iteration 31, Losses: {'ner': 9.95361699129486}\n",
      "Iteration 31, Losses: {'ner': 19.51585466741841}\n",
      "Iteration 31, Losses: {'ner': 20.57881891117796}\n",
      "Iteration 31, Losses: {'ner': 20.578841071030073}\n",
      "Iteration 31, Losses: {'ner': 26.261007598366003}\n",
      "Iteration 31, Losses: {'ner': 28.539865149254773}\n",
      "Iteration 31, Losses: {'ner': 30.698616644531622}\n",
      "Iteration 31, Losses: {'ner': 30.85149746933768}\n",
      "Iteration 31, Losses: {'ner': 61.30946450055425}\n",
      "Iteration 31, Losses: {'ner': 72.09301585657602}\n",
      "Iteration 31, Losses: {'ner': 76.44563378690084}\n",
      "Iteration 31, Losses: {'ner': 76.91644148482561}\n",
      "Iteration 31, Losses: {'ner': 87.65161103512571}\n",
      "Iteration 31, Losses: {'ner': 92.99366893452869}\n",
      "Iteration 31, Losses: {'ner': 100.80442931656917}\n",
      "Iteration 31, Losses: {'ner': 108.76436819170159}\n",
      "Iteration 31, Losses: {'ner': 111.74733646641936}\n",
      "Iteration 31, Losses: {'ner': 125.96338469936731}\n",
      "Iteration 31, Losses: {'ner': 125.97331910206044}\n",
      "Iteration 31, Losses: {'ner': 130.56894530893064}\n",
      "Iteration 31, Losses: {'ner': 140.42673331217333}\n",
      "Iteration 31, Losses: {'ner': 145.32450881065995}\n",
      "Iteration 31, Losses: {'ner': 148.47587785915863}\n",
      "Iteration 31, Losses: {'ner': 155.5274781567806}\n",
      "Iteration 31, Losses: {'ner': 155.53017561191552}\n",
      "Iteration 31, Losses: {'ner': 157.99362864593735}\n",
      "Iteration 31, Losses: {'ner': 158.17724645839496}\n",
      "Iteration 31, Losses: {'ner': 159.30201245710887}\n",
      "Iteration 31, Losses: {'ner': 161.44355580325444}\n",
      "Iteration 31, Losses: {'ner': 161.4462961915635}\n",
      "Iteration 31, Losses: {'ner': 161.47297041660718}\n",
      "Iteration 32, Losses: {'ner': 5.440434820335344}\n",
      "Iteration 32, Losses: {'ner': 20.219814227577746}\n",
      "Iteration 32, Losses: {'ner': 20.315823343701634}\n",
      "Iteration 32, Losses: {'ner': 22.762728357763752}\n",
      "Iteration 32, Losses: {'ner': 25.347626019580105}\n",
      "Iteration 32, Losses: {'ner': 40.1454089257382}\n",
      "Iteration 32, Losses: {'ner': 40.14549243875568}\n",
      "Iteration 32, Losses: {'ner': 47.010555083030816}\n",
      "Iteration 32, Losses: {'ner': 49.77550703498841}\n",
      "Iteration 32, Losses: {'ner': 54.372610746620246}\n",
      "Iteration 32, Losses: {'ner': 56.25309517939845}\n",
      "Iteration 32, Losses: {'ner': 56.294976872983916}\n",
      "Iteration 32, Losses: {'ner': 60.86861482684854}\n",
      "Iteration 32, Losses: {'ner': 60.98394592202573}\n",
      "Iteration 32, Losses: {'ner': 65.89967993071103}\n",
      "Iteration 32, Losses: {'ner': 65.9124754496874}\n",
      "Iteration 32, Losses: {'ner': 75.5135175357812}\n",
      "Iteration 32, Losses: {'ner': 76.49036396049723}\n",
      "Iteration 32, Losses: {'ner': 78.44480696037259}\n",
      "Iteration 32, Losses: {'ner': 81.15148234994066}\n",
      "Iteration 32, Losses: {'ner': 82.18204265699784}\n",
      "Iteration 32, Losses: {'ner': 83.45986082106887}\n",
      "Iteration 32, Losses: {'ner': 88.70768307220368}\n",
      "Iteration 32, Losses: {'ner': 91.81858670201825}\n",
      "Iteration 32, Losses: {'ner': 99.29584210293717}\n",
      "Iteration 32, Losses: {'ner': 99.67000623741272}\n",
      "Iteration 32, Losses: {'ner': 99.67107926208888}\n",
      "Iteration 32, Losses: {'ner': 127.23318143414276}\n",
      "Iteration 32, Losses: {'ner': 133.28999486651605}\n",
      "Iteration 32, Losses: {'ner': 136.0128919486525}\n",
      "Iteration 32, Losses: {'ner': 137.9694170108976}\n",
      "Iteration 33, Losses: {'ner': 14.823529395837449}\n",
      "Iteration 33, Losses: {'ner': 16.20108474399728}\n",
      "Iteration 33, Losses: {'ner': 26.47622596933997}\n",
      "Iteration 33, Losses: {'ner': 28.112627566785477}\n",
      "Iteration 33, Losses: {'ner': 33.27950596883723}\n",
      "Iteration 33, Losses: {'ner': 34.61231556074847}\n",
      "Iteration 33, Losses: {'ner': 38.734042164597525}\n",
      "Iteration 33, Losses: {'ner': 43.459551400712606}\n",
      "Iteration 33, Losses: {'ner': 44.135914699796075}\n",
      "Iteration 33, Losses: {'ner': 52.66033875540793}\n",
      "Iteration 33, Losses: {'ner': 52.660394627134465}\n",
      "Iteration 33, Losses: {'ner': 54.10153275517266}\n",
      "Iteration 33, Losses: {'ner': 54.27110468605424}\n",
      "Iteration 33, Losses: {'ner': 58.95159776169846}\n",
      "Iteration 33, Losses: {'ner': 58.97705490659814}\n",
      "Iteration 33, Losses: {'ner': 59.01618384164969}\n",
      "Iteration 33, Losses: {'ner': 66.52803499158975}\n",
      "Iteration 33, Losses: {'ner': 73.65504262790128}\n",
      "Iteration 33, Losses: {'ner': 82.09594056605371}\n",
      "Iteration 33, Losses: {'ner': 87.95668791095467}\n",
      "Iteration 33, Losses: {'ner': 87.96090937113293}\n",
      "Iteration 33, Losses: {'ner': 94.87583732387154}\n",
      "Iteration 33, Losses: {'ner': 97.99453518024796}\n",
      "Iteration 33, Losses: {'ner': 104.17134186029907}\n",
      "Iteration 33, Losses: {'ner': 104.19894480834776}\n",
      "Iteration 33, Losses: {'ner': 112.88718838341782}\n",
      "Iteration 33, Losses: {'ner': 114.74506323834925}\n",
      "Iteration 33, Losses: {'ner': 119.9395823090518}\n",
      "Iteration 33, Losses: {'ner': 121.93665080610654}\n",
      "Iteration 33, Losses: {'ner': 125.39810768576997}\n",
      "Iteration 33, Losses: {'ner': 125.39860737474217}\n",
      "Iteration 34, Losses: {'ner': 3.3493060671409403}\n",
      "Iteration 34, Losses: {'ner': 12.963456336536234}\n",
      "Iteration 34, Losses: {'ner': 13.15755685585059}\n",
      "Iteration 34, Losses: {'ner': 13.520882847393578}\n",
      "Iteration 34, Losses: {'ner': 19.683094947710227}\n",
      "Iteration 34, Losses: {'ner': 23.192347175528756}\n",
      "Iteration 34, Losses: {'ner': 23.192578834904488}\n",
      "Iteration 34, Losses: {'ner': 49.30410177983235}\n",
      "Iteration 34, Losses: {'ner': 51.12203153487706}\n",
      "Iteration 34, Losses: {'ner': 51.122694800428384}\n",
      "Iteration 34, Losses: {'ner': 51.122726877952296}\n",
      "Iteration 34, Losses: {'ner': 60.91682636611072}\n",
      "Iteration 34, Losses: {'ner': 62.1822443505855}\n",
      "Iteration 34, Losses: {'ner': 63.921666761539726}\n",
      "Iteration 34, Losses: {'ner': 64.46596253799758}\n",
      "Iteration 34, Losses: {'ner': 64.60165989956808}\n",
      "Iteration 34, Losses: {'ner': 75.04616929259272}\n",
      "Iteration 34, Losses: {'ner': 75.43359458223121}\n",
      "Iteration 34, Losses: {'ner': 78.47225329651873}\n",
      "Iteration 34, Losses: {'ner': 78.50305867532101}\n",
      "Iteration 34, Losses: {'ner': 78.50340715016833}\n",
      "Iteration 34, Losses: {'ner': 84.61362733782164}\n",
      "Iteration 34, Losses: {'ner': 94.76762843382278}\n",
      "Iteration 34, Losses: {'ner': 105.96958637271939}\n",
      "Iteration 34, Losses: {'ner': 117.5097958124585}\n",
      "Iteration 34, Losses: {'ner': 119.00500046590787}\n",
      "Iteration 34, Losses: {'ner': 119.00502228274628}\n",
      "Iteration 34, Losses: {'ner': 121.15868717847626}\n",
      "Iteration 34, Losses: {'ner': 134.05497314245312}\n",
      "Iteration 34, Losses: {'ner': 139.83068800961283}\n",
      "Iteration 34, Losses: {'ner': 142.62265325145106}\n",
      "Iteration 35, Losses: {'ner': 5.918873120978647}\n",
      "Iteration 35, Losses: {'ner': 6.878064051922983}\n",
      "Iteration 35, Losses: {'ner': 6.878746975447319}\n",
      "Iteration 35, Losses: {'ner': 6.886021320358581}\n",
      "Iteration 35, Losses: {'ner': 8.981356646470074}\n",
      "Iteration 35, Losses: {'ner': 23.96722478975444}\n",
      "Iteration 35, Losses: {'ner': 25.461563855021918}\n",
      "Iteration 35, Losses: {'ner': 31.063250173151673}\n",
      "Iteration 35, Losses: {'ner': 56.331289573842405}\n",
      "Iteration 35, Losses: {'ner': 59.441132349953875}\n",
      "Iteration 35, Losses: {'ner': 68.57594706640866}\n",
      "Iteration 35, Losses: {'ner': 74.98364662768927}\n",
      "Iteration 35, Losses: {'ner': 75.01382639038027}\n",
      "Iteration 35, Losses: {'ner': 75.02678910910437}\n",
      "Iteration 35, Losses: {'ner': 77.77674730526822}\n",
      "Iteration 35, Losses: {'ner': 86.82953108635368}\n",
      "Iteration 35, Losses: {'ner': 93.9801388684472}\n",
      "Iteration 35, Losses: {'ner': 95.04918181144464}\n",
      "Iteration 35, Losses: {'ner': 108.48390211383793}\n",
      "Iteration 35, Losses: {'ner': 114.22040100689284}\n",
      "Iteration 35, Losses: {'ner': 114.221006554787}\n",
      "Iteration 35, Losses: {'ner': 119.44675703021129}\n",
      "Iteration 35, Losses: {'ner': 119.54688971418365}\n",
      "Iteration 35, Losses: {'ner': 126.35709005010733}\n",
      "Iteration 35, Losses: {'ner': 137.6916748949159}\n",
      "Iteration 35, Losses: {'ner': 137.70907755665405}\n",
      "Iteration 35, Losses: {'ner': 141.0150308847389}\n",
      "Iteration 35, Losses: {'ner': 141.24737111603503}\n",
      "Iteration 35, Losses: {'ner': 141.6517012127261}\n",
      "Iteration 35, Losses: {'ner': 143.703898792263}\n",
      "Iteration 35, Losses: {'ner': 146.75209279142945}\n",
      "Iteration 36, Losses: {'ner': 4.024486714960488}\n",
      "Iteration 36, Losses: {'ner': 4.024496507681201}\n",
      "Iteration 36, Losses: {'ner': 7.1473415194368215}\n",
      "Iteration 36, Losses: {'ner': 7.15929250944497}\n",
      "Iteration 36, Losses: {'ner': 11.913791467483804}\n",
      "Iteration 36, Losses: {'ner': 18.905303350664095}\n",
      "Iteration 36, Losses: {'ner': 25.6669884296794}\n",
      "Iteration 36, Losses: {'ner': 26.91389751794775}\n",
      "Iteration 36, Losses: {'ner': 26.914017748181667}\n",
      "Iteration 36, Losses: {'ner': 39.843578051062465}\n",
      "Iteration 36, Losses: {'ner': 69.6813571886798}\n",
      "Iteration 36, Losses: {'ner': 72.33279048892578}\n",
      "Iteration 36, Losses: {'ner': 72.50174804280557}\n",
      "Iteration 36, Losses: {'ner': 76.04827883027558}\n",
      "Iteration 36, Losses: {'ner': 79.92246187583116}\n",
      "Iteration 36, Losses: {'ner': 79.93565439466474}\n",
      "Iteration 36, Losses: {'ner': 83.86295841548805}\n",
      "Iteration 36, Losses: {'ner': 83.86298168685016}\n",
      "Iteration 36, Losses: {'ner': 87.3092990722963}\n",
      "Iteration 36, Losses: {'ner': 88.56238214587759}\n",
      "Iteration 36, Losses: {'ner': 88.96345489492586}\n",
      "Iteration 36, Losses: {'ner': 88.97135797610578}\n",
      "Iteration 36, Losses: {'ner': 91.3784692895224}\n",
      "Iteration 36, Losses: {'ner': 91.44747397758856}\n",
      "Iteration 36, Losses: {'ner': 100.35088058743831}\n",
      "Iteration 36, Losses: {'ner': 108.18938690918982}\n",
      "Iteration 36, Losses: {'ner': 108.189837316216}\n",
      "Iteration 36, Losses: {'ner': 120.83828278568794}\n",
      "Iteration 36, Losses: {'ner': 120.881898665535}\n",
      "Iteration 36, Losses: {'ner': 121.03626170762706}\n",
      "Iteration 36, Losses: {'ner': 126.66599674233905}\n",
      "Iteration 37, Losses: {'ner': 3.1628334826553264}\n",
      "Iteration 37, Losses: {'ner': 3.16329647550102}\n",
      "Iteration 37, Losses: {'ner': 3.1633045528804637}\n",
      "Iteration 37, Losses: {'ner': 10.089137091962286}\n",
      "Iteration 37, Losses: {'ner': 10.089522520115462}\n",
      "Iteration 37, Losses: {'ner': 10.135101149118963}\n",
      "Iteration 37, Losses: {'ner': 10.13528301531549}\n",
      "Iteration 37, Losses: {'ner': 10.13529043700781}\n",
      "Iteration 37, Losses: {'ner': 37.11876695958091}\n",
      "Iteration 37, Losses: {'ner': 37.11877000332681}\n",
      "Iteration 37, Losses: {'ner': 37.770442049629814}\n",
      "Iteration 37, Losses: {'ner': 40.37530509143702}\n",
      "Iteration 37, Losses: {'ner': 46.59634223214521}\n",
      "Iteration 37, Losses: {'ner': 52.70818808760693}\n",
      "Iteration 37, Losses: {'ner': 52.8111475247876}\n",
      "Iteration 37, Losses: {'ner': 52.877789641518206}\n",
      "Iteration 37, Losses: {'ner': 55.10560187678786}\n",
      "Iteration 37, Losses: {'ner': 58.38701345689725}\n",
      "Iteration 37, Losses: {'ner': 74.00207475800765}\n",
      "Iteration 37, Losses: {'ner': 74.00511738787685}\n",
      "Iteration 37, Losses: {'ner': 81.82262647481282}\n",
      "Iteration 37, Losses: {'ner': 88.10799147241237}\n",
      "Iteration 37, Losses: {'ner': 92.8772370926493}\n",
      "Iteration 37, Losses: {'ner': 93.10877370853053}\n",
      "Iteration 37, Losses: {'ner': 104.22978861936394}\n",
      "Iteration 37, Losses: {'ner': 105.2217499799087}\n",
      "Iteration 37, Losses: {'ner': 110.40410422428454}\n",
      "Iteration 37, Losses: {'ner': 112.08218377389726}\n",
      "Iteration 37, Losses: {'ner': 126.88687787970962}\n",
      "Iteration 37, Losses: {'ner': 126.887961942486}\n",
      "Iteration 37, Losses: {'ner': 137.15676844452685}\n",
      "Iteration 38, Losses: {'ner': 0.5613602936473191}\n",
      "Iteration 38, Losses: {'ner': 8.95784944062597}\n",
      "Iteration 38, Losses: {'ner': 11.679951090966902}\n",
      "Iteration 38, Losses: {'ner': 11.692520105416046}\n",
      "Iteration 38, Losses: {'ner': 14.373498474389525}\n",
      "Iteration 38, Losses: {'ner': 15.411603108595267}\n",
      "Iteration 38, Losses: {'ner': 15.654524547012976}\n",
      "Iteration 38, Losses: {'ner': 19.072964541956612}\n",
      "Iteration 38, Losses: {'ner': 22.45193670616423}\n",
      "Iteration 38, Losses: {'ner': 22.45712505391664}\n",
      "Iteration 38, Losses: {'ner': 25.72626019220038}\n",
      "Iteration 38, Losses: {'ner': 26.060066107822585}\n",
      "Iteration 38, Losses: {'ner': 26.072746773227358}\n",
      "Iteration 38, Losses: {'ner': 28.082870888124205}\n",
      "Iteration 38, Losses: {'ner': 28.082875723988458}\n",
      "Iteration 38, Losses: {'ner': 33.46957981086664}\n",
      "Iteration 38, Losses: {'ner': 33.497988957510714}\n",
      "Iteration 38, Losses: {'ner': 33.50599149578107}\n",
      "Iteration 38, Losses: {'ner': 45.59637975755838}\n",
      "Iteration 38, Losses: {'ner': 45.598531001528734}\n",
      "Iteration 38, Losses: {'ner': 45.598533067405235}\n",
      "Iteration 38, Losses: {'ner': 51.741610264905454}\n",
      "Iteration 38, Losses: {'ner': 80.00817822948592}\n",
      "Iteration 38, Losses: {'ner': 92.53509790018757}\n",
      "Iteration 38, Losses: {'ner': 100.49241448043807}\n",
      "Iteration 38, Losses: {'ner': 106.1179502939645}\n",
      "Iteration 38, Losses: {'ner': 118.4656348921245}\n",
      "Iteration 38, Losses: {'ner': 120.86277625122116}\n",
      "Iteration 38, Losses: {'ner': 121.04417357816133}\n",
      "Iteration 38, Losses: {'ner': 121.07986681807442}\n",
      "Iteration 38, Losses: {'ner': 126.21245121052769}\n",
      "Iteration 39, Losses: {'ner': 3.45485273558484}\n",
      "Iteration 39, Losses: {'ner': 4.354729967881354}\n",
      "Iteration 39, Losses: {'ner': 9.933993193896821}\n",
      "Iteration 39, Losses: {'ner': 15.711368301691234}\n",
      "Iteration 39, Losses: {'ner': 16.009841370707935}\n",
      "Iteration 39, Losses: {'ner': 16.009844397728035}\n",
      "Iteration 39, Losses: {'ner': 16.60132704933307}\n",
      "Iteration 39, Losses: {'ner': 16.763570915271206}\n",
      "Iteration 39, Losses: {'ner': 19.695674438330762}\n",
      "Iteration 39, Losses: {'ner': 19.96933513045736}\n",
      "Iteration 39, Losses: {'ner': 19.988972984120803}\n",
      "Iteration 39, Losses: {'ner': 28.433708808153604}\n",
      "Iteration 39, Losses: {'ner': 28.44110369635956}\n",
      "Iteration 39, Losses: {'ner': 29.310282095805338}\n",
      "Iteration 39, Losses: {'ner': 40.41459181952516}\n",
      "Iteration 39, Losses: {'ner': 56.82429908162625}\n",
      "Iteration 39, Losses: {'ner': 60.60927521074613}\n",
      "Iteration 39, Losses: {'ner': 67.82898038164745}\n",
      "Iteration 39, Losses: {'ner': 75.3965975965972}\n",
      "Iteration 39, Losses: {'ner': 80.64112722098207}\n",
      "Iteration 39, Losses: {'ner': 82.64636515425823}\n",
      "Iteration 39, Losses: {'ner': 82.65298587644648}\n",
      "Iteration 39, Losses: {'ner': 82.65380741560509}\n",
      "Iteration 39, Losses: {'ner': 87.60035922786011}\n",
      "Iteration 39, Losses: {'ner': 88.13876552714287}\n",
      "Iteration 39, Losses: {'ner': 88.13899298121325}\n",
      "Iteration 39, Losses: {'ner': 88.13975056231705}\n",
      "Iteration 39, Losses: {'ner': 88.80369521532347}\n",
      "Iteration 39, Losses: {'ner': 89.59713351129427}\n",
      "Iteration 39, Losses: {'ner': 94.0683486488208}\n",
      "Iteration 39, Losses: {'ner': 105.12569680208803}\n",
      "Iteration 40, Losses: {'ner': 7.970275712843827}\n",
      "Iteration 40, Losses: {'ner': 11.021135565664414}\n",
      "Iteration 40, Losses: {'ner': 20.550593555719892}\n",
      "Iteration 40, Losses: {'ner': 39.58842496326372}\n",
      "Iteration 40, Losses: {'ner': 44.35788346404377}\n",
      "Iteration 40, Losses: {'ner': 44.478220053302834}\n",
      "Iteration 40, Losses: {'ner': 46.34985054841592}\n",
      "Iteration 40, Losses: {'ner': 46.349873392733805}\n",
      "Iteration 40, Losses: {'ner': 46.34993236149041}\n",
      "Iteration 40, Losses: {'ner': 51.85885783283047}\n",
      "Iteration 40, Losses: {'ner': 54.41895582153799}\n",
      "Iteration 40, Losses: {'ner': 54.46774214799631}\n",
      "Iteration 40, Losses: {'ner': 58.02847885064683}\n",
      "Iteration 40, Losses: {'ner': 58.18137808729325}\n",
      "Iteration 40, Losses: {'ner': 58.91745193276119}\n",
      "Iteration 40, Losses: {'ner': 58.93375532556222}\n",
      "Iteration 40, Losses: {'ner': 59.00302216919799}\n",
      "Iteration 40, Losses: {'ner': 64.54699411305693}\n",
      "Iteration 40, Losses: {'ner': 73.6707262995512}\n",
      "Iteration 40, Losses: {'ner': 76.05857284707167}\n",
      "Iteration 40, Losses: {'ner': 77.16248612682749}\n",
      "Iteration 40, Losses: {'ner': 77.17415054079706}\n",
      "Iteration 40, Losses: {'ner': 79.56282246110914}\n",
      "Iteration 40, Losses: {'ner': 79.5905256961988}\n",
      "Iteration 40, Losses: {'ner': 92.81129314392005}\n",
      "Iteration 40, Losses: {'ner': 96.56705934614685}\n",
      "Iteration 40, Losses: {'ner': 103.25763069252214}\n",
      "Iteration 40, Losses: {'ner': 103.25770146100382}\n",
      "Iteration 40, Losses: {'ner': 103.25968200064351}\n",
      "Iteration 40, Losses: {'ner': 110.94924117661768}\n",
      "Iteration 40, Losses: {'ner': 115.796193287728}\n",
      "Iteration 41, Losses: {'ner': 2.0944777627741757}\n",
      "Iteration 41, Losses: {'ner': 2.1235886181149466}\n",
      "Iteration 41, Losses: {'ner': 2.2729530182684194}\n",
      "Iteration 41, Losses: {'ner': 15.677935722230737}\n",
      "Iteration 41, Losses: {'ner': 16.366441848340735}\n",
      "Iteration 41, Losses: {'ner': 20.09654097073538}\n",
      "Iteration 41, Losses: {'ner': 20.096548451704223}\n",
      "Iteration 41, Losses: {'ner': 20.88864346519939}\n",
      "Iteration 41, Losses: {'ner': 20.907340882504847}\n",
      "Iteration 41, Losses: {'ner': 23.726136833754182}\n",
      "Iteration 41, Losses: {'ner': 31.4113586414062}\n",
      "Iteration 41, Losses: {'ner': 32.98029046923375}\n",
      "Iteration 41, Losses: {'ner': 32.98596554245505}\n",
      "Iteration 41, Losses: {'ner': 33.11424404215762}\n",
      "Iteration 41, Losses: {'ner': 33.162026455645545}\n",
      "Iteration 41, Losses: {'ner': 33.746786601427345}\n",
      "Iteration 41, Losses: {'ner': 36.367839008017825}\n",
      "Iteration 41, Losses: {'ner': 36.40296631586532}\n",
      "Iteration 41, Losses: {'ner': 40.65752227016994}\n",
      "Iteration 41, Losses: {'ner': 45.334955892592724}\n",
      "Iteration 41, Losses: {'ner': 45.334956757816876}\n",
      "Iteration 41, Losses: {'ner': 52.486974252963826}\n",
      "Iteration 41, Losses: {'ner': 56.09048473684095}\n",
      "Iteration 41, Losses: {'ner': 56.09236800534547}\n",
      "Iteration 41, Losses: {'ner': 56.0931913340683}\n",
      "Iteration 41, Losses: {'ner': 64.63004336591058}\n",
      "Iteration 41, Losses: {'ner': 64.64967171760308}\n",
      "Iteration 41, Losses: {'ner': 70.31012473532103}\n",
      "Iteration 41, Losses: {'ner': 71.76062843265997}\n",
      "Iteration 41, Losses: {'ner': 72.63000337964615}\n",
      "Iteration 41, Losses: {'ner': 80.11133426895518}\n",
      "Iteration 42, Losses: {'ner': 8.638535384120406}\n",
      "Iteration 42, Losses: {'ner': 9.112716620130076}\n",
      "Iteration 42, Losses: {'ner': 9.614007014265212}\n",
      "Iteration 42, Losses: {'ner': 9.615244852369607}\n",
      "Iteration 42, Losses: {'ner': 9.61524517761874}\n",
      "Iteration 42, Losses: {'ner': 9.615856021926241}\n",
      "Iteration 42, Losses: {'ner': 12.677995745648339}\n",
      "Iteration 42, Losses: {'ner': 12.92497006146064}\n",
      "Iteration 42, Losses: {'ner': 25.724153506081095}\n",
      "Iteration 42, Losses: {'ner': 34.30916535823076}\n",
      "Iteration 42, Losses: {'ner': 34.31000830397305}\n",
      "Iteration 42, Losses: {'ner': 37.074697213632795}\n",
      "Iteration 42, Losses: {'ner': 37.07554951531674}\n",
      "Iteration 42, Losses: {'ner': 37.07571904329732}\n",
      "Iteration 42, Losses: {'ner': 40.76188810804424}\n",
      "Iteration 42, Losses: {'ner': 46.66920783698914}\n",
      "Iteration 42, Losses: {'ner': 46.6742472597345}\n",
      "Iteration 42, Losses: {'ner': 47.334009332008016}\n",
      "Iteration 42, Losses: {'ner': 47.34412121601153}\n",
      "Iteration 42, Losses: {'ner': 48.29359912109738}\n",
      "Iteration 42, Losses: {'ner': 52.081846355076536}\n",
      "Iteration 42, Losses: {'ner': 52.32077173251288}\n",
      "Iteration 42, Losses: {'ner': 55.58686580047128}\n",
      "Iteration 42, Losses: {'ner': 58.58290907287183}\n",
      "Iteration 42, Losses: {'ner': 60.71219257185212}\n",
      "Iteration 42, Losses: {'ner': 69.4024358694827}\n",
      "Iteration 42, Losses: {'ner': 69.40253629271824}\n",
      "Iteration 42, Losses: {'ner': 79.7097465489789}\n",
      "Iteration 42, Losses: {'ner': 105.14672813744563}\n",
      "Iteration 42, Losses: {'ner': 111.91633841493007}\n",
      "Iteration 42, Losses: {'ner': 111.92466824753609}\n",
      "Iteration 43, Losses: {'ner': 8.843407801627611}\n",
      "Iteration 43, Losses: {'ner': 14.841740064273942}\n",
      "Iteration 43, Losses: {'ner': 14.868150158144449}\n",
      "Iteration 43, Losses: {'ner': 18.514355804654315}\n",
      "Iteration 43, Losses: {'ner': 18.626796553831916}\n",
      "Iteration 43, Losses: {'ner': 27.691578253497394}\n",
      "Iteration 43, Losses: {'ner': 34.256953117529065}\n",
      "Iteration 43, Losses: {'ner': 34.35848319291768}\n",
      "Iteration 43, Losses: {'ner': 35.91769031721486}\n",
      "Iteration 43, Losses: {'ner': 35.91769810126634}\n",
      "Iteration 43, Losses: {'ner': 41.23809196056468}\n",
      "Iteration 43, Losses: {'ner': 41.28911025655377}\n",
      "Iteration 43, Losses: {'ner': 44.10013363250057}\n",
      "Iteration 43, Losses: {'ner': 49.07260692765202}\n",
      "Iteration 43, Losses: {'ner': 75.58964867279376}\n",
      "Iteration 43, Losses: {'ner': 75.8783157083409}\n",
      "Iteration 43, Losses: {'ner': 78.6052557137051}\n",
      "Iteration 43, Losses: {'ner': 79.76231011294746}\n",
      "Iteration 43, Losses: {'ner': 79.76457743755469}\n",
      "Iteration 43, Losses: {'ner': 80.34595854139488}\n",
      "Iteration 43, Losses: {'ner': 91.12789673489213}\n",
      "Iteration 43, Losses: {'ner': 91.12790456864042}\n",
      "Iteration 43, Losses: {'ner': 91.12810588404123}\n",
      "Iteration 43, Losses: {'ner': 96.57802756181842}\n",
      "Iteration 43, Losses: {'ner': 103.64633513510687}\n",
      "Iteration 43, Losses: {'ner': 103.64633814868597}\n",
      "Iteration 43, Losses: {'ner': 106.94189431913374}\n",
      "Iteration 43, Losses: {'ner': 109.86196767162603}\n",
      "Iteration 43, Losses: {'ner': 109.86387249775386}\n",
      "Iteration 43, Losses: {'ner': 110.21816286784399}\n",
      "Iteration 43, Losses: {'ner': 110.91355973969209}\n",
      "Iteration 44, Losses: {'ner': 4.371477968130158}\n",
      "Iteration 44, Losses: {'ner': 6.504178066019201}\n",
      "Iteration 44, Losses: {'ner': 6.555725271181517}\n",
      "Iteration 44, Losses: {'ner': 6.602304773757095}\n",
      "Iteration 44, Losses: {'ner': 10.93477529459162}\n",
      "Iteration 44, Losses: {'ner': 17.37790501362411}\n",
      "Iteration 44, Losses: {'ner': 41.32196719568651}\n",
      "Iteration 44, Losses: {'ner': 41.46789116057391}\n",
      "Iteration 44, Losses: {'ner': 42.16547506677112}\n",
      "Iteration 44, Losses: {'ner': 42.20049091903212}\n",
      "Iteration 44, Losses: {'ner': 42.200512102077944}\n",
      "Iteration 44, Losses: {'ner': 42.20051250561807}\n",
      "Iteration 44, Losses: {'ner': 42.20448931803876}\n",
      "Iteration 44, Losses: {'ner': 42.20449821170591}\n",
      "Iteration 44, Losses: {'ner': 50.433012818920815}\n",
      "Iteration 44, Losses: {'ner': 54.46883405307744}\n",
      "Iteration 44, Losses: {'ner': 54.46891319264285}\n",
      "Iteration 44, Losses: {'ner': 58.14040859835862}\n",
      "Iteration 44, Losses: {'ner': 58.14049784667559}\n",
      "Iteration 44, Losses: {'ner': 58.14049811156591}\n",
      "Iteration 44, Losses: {'ner': 58.702758853129325}\n",
      "Iteration 44, Losses: {'ner': 60.80572953739215}\n",
      "Iteration 44, Losses: {'ner': 62.97752453301788}\n",
      "Iteration 44, Losses: {'ner': 63.15829322115642}\n",
      "Iteration 44, Losses: {'ner': 70.14552444549169}\n",
      "Iteration 44, Losses: {'ner': 70.1455244608342}\n",
      "Iteration 44, Losses: {'ner': 70.17675957502198}\n",
      "Iteration 44, Losses: {'ner': 76.2147583632653}\n",
      "Iteration 44, Losses: {'ner': 80.24955589275}\n",
      "Iteration 44, Losses: {'ner': 82.56835880257645}\n",
      "Iteration 44, Losses: {'ner': 89.81410348843964}\n",
      "Iteration 45, Losses: {'ner': 0.9751850006892919}\n",
      "Iteration 45, Losses: {'ner': 0.9786543887820084}\n",
      "Iteration 45, Losses: {'ner': 0.9794278002807403}\n",
      "Iteration 45, Losses: {'ner': 1.086172042122705}\n",
      "Iteration 45, Losses: {'ner': 1.0862015552124566}\n",
      "Iteration 45, Losses: {'ner': 2.0990926238780885}\n",
      "Iteration 45, Losses: {'ner': 2.099093546846889}\n",
      "Iteration 45, Losses: {'ner': 2.3307976247603994}\n",
      "Iteration 45, Losses: {'ner': 12.302209494873377}\n",
      "Iteration 45, Losses: {'ner': 17.654234393210388}\n",
      "Iteration 45, Losses: {'ner': 17.654245548671437}\n",
      "Iteration 45, Losses: {'ner': 23.499285693554857}\n",
      "Iteration 45, Losses: {'ner': 29.429419337209122}\n",
      "Iteration 45, Losses: {'ner': 38.03211712588673}\n",
      "Iteration 45, Losses: {'ner': 47.69351862731039}\n",
      "Iteration 45, Losses: {'ner': 47.826754591296044}\n",
      "Iteration 45, Losses: {'ner': 55.95852224703479}\n",
      "Iteration 45, Losses: {'ner': 64.19676420491533}\n",
      "Iteration 45, Losses: {'ner': 64.58703852916507}\n",
      "Iteration 45, Losses: {'ner': 68.93667055345355}\n",
      "Iteration 45, Losses: {'ner': 68.93669928094107}\n",
      "Iteration 45, Losses: {'ner': 70.9135632699612}\n",
      "Iteration 45, Losses: {'ner': 71.83640708229574}\n",
      "Iteration 45, Losses: {'ner': 72.4921800791221}\n",
      "Iteration 45, Losses: {'ner': 81.70068434414878}\n",
      "Iteration 45, Losses: {'ner': 95.27047763611152}\n",
      "Iteration 45, Losses: {'ner': 96.70089536228741}\n",
      "Iteration 45, Losses: {'ner': 97.51463131720755}\n",
      "Iteration 45, Losses: {'ner': 97.51973756677347}\n",
      "Iteration 45, Losses: {'ner': 100.855755220245}\n",
      "Iteration 45, Losses: {'ner': 106.8966249863053}\n",
      "Iteration 46, Losses: {'ner': 9.043035073272526}\n",
      "Iteration 46, Losses: {'ner': 9.048965951232582}\n",
      "Iteration 46, Losses: {'ner': 14.966998600237487}\n",
      "Iteration 46, Losses: {'ner': 15.067116102269276}\n",
      "Iteration 46, Losses: {'ner': 15.099470696086597}\n",
      "Iteration 46, Losses: {'ner': 15.139550628658371}\n",
      "Iteration 46, Losses: {'ner': 16.144421582105277}\n",
      "Iteration 46, Losses: {'ner': 20.81245661725889}\n",
      "Iteration 46, Losses: {'ner': 32.979453237632896}\n",
      "Iteration 46, Losses: {'ner': 33.41373695637123}\n",
      "Iteration 46, Losses: {'ner': 33.44103984337437}\n",
      "Iteration 46, Losses: {'ner': 36.35337112664673}\n",
      "Iteration 46, Losses: {'ner': 36.35449728180172}\n",
      "Iteration 46, Losses: {'ner': 42.8571515057567}\n",
      "Iteration 46, Losses: {'ner': 46.05995116283452}\n",
      "Iteration 46, Losses: {'ner': 64.09498526238411}\n",
      "Iteration 46, Losses: {'ner': 67.32778496051924}\n",
      "Iteration 46, Losses: {'ner': 67.32778667076758}\n",
      "Iteration 46, Losses: {'ner': 72.12764760006856}\n",
      "Iteration 46, Losses: {'ner': 72.12765263034103}\n",
      "Iteration 46, Losses: {'ner': 72.7178672144014}\n",
      "Iteration 46, Losses: {'ner': 72.71806200133106}\n",
      "Iteration 46, Losses: {'ner': 72.71850357528245}\n",
      "Iteration 46, Losses: {'ner': 79.49627546361191}\n",
      "Iteration 46, Losses: {'ner': 90.37322175396669}\n",
      "Iteration 46, Losses: {'ner': 90.55511875863674}\n",
      "Iteration 46, Losses: {'ner': 99.97209597970439}\n",
      "Iteration 46, Losses: {'ner': 100.20198463443725}\n",
      "Iteration 46, Losses: {'ner': 100.20942559744408}\n",
      "Iteration 46, Losses: {'ner': 100.71036517842037}\n",
      "Iteration 46, Losses: {'ner': 106.63628810723799}\n",
      "Iteration 47, Losses: {'ner': 7.071001866255998e-07}\n",
      "Iteration 47, Losses: {'ner': 0.0009058583766070014}\n",
      "Iteration 47, Losses: {'ner': 3.371384108199097}\n",
      "Iteration 47, Losses: {'ner': 10.229212427022262}\n",
      "Iteration 47, Losses: {'ner': 30.94685056725107}\n",
      "Iteration 47, Losses: {'ner': 38.65767246735598}\n",
      "Iteration 47, Losses: {'ner': 42.521746037532374}\n",
      "Iteration 47, Losses: {'ner': 43.96004564769532}\n",
      "Iteration 47, Losses: {'ner': 43.960078484508465}\n",
      "Iteration 47, Losses: {'ner': 43.961468324283366}\n",
      "Iteration 47, Losses: {'ner': 47.56939013939786}\n",
      "Iteration 47, Losses: {'ner': 60.03236831226754}\n",
      "Iteration 47, Losses: {'ner': 60.03236941117608}\n",
      "Iteration 47, Losses: {'ner': 60.206420179361295}\n",
      "Iteration 47, Losses: {'ner': 63.965715632454646}\n",
      "Iteration 47, Losses: {'ner': 73.25173070020347}\n",
      "Iteration 47, Losses: {'ner': 73.29851370625092}\n",
      "Iteration 47, Losses: {'ner': 74.26199603957183}\n",
      "Iteration 47, Losses: {'ner': 75.18643978585871}\n",
      "Iteration 47, Losses: {'ner': 75.73372813049158}\n",
      "Iteration 47, Losses: {'ner': 75.9205615175715}\n",
      "Iteration 47, Losses: {'ner': 79.62049902015386}\n",
      "Iteration 47, Losses: {'ner': 89.35060865387766}\n",
      "Iteration 47, Losses: {'ner': 93.34184033575208}\n",
      "Iteration 47, Losses: {'ner': 94.83081576813868}\n",
      "Iteration 47, Losses: {'ner': 96.46177684717152}\n",
      "Iteration 47, Losses: {'ner': 103.0375216058641}\n",
      "Iteration 47, Losses: {'ner': 103.06217895762737}\n",
      "Iteration 47, Losses: {'ner': 104.80628478601784}\n",
      "Iteration 47, Losses: {'ner': 104.80954691325668}\n",
      "Iteration 47, Losses: {'ner': 104.88837624973831}\n",
      "Iteration 48, Losses: {'ner': 0.00033276222458522385}\n",
      "Iteration 48, Losses: {'ner': 7.258289728783678}\n",
      "Iteration 48, Losses: {'ner': 10.25053290794894}\n",
      "Iteration 48, Losses: {'ner': 10.256184711867391}\n",
      "Iteration 48, Losses: {'ner': 17.421531017181504}\n",
      "Iteration 48, Losses: {'ner': 17.42261042221413}\n",
      "Iteration 48, Losses: {'ner': 17.422626477052184}\n",
      "Iteration 48, Losses: {'ner': 17.423551000234898}\n",
      "Iteration 48, Losses: {'ner': 17.423584683612884}\n",
      "Iteration 48, Losses: {'ner': 17.42364843956936}\n",
      "Iteration 48, Losses: {'ner': 17.423671792626088}\n",
      "Iteration 48, Losses: {'ner': 32.16118892729355}\n",
      "Iteration 48, Losses: {'ner': 32.16205366808017}\n",
      "Iteration 48, Losses: {'ner': 44.12374329775725}\n",
      "Iteration 48, Losses: {'ner': 47.33346779021426}\n",
      "Iteration 48, Losses: {'ner': 48.85301602818065}\n",
      "Iteration 48, Losses: {'ner': 55.164017505092204}\n",
      "Iteration 48, Losses: {'ner': 55.65103793878162}\n",
      "Iteration 48, Losses: {'ner': 55.6561919948009}\n",
      "Iteration 48, Losses: {'ner': 57.8742690191893}\n",
      "Iteration 48, Losses: {'ner': 57.8743155158206}\n",
      "Iteration 48, Losses: {'ner': 61.605715353380425}\n",
      "Iteration 48, Losses: {'ner': 65.11965373070244}\n",
      "Iteration 48, Losses: {'ner': 86.64403105508296}\n",
      "Iteration 48, Losses: {'ner': 86.64917456360874}\n",
      "Iteration 48, Losses: {'ner': 91.70930262607942}\n",
      "Iteration 48, Losses: {'ner': 96.98468446192729}\n",
      "Iteration 48, Losses: {'ner': 98.40762987273942}\n",
      "Iteration 48, Losses: {'ner': 98.40997758152521}\n",
      "Iteration 48, Losses: {'ner': 99.13019952738303}\n",
      "Iteration 48, Losses: {'ner': 109.87789656743008}\n",
      "Iteration 49, Losses: {'ner': 0.00012312554117948973}\n",
      "Iteration 49, Losses: {'ner': 3.4886165512704075}\n",
      "Iteration 49, Losses: {'ner': 3.488787914631951}\n",
      "Iteration 49, Losses: {'ner': 4.6531777516328425}\n",
      "Iteration 49, Losses: {'ner': 6.981043209402763}\n",
      "Iteration 49, Losses: {'ner': 6.981206680420112}\n",
      "Iteration 49, Losses: {'ner': 7.032035161681577}\n",
      "Iteration 49, Losses: {'ner': 7.4327511386954646}\n",
      "Iteration 49, Losses: {'ner': 15.419789716616876}\n",
      "Iteration 49, Losses: {'ner': 22.703570008725187}\n",
      "Iteration 49, Losses: {'ner': 30.762931993605953}\n",
      "Iteration 49, Losses: {'ner': 30.762931998910734}\n",
      "Iteration 49, Losses: {'ner': 33.81998703340311}\n",
      "Iteration 49, Losses: {'ner': 35.74547072515776}\n",
      "Iteration 49, Losses: {'ner': 41.09769869599294}\n",
      "Iteration 49, Losses: {'ner': 41.09940749072391}\n",
      "Iteration 49, Losses: {'ner': 41.099407662774965}\n",
      "Iteration 49, Losses: {'ner': 69.74268743760581}\n",
      "Iteration 49, Losses: {'ner': 69.93067927481576}\n",
      "Iteration 49, Losses: {'ner': 75.08608288446466}\n",
      "Iteration 49, Losses: {'ner': 76.28765725535457}\n",
      "Iteration 49, Losses: {'ner': 77.97388269008968}\n",
      "Iteration 49, Losses: {'ner': 78.04230998782323}\n",
      "Iteration 49, Losses: {'ner': 78.04245121729336}\n",
      "Iteration 49, Losses: {'ner': 78.29408587286302}\n",
      "Iteration 49, Losses: {'ner': 83.5783903920031}\n",
      "Iteration 49, Losses: {'ner': 83.57845416117496}\n",
      "Iteration 49, Losses: {'ner': 93.73346484358667}\n",
      "Iteration 49, Losses: {'ner': 93.73346649355129}\n",
      "Iteration 49, Losses: {'ner': 96.00594114979017}\n",
      "Iteration 49, Losses: {'ner': 96.00598636633279}\n",
      "Iteration 50, Losses: {'ner': 9.033673939710411}\n",
      "Iteration 50, Losses: {'ner': 11.741552012593177}\n",
      "Iteration 50, Losses: {'ner': 18.055978443591563}\n",
      "Iteration 50, Losses: {'ner': 22.92100150024521}\n",
      "Iteration 50, Losses: {'ner': 31.562915939104876}\n",
      "Iteration 50, Losses: {'ner': 31.562915946223697}\n",
      "Iteration 50, Losses: {'ner': 31.6180783517285}\n",
      "Iteration 50, Losses: {'ner': 31.80359870060536}\n",
      "Iteration 50, Losses: {'ner': 31.803727445095543}\n",
      "Iteration 50, Losses: {'ner': 31.804396335165155}\n",
      "Iteration 50, Losses: {'ner': 34.99078007644778}\n",
      "Iteration 50, Losses: {'ner': 38.19763680179508}\n",
      "Iteration 50, Losses: {'ner': 41.51068432012208}\n",
      "Iteration 50, Losses: {'ner': 41.51068433915458}\n",
      "Iteration 50, Losses: {'ner': 41.7672148151412}\n",
      "Iteration 50, Losses: {'ner': 45.0109123796166}\n",
      "Iteration 50, Losses: {'ner': 50.00859988674968}\n",
      "Iteration 50, Losses: {'ner': 58.44442993080902}\n",
      "Iteration 50, Losses: {'ner': 58.44443238565568}\n",
      "Iteration 50, Losses: {'ner': 58.655909307227354}\n",
      "Iteration 50, Losses: {'ner': 68.01575868219858}\n",
      "Iteration 50, Losses: {'ner': 69.51596742737298}\n",
      "Iteration 50, Losses: {'ner': 69.51597929605863}\n",
      "Iteration 50, Losses: {'ner': 69.51608650079437}\n",
      "Iteration 50, Losses: {'ner': 72.43158539843473}\n",
      "Iteration 50, Losses: {'ner': 72.4752700637784}\n",
      "Iteration 50, Losses: {'ner': 85.83516992287171}\n",
      "Iteration 50, Losses: {'ner': 90.17574165764938}\n",
      "Iteration 50, Losses: {'ner': 92.88596479584886}\n",
      "Iteration 50, Losses: {'ner': 94.60979380018203}\n",
      "Iteration 50, Losses: {'ner': 96.24079922330714}\n",
      "Iteration 51, Losses: {'ner': 1.1390352512334576}\n",
      "Iteration 51, Losses: {'ner': 5.354745078029092}\n",
      "Iteration 51, Losses: {'ner': 5.355494338345876}\n",
      "Iteration 51, Losses: {'ner': 10.864583831564167}\n",
      "Iteration 51, Losses: {'ner': 11.74784197116521}\n",
      "Iteration 51, Losses: {'ner': 11.74797865488598}\n",
      "Iteration 51, Losses: {'ner': 13.67190195000812}\n",
      "Iteration 51, Losses: {'ner': 14.296372198709753}\n",
      "Iteration 51, Losses: {'ner': 16.11616955789159}\n",
      "Iteration 51, Losses: {'ner': 18.859317410429526}\n",
      "Iteration 51, Losses: {'ner': 18.859325844667513}\n",
      "Iteration 51, Losses: {'ner': 18.85941523141}\n",
      "Iteration 51, Losses: {'ner': 18.867415370766775}\n",
      "Iteration 51, Losses: {'ner': 23.09393989867722}\n",
      "Iteration 51, Losses: {'ner': 26.55919988357528}\n",
      "Iteration 51, Losses: {'ner': 29.855146407097962}\n",
      "Iteration 51, Losses: {'ner': 30.76292216325228}\n",
      "Iteration 51, Losses: {'ner': 36.76336700670951}\n",
      "Iteration 51, Losses: {'ner': 36.96149449148643}\n",
      "Iteration 51, Losses: {'ner': 42.11222749099174}\n",
      "Iteration 51, Losses: {'ner': 46.108764855930495}\n",
      "Iteration 51, Losses: {'ner': 50.2656001651125}\n",
      "Iteration 51, Losses: {'ner': 50.26590471418676}\n",
      "Iteration 51, Losses: {'ner': 50.2724840761634}\n",
      "Iteration 51, Losses: {'ner': 56.64084222536952}\n",
      "Iteration 51, Losses: {'ner': 70.79171861846031}\n",
      "Iteration 51, Losses: {'ner': 78.92274823095633}\n",
      "Iteration 51, Losses: {'ner': 78.9552703285382}\n",
      "Iteration 51, Losses: {'ner': 79.70296668807786}\n",
      "Iteration 51, Losses: {'ner': 82.92021259963335}\n",
      "Iteration 51, Losses: {'ner': 92.10203289274138}\n",
      "Iteration 52, Losses: {'ner': 4.797010560689098}\n",
      "Iteration 52, Losses: {'ner': 8.785264231293938}\n",
      "Iteration 52, Losses: {'ner': 10.403390561150724}\n",
      "Iteration 52, Losses: {'ner': 10.418880695354419}\n",
      "Iteration 52, Losses: {'ner': 17.041260517495846}\n",
      "Iteration 52, Losses: {'ner': 25.36754311172789}\n",
      "Iteration 52, Losses: {'ner': 25.367705301159575}\n",
      "Iteration 52, Losses: {'ner': 25.367705345787986}\n",
      "Iteration 52, Losses: {'ner': 25.367720090888696}\n",
      "Iteration 52, Losses: {'ner': 25.367721043373503}\n",
      "Iteration 52, Losses: {'ner': 26.54392688306814}\n",
      "Iteration 52, Losses: {'ner': 32.913812204986215}\n",
      "Iteration 52, Losses: {'ner': 33.32055620981988}\n",
      "Iteration 52, Losses: {'ner': 33.320776519798144}\n",
      "Iteration 52, Losses: {'ner': 36.532794059551655}\n",
      "Iteration 52, Losses: {'ner': 44.301776395534795}\n",
      "Iteration 52, Losses: {'ner': 48.08446691752033}\n",
      "Iteration 52, Losses: {'ner': 49.32281579598634}\n",
      "Iteration 52, Losses: {'ner': 50.94456729003651}\n",
      "Iteration 52, Losses: {'ner': 51.08471717585045}\n",
      "Iteration 52, Losses: {'ner': 52.551863374105686}\n",
      "Iteration 52, Losses: {'ner': 52.76636178769906}\n",
      "Iteration 52, Losses: {'ner': 52.769270950734004}\n",
      "Iteration 52, Losses: {'ner': 54.20457435429836}\n",
      "Iteration 52, Losses: {'ner': 57.252494138566306}\n",
      "Iteration 52, Losses: {'ner': 59.54704831207648}\n",
      "Iteration 52, Losses: {'ner': 66.81027605088242}\n",
      "Iteration 52, Losses: {'ner': 66.8119517656558}\n",
      "Iteration 52, Losses: {'ner': 81.69483817747016}\n",
      "Iteration 52, Losses: {'ner': 83.75303163366638}\n",
      "Iteration 52, Losses: {'ner': 83.75308452616878}\n",
      "Iteration 53, Losses: {'ner': 0.16347902199397957}\n",
      "Iteration 53, Losses: {'ner': 0.16353770521923316}\n",
      "Iteration 53, Losses: {'ner': 13.487903381490089}\n",
      "Iteration 53, Losses: {'ner': 14.016820444624589}\n",
      "Iteration 53, Losses: {'ner': 14.0559401830509}\n",
      "Iteration 53, Losses: {'ner': 17.57435924930772}\n",
      "Iteration 53, Losses: {'ner': 17.574369203534562}\n",
      "Iteration 53, Losses: {'ner': 35.5983932362036}\n",
      "Iteration 53, Losses: {'ner': 35.77704357987713}\n",
      "Iteration 53, Losses: {'ner': 35.78294096456721}\n",
      "Iteration 53, Losses: {'ner': 35.82482212587879}\n",
      "Iteration 53, Losses: {'ner': 37.173997348909054}\n",
      "Iteration 53, Losses: {'ner': 37.19479100636593}\n",
      "Iteration 53, Losses: {'ner': 37.24951478626271}\n",
      "Iteration 53, Losses: {'ner': 37.24951580183279}\n",
      "Iteration 53, Losses: {'ner': 38.87219043878889}\n",
      "Iteration 53, Losses: {'ner': 49.16026017880295}\n",
      "Iteration 53, Losses: {'ner': 53.399465744895735}\n",
      "Iteration 53, Losses: {'ner': 53.414910347907224}\n",
      "Iteration 53, Losses: {'ner': 53.41749915462526}\n",
      "Iteration 53, Losses: {'ner': 61.90294427697905}\n",
      "Iteration 53, Losses: {'ner': 63.52437424308561}\n",
      "Iteration 53, Losses: {'ner': 65.21343516635795}\n",
      "Iteration 53, Losses: {'ner': 65.31868799946615}\n",
      "Iteration 53, Losses: {'ner': 67.30988111384525}\n",
      "Iteration 53, Losses: {'ner': 69.25041364800043}\n",
      "Iteration 53, Losses: {'ner': 71.95785861811513}\n",
      "Iteration 53, Losses: {'ner': 75.44858017419399}\n",
      "Iteration 53, Losses: {'ner': 76.17103535057416}\n",
      "Iteration 53, Losses: {'ner': 76.28683214932285}\n",
      "Iteration 53, Losses: {'ner': 76.28683326544687}\n",
      "Iteration 54, Losses: {'ner': 0.3314160148674012}\n",
      "Iteration 54, Losses: {'ner': 0.8884509625442905}\n",
      "Iteration 54, Losses: {'ner': 0.9015538043116931}\n",
      "Iteration 54, Losses: {'ner': 1.7703982122157154}\n",
      "Iteration 54, Losses: {'ner': 3.1477109096704123}\n",
      "Iteration 54, Losses: {'ner': 3.2054655233590523}\n",
      "Iteration 54, Losses: {'ner': 3.874210492181704}\n",
      "Iteration 54, Losses: {'ner': 6.98605856693647}\n",
      "Iteration 54, Losses: {'ner': 8.46011716246996}\n",
      "Iteration 54, Losses: {'ner': 9.394362575891591}\n",
      "Iteration 54, Losses: {'ner': 11.953495808382197}\n",
      "Iteration 54, Losses: {'ner': 20.639210742102232}\n",
      "Iteration 54, Losses: {'ner': 33.693128362088956}\n",
      "Iteration 54, Losses: {'ner': 33.69502127541696}\n",
      "Iteration 54, Losses: {'ner': 35.32221493019045}\n",
      "Iteration 54, Losses: {'ner': 35.32227829770299}\n",
      "Iteration 54, Losses: {'ner': 39.23852639987446}\n",
      "Iteration 54, Losses: {'ner': 58.044355525261885}\n",
      "Iteration 54, Losses: {'ner': 58.044356829027436}\n",
      "Iteration 54, Losses: {'ner': 58.044549465261845}\n",
      "Iteration 54, Losses: {'ner': 60.50861272187873}\n",
      "Iteration 54, Losses: {'ner': 62.7948959704596}\n",
      "Iteration 54, Losses: {'ner': 66.76987783805282}\n",
      "Iteration 54, Losses: {'ner': 70.72935003425069}\n",
      "Iteration 54, Losses: {'ner': 79.75315932297661}\n",
      "Iteration 54, Losses: {'ner': 82.19871742937526}\n",
      "Iteration 54, Losses: {'ner': 86.3948739897396}\n",
      "Iteration 54, Losses: {'ner': 86.39496748678152}\n",
      "Iteration 54, Losses: {'ner': 86.40144427429786}\n",
      "Iteration 54, Losses: {'ner': 86.40144791798812}\n",
      "Iteration 54, Losses: {'ner': 86.41888428998855}\n",
      "Iteration 55, Losses: {'ner': 10.856091983250387}\n",
      "Iteration 55, Losses: {'ner': 10.872734802395934}\n",
      "Iteration 55, Losses: {'ner': 18.90005982722528}\n",
      "Iteration 55, Losses: {'ner': 19.665481300537362}\n",
      "Iteration 55, Losses: {'ner': 19.667198237735004}\n",
      "Iteration 55, Losses: {'ner': 19.67299499685518}\n",
      "Iteration 55, Losses: {'ner': 19.701250624003617}\n",
      "Iteration 55, Losses: {'ner': 25.361410621414645}\n",
      "Iteration 55, Losses: {'ner': 27.912954910838735}\n",
      "Iteration 55, Losses: {'ner': 35.62459933164447}\n",
      "Iteration 55, Losses: {'ner': 37.931377496100716}\n",
      "Iteration 55, Losses: {'ner': 37.931410667537136}\n",
      "Iteration 55, Losses: {'ner': 41.007702154961116}\n",
      "Iteration 55, Losses: {'ner': 48.86173598548502}\n",
      "Iteration 55, Losses: {'ner': 49.970440035031565}\n",
      "Iteration 55, Losses: {'ner': 49.97044218364579}\n",
      "Iteration 55, Losses: {'ner': 50.11259454143297}\n",
      "Iteration 55, Losses: {'ner': 50.112597623215464}\n",
      "Iteration 55, Losses: {'ner': 53.54275488153219}\n",
      "Iteration 55, Losses: {'ner': 53.54279993582564}\n",
      "Iteration 55, Losses: {'ner': 59.84678686982848}\n",
      "Iteration 55, Losses: {'ner': 59.91128537566392}\n",
      "Iteration 55, Losses: {'ner': 61.397205798269276}\n",
      "Iteration 55, Losses: {'ner': 62.695404199608134}\n",
      "Iteration 55, Losses: {'ner': 64.41921006778428}\n",
      "Iteration 55, Losses: {'ner': 66.42613059277305}\n",
      "Iteration 55, Losses: {'ner': 75.50549620237251}\n",
      "Iteration 55, Losses: {'ner': 75.61420443218084}\n",
      "Iteration 55, Losses: {'ner': 79.04877813703823}\n",
      "Iteration 55, Losses: {'ner': 79.14372203424884}\n",
      "Iteration 55, Losses: {'ner': 88.5551161996319}\n",
      "Iteration 56, Losses: {'ner': 1.2341234734821559e-05}\n",
      "Iteration 56, Losses: {'ner': 0.02391561277177471}\n",
      "Iteration 56, Losses: {'ner': 3.8595775044164995}\n",
      "Iteration 56, Losses: {'ner': 3.859582425668939}\n",
      "Iteration 56, Losses: {'ner': 6.110966755316857}\n",
      "Iteration 56, Losses: {'ner': 6.305021127376618}\n",
      "Iteration 56, Losses: {'ner': 6.30578197352417}\n",
      "Iteration 56, Losses: {'ner': 6.3057826502663215}\n",
      "Iteration 56, Losses: {'ner': 6.706393748643272}\n",
      "Iteration 56, Losses: {'ner': 10.955006310903752}\n",
      "Iteration 56, Losses: {'ner': 10.991712889685065}\n",
      "Iteration 56, Losses: {'ner': 12.919638153666455}\n",
      "Iteration 56, Losses: {'ner': 14.771675361601066}\n",
      "Iteration 56, Losses: {'ner': 14.82780585407722}\n",
      "Iteration 56, Losses: {'ner': 27.07958074877855}\n",
      "Iteration 56, Losses: {'ner': 33.72927499937466}\n",
      "Iteration 56, Losses: {'ner': 42.717390151536456}\n",
      "Iteration 56, Losses: {'ner': 47.63094270715021}\n",
      "Iteration 56, Losses: {'ner': 50.66552739071457}\n",
      "Iteration 56, Losses: {'ner': 50.77701945079405}\n",
      "Iteration 56, Losses: {'ner': 50.77743886179513}\n",
      "Iteration 56, Losses: {'ner': 52.73678432340035}\n",
      "Iteration 56, Losses: {'ner': 57.921574445073816}\n",
      "Iteration 56, Losses: {'ner': 57.93235401503007}\n",
      "Iteration 56, Losses: {'ner': 57.9588403375127}\n",
      "Iteration 56, Losses: {'ner': 64.91180408202061}\n",
      "Iteration 56, Losses: {'ner': 64.91180615004444}\n",
      "Iteration 56, Losses: {'ner': 64.9401854112293}\n",
      "Iteration 56, Losses: {'ner': 87.88055933017083}\n",
      "Iteration 56, Losses: {'ner': 87.88055937736384}\n",
      "Iteration 56, Losses: {'ner': 87.88056023118712}\n",
      "Iteration 57, Losses: {'ner': 13.600809744328473}\n",
      "Iteration 57, Losses: {'ner': 26.763201560177077}\n",
      "Iteration 57, Losses: {'ner': 28.97527308481755}\n",
      "Iteration 57, Losses: {'ner': 28.97531066681414}\n",
      "Iteration 57, Losses: {'ner': 31.16628181456526}\n",
      "Iteration 57, Losses: {'ner': 41.46663794303728}\n",
      "Iteration 57, Losses: {'ner': 41.46716135387553}\n",
      "Iteration 57, Losses: {'ner': 42.79202702502725}\n",
      "Iteration 57, Losses: {'ner': 50.940874239988524}\n",
      "Iteration 57, Losses: {'ner': 71.88970105173415}\n",
      "Iteration 57, Losses: {'ner': 71.89008953741335}\n",
      "Iteration 57, Losses: {'ner': 71.89010177729348}\n",
      "Iteration 57, Losses: {'ner': 71.91536487851955}\n",
      "Iteration 57, Losses: {'ner': 73.09215429057672}\n",
      "Iteration 57, Losses: {'ner': 75.47348985946279}\n",
      "Iteration 57, Losses: {'ner': 75.52446118018175}\n",
      "Iteration 57, Losses: {'ner': 75.52580598765198}\n",
      "Iteration 57, Losses: {'ner': 75.52580716949348}\n",
      "Iteration 57, Losses: {'ner': 75.65151431943355}\n",
      "Iteration 57, Losses: {'ner': 77.09536722945053}\n",
      "Iteration 57, Losses: {'ner': 84.72523829363493}\n",
      "Iteration 57, Losses: {'ner': 87.47832046801379}\n",
      "Iteration 57, Losses: {'ner': 87.47867663148821}\n",
      "Iteration 57, Losses: {'ner': 87.47868972755867}\n",
      "Iteration 57, Losses: {'ner': 87.51771692728127}\n",
      "Iteration 57, Losses: {'ner': 89.05860000718476}\n",
      "Iteration 57, Losses: {'ner': 89.63256410193772}\n",
      "Iteration 57, Losses: {'ner': 89.95089922452212}\n",
      "Iteration 57, Losses: {'ner': 89.9519556381312}\n",
      "Iteration 57, Losses: {'ner': 91.06204643799757}\n",
      "Iteration 57, Losses: {'ner': 94.638499821347}\n",
      "Iteration 58, Losses: {'ner': 1.6508361433359622}\n",
      "Iteration 58, Losses: {'ner': 1.6508466255228478}\n",
      "Iteration 58, Losses: {'ner': 4.016751957022284}\n",
      "Iteration 58, Losses: {'ner': 24.956635804467012}\n",
      "Iteration 58, Losses: {'ner': 24.980280473073638}\n",
      "Iteration 58, Losses: {'ner': 25.97319796486553}\n",
      "Iteration 58, Losses: {'ner': 27.931217913166744}\n",
      "Iteration 58, Losses: {'ner': 29.91206881762789}\n",
      "Iteration 58, Losses: {'ner': 32.552200676887416}\n",
      "Iteration 58, Losses: {'ner': 39.90862928045421}\n",
      "Iteration 58, Losses: {'ner': 48.96245960238516}\n",
      "Iteration 58, Losses: {'ner': 48.98511092033893}\n",
      "Iteration 58, Losses: {'ner': 49.058353924131424}\n",
      "Iteration 58, Losses: {'ner': 50.26026421644573}\n",
      "Iteration 58, Losses: {'ner': 52.94375291842963}\n",
      "Iteration 58, Losses: {'ner': 52.9437531189799}\n",
      "Iteration 58, Losses: {'ner': 54.60510208682637}\n",
      "Iteration 58, Losses: {'ner': 54.60525018637619}\n",
      "Iteration 58, Losses: {'ner': 54.605268653895656}\n",
      "Iteration 58, Losses: {'ner': 65.10016221870698}\n",
      "Iteration 58, Losses: {'ner': 66.31623911632096}\n",
      "Iteration 58, Losses: {'ner': 66.33712388232986}\n",
      "Iteration 58, Losses: {'ner': 66.337127110266}\n",
      "Iteration 58, Losses: {'ner': 66.33713433519047}\n",
      "Iteration 58, Losses: {'ner': 66.62124263391925}\n",
      "Iteration 58, Losses: {'ner': 66.62416069165353}\n",
      "Iteration 58, Losses: {'ner': 66.62456702002862}\n",
      "Iteration 58, Losses: {'ner': 68.42082418102878}\n",
      "Iteration 58, Losses: {'ner': 70.79894718995062}\n",
      "Iteration 58, Losses: {'ner': 70.79931467506192}\n",
      "Iteration 58, Losses: {'ner': 72.3188896960476}\n",
      "Iteration 59, Losses: {'ner': 2.672734056275432}\n",
      "Iteration 59, Losses: {'ner': 4.018202357799728}\n",
      "Iteration 59, Losses: {'ner': 5.6221628856519805}\n",
      "Iteration 59, Losses: {'ner': 5.622167574412271}\n",
      "Iteration 59, Losses: {'ner': 5.622167609404079}\n",
      "Iteration 59, Losses: {'ner': 7.455436339528582}\n",
      "Iteration 59, Losses: {'ner': 7.455460614965922}\n",
      "Iteration 59, Losses: {'ner': 15.715344379256955}\n",
      "Iteration 59, Losses: {'ner': 21.51835771328319}\n",
      "Iteration 59, Losses: {'ner': 21.518357716364257}\n",
      "Iteration 59, Losses: {'ner': 21.72610128796755}\n",
      "Iteration 59, Losses: {'ner': 21.757731854617273}\n",
      "Iteration 59, Losses: {'ner': 23.776634436068104}\n",
      "Iteration 59, Losses: {'ner': 25.20319242831085}\n",
      "Iteration 59, Losses: {'ner': 25.203192830385714}\n",
      "Iteration 59, Losses: {'ner': 25.203232035315995}\n",
      "Iteration 59, Losses: {'ner': 28.411291322186578}\n",
      "Iteration 59, Losses: {'ner': 29.438259448967344}\n",
      "Iteration 59, Losses: {'ner': 29.43825948607754}\n",
      "Iteration 59, Losses: {'ner': 39.1690623928934}\n",
      "Iteration 59, Losses: {'ner': 39.6379838758548}\n",
      "Iteration 59, Losses: {'ner': 62.44446713209365}\n",
      "Iteration 59, Losses: {'ner': 68.07798158495802}\n",
      "Iteration 59, Losses: {'ner': 68.91023724080334}\n",
      "Iteration 59, Losses: {'ner': 70.33615107122192}\n",
      "Iteration 59, Losses: {'ner': 73.27947719857957}\n",
      "Iteration 59, Losses: {'ner': 75.24764363217116}\n",
      "Iteration 59, Losses: {'ner': 107.55694724393902}\n",
      "Iteration 59, Losses: {'ner': 112.44976676053827}\n",
      "Iteration 59, Losses: {'ner': 112.45186065068643}\n",
      "Iteration 59, Losses: {'ner': 118.69861180438002}\n",
      "Iteration 60, Losses: {'ner': 0.005799016652523434}\n",
      "Iteration 60, Losses: {'ner': 0.24230037029109744}\n",
      "Iteration 60, Losses: {'ner': 2.596618362309732}\n",
      "Iteration 60, Losses: {'ner': 3.153161192250356}\n",
      "Iteration 60, Losses: {'ner': 4.293220431428675}\n",
      "Iteration 60, Losses: {'ner': 9.281444001403969}\n",
      "Iteration 60, Losses: {'ner': 9.283438462122083}\n",
      "Iteration 60, Losses: {'ner': 9.284626604663588}\n",
      "Iteration 60, Losses: {'ner': 12.147825893897645}\n",
      "Iteration 60, Losses: {'ner': 12.166362797938008}\n",
      "Iteration 60, Losses: {'ner': 12.166403276547708}\n",
      "Iteration 60, Losses: {'ner': 12.19427871473747}\n",
      "Iteration 60, Losses: {'ner': 14.328106643588864}\n",
      "Iteration 60, Losses: {'ner': 22.59062849454686}\n",
      "Iteration 60, Losses: {'ner': 25.350203477370478}\n",
      "Iteration 60, Losses: {'ner': 26.520526713511494}\n",
      "Iteration 60, Losses: {'ner': 27.54323509205481}\n",
      "Iteration 60, Losses: {'ner': 27.576731938347503}\n",
      "Iteration 60, Losses: {'ner': 27.676492839350537}\n",
      "Iteration 60, Losses: {'ner': 27.678015379908516}\n",
      "Iteration 60, Losses: {'ner': 56.93323060766972}\n",
      "Iteration 60, Losses: {'ner': 67.60244409311467}\n",
      "Iteration 60, Losses: {'ner': 69.11897932151005}\n",
      "Iteration 60, Losses: {'ner': 80.7390072925653}\n",
      "Iteration 60, Losses: {'ner': 84.64589813012768}\n",
      "Iteration 60, Losses: {'ner': 89.89066676599505}\n",
      "Iteration 60, Losses: {'ner': 93.73869243949423}\n",
      "Iteration 60, Losses: {'ner': 93.73884484420891}\n",
      "Iteration 60, Losses: {'ner': 102.00923258948453}\n",
      "Iteration 60, Losses: {'ner': 102.00923265282059}\n",
      "Iteration 60, Losses: {'ner': 102.37751548538117}\n",
      "Iteration 61, Losses: {'ner': 0.026951762126177444}\n",
      "Iteration 61, Losses: {'ner': 6.591745970895117}\n",
      "Iteration 61, Losses: {'ner': 8.603352294440871}\n",
      "Iteration 61, Losses: {'ner': 8.609405342343894}\n",
      "Iteration 61, Losses: {'ner': 16.26348572574904}\n",
      "Iteration 61, Losses: {'ner': 16.267329686357293}\n",
      "Iteration 61, Losses: {'ner': 27.616036375840263}\n",
      "Iteration 61, Losses: {'ner': 28.054537684701895}\n",
      "Iteration 61, Losses: {'ner': 28.054615978132677}\n",
      "Iteration 61, Losses: {'ner': 44.99197442848018}\n",
      "Iteration 61, Losses: {'ner': 50.80152936174734}\n",
      "Iteration 61, Losses: {'ner': 50.88576367714824}\n",
      "Iteration 61, Losses: {'ner': 52.36606684781271}\n",
      "Iteration 61, Losses: {'ner': 52.366089029256706}\n",
      "Iteration 61, Losses: {'ner': 55.54428180708682}\n",
      "Iteration 61, Losses: {'ner': 55.62267488435941}\n",
      "Iteration 61, Losses: {'ner': 57.39318628135139}\n",
      "Iteration 61, Losses: {'ner': 57.42017989805373}\n",
      "Iteration 61, Losses: {'ner': 57.453287829657256}\n",
      "Iteration 61, Losses: {'ner': 60.900181962691335}\n",
      "Iteration 61, Losses: {'ner': 60.90018198230588}\n",
      "Iteration 61, Losses: {'ner': 72.88985015406611}\n",
      "Iteration 61, Losses: {'ner': 72.8898633985568}\n",
      "Iteration 61, Losses: {'ner': 72.89020041159743}\n",
      "Iteration 61, Losses: {'ner': 75.24910627000953}\n",
      "Iteration 61, Losses: {'ner': 91.2436794225657}\n",
      "Iteration 61, Losses: {'ner': 93.38229718800417}\n",
      "Iteration 61, Losses: {'ner': 93.38267997073301}\n",
      "Iteration 61, Losses: {'ner': 93.38611823403724}\n",
      "Iteration 61, Losses: {'ner': 93.5259520355978}\n",
      "Iteration 61, Losses: {'ner': 93.5511164263653}\n",
      "Iteration 62, Losses: {'ner': 0.039327990252975696}\n",
      "Iteration 62, Losses: {'ner': 12.184496130846421}\n",
      "Iteration 62, Losses: {'ner': 12.184500602311262}\n",
      "Iteration 62, Losses: {'ner': 18.722762551348854}\n",
      "Iteration 62, Losses: {'ner': 20.750276193871617}\n",
      "Iteration 62, Losses: {'ner': 20.750690109773224}\n",
      "Iteration 62, Losses: {'ner': 26.332362192018476}\n",
      "Iteration 62, Losses: {'ner': 32.68874904446316}\n",
      "Iteration 62, Losses: {'ner': 40.194975752045025}\n",
      "Iteration 62, Losses: {'ner': 44.10663757068218}\n",
      "Iteration 62, Losses: {'ner': 49.48056043631175}\n",
      "Iteration 62, Losses: {'ner': 49.49806785016678}\n",
      "Iteration 62, Losses: {'ner': 49.72181544566465}\n",
      "Iteration 62, Losses: {'ner': 49.72182940776061}\n",
      "Iteration 62, Losses: {'ner': 49.72183031272411}\n",
      "Iteration 62, Losses: {'ner': 49.727574358741364}\n",
      "Iteration 62, Losses: {'ner': 49.82962403881902}\n",
      "Iteration 62, Losses: {'ner': 49.84698136792928}\n",
      "Iteration 62, Losses: {'ner': 50.44881168875479}\n",
      "Iteration 62, Losses: {'ner': 50.56527196928501}\n",
      "Iteration 62, Losses: {'ner': 50.565379914241134}\n",
      "Iteration 62, Losses: {'ner': 54.449445670922046}\n",
      "Iteration 62, Losses: {'ner': 54.4494470090738}\n",
      "Iteration 62, Losses: {'ner': 54.451425511221025}\n",
      "Iteration 62, Losses: {'ner': 58.276065637813275}\n",
      "Iteration 62, Losses: {'ner': 58.29396548161463}\n",
      "Iteration 62, Losses: {'ner': 63.87613601903306}\n",
      "Iteration 62, Losses: {'ner': 63.91567669406384}\n",
      "Iteration 62, Losses: {'ner': 77.52177725281113}\n",
      "Iteration 62, Losses: {'ner': 81.70521070241621}\n",
      "Iteration 62, Losses: {'ner': 81.70526598169627}\n",
      "Iteration 63, Losses: {'ner': 4.718922934858052}\n",
      "Iteration 63, Losses: {'ner': 4.74751626933568}\n",
      "Iteration 63, Losses: {'ner': 4.912579826841472}\n",
      "Iteration 63, Losses: {'ner': 5.080264775230158}\n",
      "Iteration 63, Losses: {'ner': 5.082345490278765}\n",
      "Iteration 63, Losses: {'ner': 5.082345601656088}\n",
      "Iteration 63, Losses: {'ner': 5.96769515490587}\n",
      "Iteration 63, Losses: {'ner': 5.98096464713916}\n",
      "Iteration 63, Losses: {'ner': 21.4567624455041}\n",
      "Iteration 63, Losses: {'ner': 26.919235081024002}\n",
      "Iteration 63, Losses: {'ner': 34.681625554690015}\n",
      "Iteration 63, Losses: {'ner': 34.6816259501684}\n",
      "Iteration 63, Losses: {'ner': 44.26029459527256}\n",
      "Iteration 63, Losses: {'ner': 44.26147823899713}\n",
      "Iteration 63, Losses: {'ner': 49.46554506963215}\n",
      "Iteration 63, Losses: {'ner': 49.47832277528911}\n",
      "Iteration 63, Losses: {'ner': 51.74360191826458}\n",
      "Iteration 63, Losses: {'ner': 51.743604987799024}\n",
      "Iteration 63, Losses: {'ner': 60.6604436514513}\n",
      "Iteration 63, Losses: {'ner': 61.752581459062576}\n",
      "Iteration 63, Losses: {'ner': 61.81736410132188}\n",
      "Iteration 63, Losses: {'ner': 62.24535656898834}\n",
      "Iteration 63, Losses: {'ner': 66.61041346846675}\n",
      "Iteration 63, Losses: {'ner': 68.83754566744334}\n",
      "Iteration 63, Losses: {'ner': 69.68738117134703}\n",
      "Iteration 63, Losses: {'ner': 69.71778500242996}\n",
      "Iteration 63, Losses: {'ner': 69.7177886929106}\n",
      "Iteration 63, Losses: {'ner': 73.25045098720253}\n",
      "Iteration 63, Losses: {'ner': 73.25045333976296}\n",
      "Iteration 63, Losses: {'ner': 73.99953543615007}\n",
      "Iteration 63, Losses: {'ner': 76.10636083051808}\n",
      "Iteration 64, Losses: {'ner': 1.4006062901695255}\n",
      "Iteration 64, Losses: {'ner': 5.19288015937215}\n",
      "Iteration 64, Losses: {'ner': 5.192880180335925}\n",
      "Iteration 64, Losses: {'ner': 12.4158159804471}\n",
      "Iteration 64, Losses: {'ner': 12.502495381848094}\n",
      "Iteration 64, Losses: {'ner': 13.479463850371488}\n",
      "Iteration 64, Losses: {'ner': 18.366923984732875}\n",
      "Iteration 64, Losses: {'ner': 20.353273574112553}\n",
      "Iteration 64, Losses: {'ner': 20.35416438389475}\n",
      "Iteration 64, Losses: {'ner': 22.64921446383601}\n",
      "Iteration 64, Losses: {'ner': 22.65237710393633}\n",
      "Iteration 64, Losses: {'ner': 22.653336165343188}\n",
      "Iteration 64, Losses: {'ner': 23.180809200846845}\n",
      "Iteration 64, Losses: {'ner': 24.51489165589709}\n",
      "Iteration 64, Losses: {'ner': 24.516765454760517}\n",
      "Iteration 64, Losses: {'ner': 30.836565282476542}\n",
      "Iteration 64, Losses: {'ner': 30.919346421922675}\n",
      "Iteration 64, Losses: {'ner': 43.35599618217139}\n",
      "Iteration 64, Losses: {'ner': 43.356084626649626}\n",
      "Iteration 64, Losses: {'ner': 50.66860879962579}\n",
      "Iteration 64, Losses: {'ner': 51.057357526978244}\n",
      "Iteration 64, Losses: {'ner': 56.004559120432326}\n",
      "Iteration 64, Losses: {'ner': 59.58132683218378}\n",
      "Iteration 64, Losses: {'ner': 67.90715699502364}\n",
      "Iteration 64, Losses: {'ner': 69.38372346053747}\n",
      "Iteration 64, Losses: {'ner': 81.24747000611467}\n",
      "Iteration 64, Losses: {'ner': 82.61233323744256}\n",
      "Iteration 64, Losses: {'ner': 85.6827023423378}\n",
      "Iteration 64, Losses: {'ner': 86.57796293236557}\n",
      "Iteration 64, Losses: {'ner': 86.64380302132273}\n",
      "Iteration 64, Losses: {'ner': 87.13863432267128}\n",
      "Iteration 65, Losses: {'ner': 0.07262689055779797}\n",
      "Iteration 65, Losses: {'ner': 1.624339784009773}\n",
      "Iteration 65, Losses: {'ner': 2.9822689817015666}\n",
      "Iteration 65, Losses: {'ner': 3.1803407049311176}\n",
      "Iteration 65, Losses: {'ner': 3.1814956034872472}\n",
      "Iteration 65, Losses: {'ner': 3.6285528164898575}\n",
      "Iteration 65, Losses: {'ner': 7.709046300609989}\n",
      "Iteration 65, Losses: {'ner': 18.930169150918896}\n",
      "Iteration 65, Losses: {'ner': 18.930211129242526}\n",
      "Iteration 65, Losses: {'ner': 22.015838961189356}\n",
      "Iteration 65, Losses: {'ner': 24.85256929048598}\n",
      "Iteration 65, Losses: {'ner': 30.84185659840026}\n",
      "Iteration 65, Losses: {'ner': 33.16441209624627}\n",
      "Iteration 65, Losses: {'ner': 33.16441210506222}\n",
      "Iteration 65, Losses: {'ner': 34.18271878496702}\n",
      "Iteration 65, Losses: {'ner': 34.18274349982739}\n",
      "Iteration 65, Losses: {'ner': 34.204274027244274}\n",
      "Iteration 65, Losses: {'ner': 37.84900560296279}\n",
      "Iteration 65, Losses: {'ner': 46.62817528293043}\n",
      "Iteration 65, Losses: {'ner': 46.652345077755804}\n",
      "Iteration 65, Losses: {'ner': 46.652345187514925}\n",
      "Iteration 65, Losses: {'ner': 51.58801324444958}\n",
      "Iteration 65, Losses: {'ner': 53.52171001577117}\n",
      "Iteration 65, Losses: {'ner': 63.043202694804016}\n",
      "Iteration 65, Losses: {'ner': 64.91236159781808}\n",
      "Iteration 65, Losses: {'ner': 64.91256366590287}\n",
      "Iteration 65, Losses: {'ner': 66.86227924233114}\n",
      "Iteration 65, Losses: {'ner': 67.81478803717859}\n",
      "Iteration 65, Losses: {'ner': 83.46484282337856}\n",
      "Iteration 65, Losses: {'ner': 83.6296354953186}\n",
      "Iteration 65, Losses: {'ner': 84.13398153855894}\n",
      "Iteration 66, Losses: {'ner': 0.5103467618476684}\n",
      "Iteration 66, Losses: {'ner': 3.132914268774611}\n",
      "Iteration 66, Losses: {'ner': 3.133032400655738}\n",
      "Iteration 66, Losses: {'ner': 6.052036235211116}\n",
      "Iteration 66, Losses: {'ner': 6.055471668736663}\n",
      "Iteration 66, Losses: {'ner': 6.565501340015174}\n",
      "Iteration 66, Losses: {'ner': 6.565710957282346}\n",
      "Iteration 66, Losses: {'ner': 17.161353343726127}\n",
      "Iteration 66, Losses: {'ner': 24.914993358876558}\n",
      "Iteration 66, Losses: {'ner': 32.353011498455295}\n",
      "Iteration 66, Losses: {'ner': 34.31047507103733}\n",
      "Iteration 66, Losses: {'ner': 36.53261851704457}\n",
      "Iteration 66, Losses: {'ner': 39.5838392255692}\n",
      "Iteration 66, Losses: {'ner': 40.987050060598705}\n",
      "Iteration 66, Losses: {'ner': 40.991348184318745}\n",
      "Iteration 66, Losses: {'ner': 47.517407667013025}\n",
      "Iteration 66, Losses: {'ner': 47.5177764583739}\n",
      "Iteration 66, Losses: {'ner': 47.5177989901912}\n",
      "Iteration 66, Losses: {'ner': 47.52235597165172}\n",
      "Iteration 66, Losses: {'ner': 47.52239997626565}\n",
      "Iteration 66, Losses: {'ner': 47.82344751255071}\n",
      "Iteration 66, Losses: {'ner': 53.934958210273706}\n",
      "Iteration 66, Losses: {'ner': 57.87373986863106}\n",
      "Iteration 66, Losses: {'ner': 69.79584238633358}\n",
      "Iteration 66, Losses: {'ner': 71.34589485049284}\n",
      "Iteration 66, Losses: {'ner': 71.35691573326524}\n",
      "Iteration 66, Losses: {'ner': 71.35840973704796}\n",
      "Iteration 66, Losses: {'ner': 71.94744603365203}\n",
      "Iteration 66, Losses: {'ner': 71.94749814468598}\n",
      "Iteration 66, Losses: {'ner': 74.76778159215078}\n",
      "Iteration 66, Losses: {'ner': 75.1290489951003}\n",
      "Iteration 67, Losses: {'ner': 0.27101484577439017}\n",
      "Iteration 67, Losses: {'ner': 5.6999140789824185}\n",
      "Iteration 67, Losses: {'ner': 5.6999140823762735}\n",
      "Iteration 67, Losses: {'ner': 10.337944493067}\n",
      "Iteration 67, Losses: {'ner': 13.860122359480705}\n",
      "Iteration 67, Losses: {'ner': 13.86013560491939}\n",
      "Iteration 67, Losses: {'ner': 17.23439503247026}\n",
      "Iteration 67, Losses: {'ner': 17.23443241849378}\n",
      "Iteration 67, Losses: {'ner': 17.379762137644427}\n",
      "Iteration 67, Losses: {'ner': 18.177765692185194}\n",
      "Iteration 67, Losses: {'ner': 22.597194372001105}\n",
      "Iteration 67, Losses: {'ner': 27.319498710499385}\n",
      "Iteration 67, Losses: {'ner': 31.934730829493013}\n",
      "Iteration 67, Losses: {'ner': 38.22694732405665}\n",
      "Iteration 67, Losses: {'ner': 38.2290506137855}\n",
      "Iteration 67, Losses: {'ner': 38.32119045463812}\n",
      "Iteration 67, Losses: {'ner': 38.80347901949767}\n",
      "Iteration 67, Losses: {'ner': 40.63094342694669}\n",
      "Iteration 67, Losses: {'ner': 41.92185983428756}\n",
      "Iteration 67, Losses: {'ner': 55.13623657973182}\n",
      "Iteration 67, Losses: {'ner': 55.136236634427746}\n",
      "Iteration 67, Losses: {'ner': 55.13627091990983}\n",
      "Iteration 67, Losses: {'ner': 55.1362710826312}\n",
      "Iteration 67, Losses: {'ner': 66.1997149383128}\n",
      "Iteration 67, Losses: {'ner': 67.8233839947693}\n",
      "Iteration 67, Losses: {'ner': 67.8234259768688}\n",
      "Iteration 67, Losses: {'ner': 86.77802679669772}\n",
      "Iteration 67, Losses: {'ner': 86.77820250342458}\n",
      "Iteration 67, Losses: {'ner': 89.65602043096366}\n",
      "Iteration 67, Losses: {'ner': 120.18753431965422}\n",
      "Iteration 67, Losses: {'ner': 120.19015677152397}\n",
      "Iteration 68, Losses: {'ner': 3.5130261287052966e-09}\n",
      "Iteration 68, Losses: {'ner': 0.0007621176623015146}\n",
      "Iteration 68, Losses: {'ner': 6.3675736397197795}\n",
      "Iteration 68, Losses: {'ner': 7.792899040074131}\n",
      "Iteration 68, Losses: {'ner': 10.315949375024308}\n",
      "Iteration 68, Losses: {'ner': 17.051757894678296}\n",
      "Iteration 68, Losses: {'ner': 17.05189776414115}\n",
      "Iteration 68, Losses: {'ner': 17.05189842229869}\n",
      "Iteration 68, Losses: {'ner': 18.069185759014434}\n",
      "Iteration 68, Losses: {'ner': 20.123679821483293}\n",
      "Iteration 68, Losses: {'ner': 23.012496148382684}\n",
      "Iteration 68, Losses: {'ner': 23.777921114912452}\n",
      "Iteration 68, Losses: {'ner': 25.95325416229341}\n",
      "Iteration 68, Losses: {'ner': 31.109708704241328}\n",
      "Iteration 68, Losses: {'ner': 45.83867902867747}\n",
      "Iteration 68, Losses: {'ner': 47.93397451871958}\n",
      "Iteration 68, Losses: {'ner': 54.07353060271777}\n",
      "Iteration 68, Losses: {'ner': 54.07436622351877}\n",
      "Iteration 68, Losses: {'ner': 57.7497582645574}\n",
      "Iteration 68, Losses: {'ner': 71.24867044032075}\n",
      "Iteration 68, Losses: {'ner': 71.24872928437895}\n",
      "Iteration 68, Losses: {'ner': 72.78513390306634}\n",
      "Iteration 68, Losses: {'ner': 72.80448976578636}\n",
      "Iteration 68, Losses: {'ner': 72.80450002051252}\n",
      "Iteration 68, Losses: {'ner': 84.99079127380877}\n",
      "Iteration 68, Losses: {'ner': 84.99247053848006}\n",
      "Iteration 68, Losses: {'ner': 88.87192660407686}\n",
      "Iteration 68, Losses: {'ner': 88.88057567296485}\n",
      "Iteration 68, Losses: {'ner': 88.88381035295731}\n",
      "Iteration 68, Losses: {'ner': 88.89418907056121}\n",
      "Iteration 68, Losses: {'ner': 90.03827380786366}\n",
      "Iteration 69, Losses: {'ner': 0.0018972570976054258}\n",
      "Iteration 69, Losses: {'ner': 4.362504692397411}\n",
      "Iteration 69, Losses: {'ner': 6.42636627193251}\n",
      "Iteration 69, Losses: {'ner': 12.363080159435766}\n",
      "Iteration 69, Losses: {'ner': 12.732374834105046}\n",
      "Iteration 69, Losses: {'ner': 12.876431433589454}\n",
      "Iteration 69, Losses: {'ner': 12.876445641153248}\n",
      "Iteration 69, Losses: {'ner': 14.058906431495455}\n",
      "Iteration 69, Losses: {'ner': 14.960118056333094}\n",
      "Iteration 69, Losses: {'ner': 14.972417496643311}\n",
      "Iteration 69, Losses: {'ner': 20.469324387401375}\n",
      "Iteration 69, Losses: {'ner': 22.520602375885016}\n",
      "Iteration 69, Losses: {'ner': 22.53507451012658}\n",
      "Iteration 69, Losses: {'ner': 24.289616577236835}\n",
      "Iteration 69, Losses: {'ner': 37.46565031085623}\n",
      "Iteration 69, Losses: {'ner': 37.46565034509411}\n",
      "Iteration 69, Losses: {'ner': 39.46818722983095}\n",
      "Iteration 69, Losses: {'ner': 42.820759455300795}\n",
      "Iteration 69, Losses: {'ner': 42.82092334512923}\n",
      "Iteration 69, Losses: {'ner': 42.91099578092078}\n",
      "Iteration 69, Losses: {'ner': 50.213337900958706}\n",
      "Iteration 69, Losses: {'ner': 54.49743558168616}\n",
      "Iteration 69, Losses: {'ner': 58.66005233153048}\n",
      "Iteration 69, Losses: {'ner': 63.88314215058642}\n",
      "Iteration 69, Losses: {'ner': 68.84653212664149}\n",
      "Iteration 69, Losses: {'ner': 68.88766162557353}\n",
      "Iteration 69, Losses: {'ner': 68.89385674822512}\n",
      "Iteration 69, Losses: {'ner': 70.05199792660068}\n",
      "Iteration 69, Losses: {'ner': 71.86344315627866}\n",
      "Iteration 69, Losses: {'ner': 71.86344322330405}\n",
      "Iteration 69, Losses: {'ner': 71.86595344885653}\n",
      "Iteration 70, Losses: {'ner': 0.24684581737102212}\n",
      "Iteration 70, Losses: {'ner': 0.41932031062511654}\n",
      "Iteration 70, Losses: {'ner': 3.1233057584715684}\n",
      "Iteration 70, Losses: {'ner': 3.1249996482158737}\n",
      "Iteration 70, Losses: {'ner': 3.1250011912934426}\n",
      "Iteration 70, Losses: {'ner': 7.933206060141525}\n",
      "Iteration 70, Losses: {'ner': 7.937401614093179}\n",
      "Iteration 70, Losses: {'ner': 7.938639546762207}\n",
      "Iteration 70, Losses: {'ner': 10.552133720704003}\n",
      "Iteration 70, Losses: {'ner': 10.554166448229106}\n",
      "Iteration 70, Losses: {'ner': 13.545649760473134}\n",
      "Iteration 70, Losses: {'ner': 15.334533820235347}\n",
      "Iteration 70, Losses: {'ner': 16.716583593330988}\n",
      "Iteration 70, Losses: {'ner': 17.853026237781044}\n",
      "Iteration 70, Losses: {'ner': 17.855927754616836}\n",
      "Iteration 70, Losses: {'ner': 17.873269665710062}\n",
      "Iteration 70, Losses: {'ner': 17.873353576264318}\n",
      "Iteration 70, Losses: {'ner': 17.890668544307054}\n",
      "Iteration 70, Losses: {'ner': 18.439538347264357}\n",
      "Iteration 70, Losses: {'ner': 18.439538360643304}\n",
      "Iteration 70, Losses: {'ner': 19.95084658864211}\n",
      "Iteration 70, Losses: {'ner': 19.951021876743535}\n",
      "Iteration 70, Losses: {'ner': 19.951021888324767}\n",
      "Iteration 70, Losses: {'ner': 27.29345319759766}\n",
      "Iteration 70, Losses: {'ner': 27.293453230283518}\n",
      "Iteration 70, Losses: {'ner': 27.29386731638649}\n",
      "Iteration 70, Losses: {'ner': 43.493833597525125}\n",
      "Iteration 70, Losses: {'ner': 43.49383359763456}\n",
      "Iteration 70, Losses: {'ner': 45.52498727559611}\n",
      "Iteration 70, Losses: {'ner': 49.480486709801696}\n",
      "Iteration 70, Losses: {'ner': 54.97024132613054}\n",
      "Iteration 71, Losses: {'ner': 6.456815116732626}\n",
      "Iteration 71, Losses: {'ner': 22.624780193365027}\n",
      "Iteration 71, Losses: {'ner': 26.00182946158605}\n",
      "Iteration 71, Losses: {'ner': 26.00193177069087}\n",
      "Iteration 71, Losses: {'ner': 26.304580479011534}\n",
      "Iteration 71, Losses: {'ner': 26.31083881954532}\n",
      "Iteration 71, Losses: {'ner': 26.310838837338576}\n",
      "Iteration 71, Losses: {'ner': 38.922299970851874}\n",
      "Iteration 71, Losses: {'ner': 44.23888612320163}\n",
      "Iteration 71, Losses: {'ner': 46.38682730007778}\n",
      "Iteration 71, Losses: {'ner': 51.21407491965876}\n",
      "Iteration 71, Losses: {'ner': 52.35146417385165}\n",
      "Iteration 71, Losses: {'ner': 52.634571720184596}\n",
      "Iteration 71, Losses: {'ner': 52.886309244616804}\n",
      "Iteration 71, Losses: {'ner': 52.886311202561316}\n",
      "Iteration 71, Losses: {'ner': 59.705484231098495}\n",
      "Iteration 71, Losses: {'ner': 59.71383738639582}\n",
      "Iteration 71, Losses: {'ner': 59.71394046248623}\n",
      "Iteration 71, Losses: {'ner': 59.743075968100364}\n",
      "Iteration 71, Losses: {'ner': 65.28120496497503}\n",
      "Iteration 71, Losses: {'ner': 65.28122293199655}\n",
      "Iteration 71, Losses: {'ner': 67.89766358839785}\n",
      "Iteration 71, Losses: {'ner': 74.20042122489502}\n",
      "Iteration 71, Losses: {'ner': 78.7279576331229}\n",
      "Iteration 71, Losses: {'ner': 78.7282221374095}\n",
      "Iteration 71, Losses: {'ner': 78.73141617769946}\n",
      "Iteration 71, Losses: {'ner': 79.65822392370498}\n",
      "Iteration 71, Losses: {'ner': 80.14383888551072}\n",
      "Iteration 71, Losses: {'ner': 82.79246854840501}\n",
      "Iteration 71, Losses: {'ner': 82.79246856411258}\n",
      "Iteration 71, Losses: {'ner': 82.79246866627227}\n",
      "Iteration 72, Losses: {'ner': 2.9987988462636547e-07}\n",
      "Iteration 72, Losses: {'ner': 0.013778155731559707}\n",
      "Iteration 72, Losses: {'ner': 0.013797272517314722}\n",
      "Iteration 72, Losses: {'ner': 0.01791393567173507}\n",
      "Iteration 72, Losses: {'ner': 0.01823156873945012}\n",
      "Iteration 72, Losses: {'ner': 0.018255564854566832}\n",
      "Iteration 72, Losses: {'ner': 15.57077026931843}\n",
      "Iteration 72, Losses: {'ner': 18.22273548962815}\n",
      "Iteration 72, Losses: {'ner': 24.301633941004553}\n",
      "Iteration 72, Losses: {'ner': 24.302009697725243}\n",
      "Iteration 72, Losses: {'ner': 24.302011968574355}\n",
      "Iteration 72, Losses: {'ner': 28.86225723059939}\n",
      "Iteration 72, Losses: {'ner': 52.25670972692102}\n",
      "Iteration 72, Losses: {'ner': 57.78001607386904}\n",
      "Iteration 72, Losses: {'ner': 59.93702550151213}\n",
      "Iteration 72, Losses: {'ner': 59.93888208942429}\n",
      "Iteration 72, Losses: {'ner': 59.94247496830101}\n",
      "Iteration 72, Losses: {'ner': 62.077632038131554}\n",
      "Iteration 72, Losses: {'ner': 62.74958705832936}\n",
      "Iteration 72, Losses: {'ner': 62.7496006626805}\n",
      "Iteration 72, Losses: {'ner': 63.259811123348214}\n",
      "Iteration 72, Losses: {'ner': 66.51835968301829}\n",
      "Iteration 72, Losses: {'ner': 72.43728157566005}\n",
      "Iteration 72, Losses: {'ner': 77.83214933044341}\n",
      "Iteration 72, Losses: {'ner': 77.83259306915792}\n",
      "Iteration 72, Losses: {'ner': 77.92750923186644}\n",
      "Iteration 72, Losses: {'ner': 77.92777881582558}\n",
      "Iteration 72, Losses: {'ner': 78.02382729727637}\n",
      "Iteration 72, Losses: {'ner': 80.0193412467613}\n",
      "Iteration 72, Losses: {'ner': 81.82205095105222}\n",
      "Iteration 72, Losses: {'ner': 81.82206597789538}\n",
      "Iteration 73, Losses: {'ner': 1.6130914589879335}\n",
      "Iteration 73, Losses: {'ner': 10.19242785431487}\n",
      "Iteration 73, Losses: {'ner': 11.294224300216374}\n",
      "Iteration 73, Losses: {'ner': 15.205465738051398}\n",
      "Iteration 73, Losses: {'ner': 16.35240907828075}\n",
      "Iteration 73, Losses: {'ner': 20.934946718234468}\n",
      "Iteration 73, Losses: {'ner': 20.95313075729073}\n",
      "Iteration 73, Losses: {'ner': 20.95377703976028}\n",
      "Iteration 73, Losses: {'ner': 20.953823017568478}\n",
      "Iteration 73, Losses: {'ner': 20.953823022214113}\n",
      "Iteration 73, Losses: {'ner': 20.984906340724326}\n",
      "Iteration 73, Losses: {'ner': 20.984906752444854}\n",
      "Iteration 73, Losses: {'ner': 28.31598265307132}\n",
      "Iteration 73, Losses: {'ner': 28.317726240825387}\n",
      "Iteration 73, Losses: {'ner': 32.06429480830039}\n",
      "Iteration 73, Losses: {'ner': 32.06483696945232}\n",
      "Iteration 73, Losses: {'ner': 32.07172750808455}\n",
      "Iteration 73, Losses: {'ner': 34.99168179492517}\n",
      "Iteration 73, Losses: {'ner': 44.04112796402008}\n",
      "Iteration 73, Losses: {'ner': 52.0803318529323}\n",
      "Iteration 73, Losses: {'ner': 52.080332944752776}\n",
      "Iteration 73, Losses: {'ner': 52.08038308159012}\n",
      "Iteration 73, Losses: {'ner': 52.080383089556754}\n",
      "Iteration 73, Losses: {'ner': 52.080384724404134}\n",
      "Iteration 73, Losses: {'ner': 52.082829127900034}\n",
      "Iteration 73, Losses: {'ner': 59.1341910486413}\n",
      "Iteration 73, Losses: {'ner': 62.30175961296071}\n",
      "Iteration 73, Losses: {'ner': 62.60874513644162}\n",
      "Iteration 73, Losses: {'ner': 64.54174635395944}\n",
      "Iteration 73, Losses: {'ner': 67.76453261610354}\n",
      "Iteration 73, Losses: {'ner': 67.76453289764133}\n",
      "Iteration 74, Losses: {'ner': 0.0004690960294112895}\n",
      "Iteration 74, Losses: {'ner': 0.41670025118320964}\n",
      "Iteration 74, Losses: {'ner': 1.8799690968429112}\n",
      "Iteration 74, Losses: {'ner': 6.328393921528646}\n",
      "Iteration 74, Losses: {'ner': 6.328853640460352}\n",
      "Iteration 74, Losses: {'ner': 6.32994928151739}\n",
      "Iteration 74, Losses: {'ner': 7.529655965987668}\n",
      "Iteration 74, Losses: {'ner': 11.718819963517516}\n",
      "Iteration 74, Losses: {'ner': 15.118193635383026}\n",
      "Iteration 74, Losses: {'ner': 17.112206036838792}\n",
      "Iteration 74, Losses: {'ner': 17.13410362469452}\n",
      "Iteration 74, Losses: {'ner': 17.134628453941456}\n",
      "Iteration 74, Losses: {'ner': 17.145722316358402}\n",
      "Iteration 74, Losses: {'ner': 25.323437276356792}\n",
      "Iteration 74, Losses: {'ner': 28.47239738418789}\n",
      "Iteration 74, Losses: {'ner': 28.472530482762657}\n",
      "Iteration 74, Losses: {'ner': 29.963951120604804}\n",
      "Iteration 74, Losses: {'ner': 29.96432849978133}\n",
      "Iteration 74, Losses: {'ner': 29.968087282212622}\n",
      "Iteration 74, Losses: {'ner': 29.96808728744017}\n",
      "Iteration 74, Losses: {'ner': 30.125404833226007}\n",
      "Iteration 74, Losses: {'ner': 36.35674787422662}\n",
      "Iteration 74, Losses: {'ner': 36.430112854978475}\n",
      "Iteration 74, Losses: {'ner': 41.87994965120453}\n",
      "Iteration 74, Losses: {'ner': 42.2709938995886}\n",
      "Iteration 74, Losses: {'ner': 42.28962341238562}\n",
      "Iteration 74, Losses: {'ner': 43.33606495808558}\n",
      "Iteration 74, Losses: {'ner': 53.55108077119606}\n",
      "Iteration 74, Losses: {'ner': 74.55594179498051}\n",
      "Iteration 74, Losses: {'ner': 85.54635025812748}\n",
      "Iteration 74, Losses: {'ner': 85.63378972896822}\n",
      "Iteration 75, Losses: {'ner': 2.570714905510135}\n",
      "Iteration 75, Losses: {'ner': 2.5707158194858306}\n",
      "Iteration 75, Losses: {'ner': 2.5716284286847686}\n",
      "Iteration 75, Losses: {'ner': 6.76497438901273}\n",
      "Iteration 75, Losses: {'ner': 8.178923693830743}\n",
      "Iteration 75, Losses: {'ner': 13.637130788116567}\n",
      "Iteration 75, Losses: {'ner': 16.005906277715216}\n",
      "Iteration 75, Losses: {'ner': 16.006898508106346}\n",
      "Iteration 75, Losses: {'ner': 16.036572449751223}\n",
      "Iteration 75, Losses: {'ner': 16.057845033375216}\n",
      "Iteration 75, Losses: {'ner': 18.624847164010244}\n",
      "Iteration 75, Losses: {'ner': 18.63339773347154}\n",
      "Iteration 75, Losses: {'ner': 18.638170317288377}\n",
      "Iteration 75, Losses: {'ner': 18.638170345006877}\n",
      "Iteration 75, Losses: {'ner': 18.657939956099778}\n",
      "Iteration 75, Losses: {'ner': 19.69897010557257}\n",
      "Iteration 75, Losses: {'ner': 19.698977679851485}\n",
      "Iteration 75, Losses: {'ner': 21.983956097986542}\n",
      "Iteration 75, Losses: {'ner': 22.00979299134437}\n",
      "Iteration 75, Losses: {'ner': 22.31986161564992}\n",
      "Iteration 75, Losses: {'ner': 34.33169628496226}\n",
      "Iteration 75, Losses: {'ner': 34.33199533210054}\n",
      "Iteration 75, Losses: {'ner': 36.31301806224789}\n",
      "Iteration 75, Losses: {'ner': 36.31304459952866}\n",
      "Iteration 75, Losses: {'ner': 36.31322511983235}\n",
      "Iteration 75, Losses: {'ner': 36.313826298505745}\n",
      "Iteration 75, Losses: {'ner': 36.313826326112874}\n",
      "Iteration 75, Losses: {'ner': 42.80505031640794}\n",
      "Iteration 75, Losses: {'ner': 42.808509402583255}\n",
      "Iteration 75, Losses: {'ner': 50.37370999007289}\n",
      "Iteration 75, Losses: {'ner': 59.3047986091471}\n",
      "Iteration 76, Losses: {'ner': 7.725112685101583}\n",
      "Iteration 76, Losses: {'ner': 11.450518553560686}\n",
      "Iteration 76, Losses: {'ner': 11.961792891685352}\n",
      "Iteration 76, Losses: {'ner': 11.965951315874484}\n",
      "Iteration 76, Losses: {'ner': 11.965952984858244}\n",
      "Iteration 76, Losses: {'ner': 11.987388127534867}\n",
      "Iteration 76, Losses: {'ner': 13.736195830772887}\n",
      "Iteration 76, Losses: {'ner': 20.24325640901097}\n",
      "Iteration 76, Losses: {'ner': 20.243579160009343}\n",
      "Iteration 76, Losses: {'ner': 27.08210768011729}\n",
      "Iteration 76, Losses: {'ner': 32.188232661462536}\n",
      "Iteration 76, Losses: {'ner': 35.239191371999354}\n",
      "Iteration 76, Losses: {'ner': 35.25696920920358}\n",
      "Iteration 76, Losses: {'ner': 39.00750309867943}\n",
      "Iteration 76, Losses: {'ner': 39.00761957495485}\n",
      "Iteration 76, Losses: {'ner': 39.00762570819615}\n",
      "Iteration 76, Losses: {'ner': 39.007626124856706}\n",
      "Iteration 76, Losses: {'ner': 44.045341605371014}\n",
      "Iteration 76, Losses: {'ner': 47.22658658293815}\n",
      "Iteration 76, Losses: {'ner': 47.23455704432301}\n",
      "Iteration 76, Losses: {'ner': 49.22894974650544}\n",
      "Iteration 76, Losses: {'ner': 49.22895137384938}\n",
      "Iteration 76, Losses: {'ner': 50.515002884598616}\n",
      "Iteration 76, Losses: {'ner': 50.5793343366483}\n",
      "Iteration 76, Losses: {'ner': 50.57943240980581}\n",
      "Iteration 76, Losses: {'ner': 51.771576740682384}\n",
      "Iteration 76, Losses: {'ner': 51.77158075810803}\n",
      "Iteration 76, Losses: {'ner': 53.780460555538696}\n",
      "Iteration 76, Losses: {'ner': 53.78282922157542}\n",
      "Iteration 76, Losses: {'ner': 66.90802397145428}\n",
      "Iteration 76, Losses: {'ner': 68.80450848368008}\n",
      "Iteration 77, Losses: {'ner': 2.2657071056993083}\n",
      "Iteration 77, Losses: {'ner': 2.266628337772718}\n",
      "Iteration 77, Losses: {'ner': 2.311111660651515}\n",
      "Iteration 77, Losses: {'ner': 2.3591372446567873}\n",
      "Iteration 77, Losses: {'ner': 2.3593459312801497}\n",
      "Iteration 77, Losses: {'ner': 2.4224744515778465}\n",
      "Iteration 77, Losses: {'ner': 2.4224748940022796}\n",
      "Iteration 77, Losses: {'ner': 2.4224753649225503}\n",
      "Iteration 77, Losses: {'ner': 4.032172087016202}\n",
      "Iteration 77, Losses: {'ner': 5.414635172970226}\n",
      "Iteration 77, Losses: {'ner': 10.683309631758284}\n",
      "Iteration 77, Losses: {'ner': 13.717468782382864}\n",
      "Iteration 77, Losses: {'ner': 13.717477343696343}\n",
      "Iteration 77, Losses: {'ner': 13.717598342833622}\n",
      "Iteration 77, Losses: {'ner': 28.36498348756819}\n",
      "Iteration 77, Losses: {'ner': 28.36499369527499}\n",
      "Iteration 77, Losses: {'ner': 28.36499369949684}\n",
      "Iteration 77, Losses: {'ner': 28.367366033873562}\n",
      "Iteration 77, Losses: {'ner': 45.07552413729015}\n",
      "Iteration 77, Losses: {'ner': 45.07555042290783}\n",
      "Iteration 77, Losses: {'ner': 53.20815304263452}\n",
      "Iteration 77, Losses: {'ner': 54.488907612878364}\n",
      "Iteration 77, Losses: {'ner': 58.0650647582471}\n",
      "Iteration 77, Losses: {'ner': 62.814296240339075}\n",
      "Iteration 77, Losses: {'ner': 66.94561672722207}\n",
      "Iteration 77, Losses: {'ner': 66.94563157860856}\n",
      "Iteration 77, Losses: {'ner': 66.97139515374234}\n",
      "Iteration 77, Losses: {'ner': 71.58794432986996}\n",
      "Iteration 77, Losses: {'ner': 71.58794433632296}\n",
      "Iteration 77, Losses: {'ner': 72.14290750467362}\n",
      "Iteration 77, Losses: {'ner': 72.14291052841675}\n",
      "Iteration 78, Losses: {'ner': 5.3744720012837604e-08}\n",
      "Iteration 78, Losses: {'ner': 0.2878133627903484}\n",
      "Iteration 78, Losses: {'ner': 0.32168095082574716}\n",
      "Iteration 78, Losses: {'ner': 0.4600890176045587}\n",
      "Iteration 78, Losses: {'ner': 0.7241578438642678}\n",
      "Iteration 78, Losses: {'ner': 2.8030099266652866}\n",
      "Iteration 78, Losses: {'ner': 2.8180463505444457}\n",
      "Iteration 78, Losses: {'ner': 5.834087184546283}\n",
      "Iteration 78, Losses: {'ner': 16.918731559789958}\n",
      "Iteration 78, Losses: {'ner': 16.918732770926482}\n",
      "Iteration 78, Losses: {'ner': 22.669142525900213}\n",
      "Iteration 78, Losses: {'ner': 26.849953484707633}\n",
      "Iteration 78, Losses: {'ner': 29.687643296273652}\n",
      "Iteration 78, Losses: {'ner': 29.801567228994006}\n",
      "Iteration 78, Losses: {'ner': 29.80156777825491}\n",
      "Iteration 78, Losses: {'ner': 29.801569365196652}\n",
      "Iteration 78, Losses: {'ner': 47.82193925774789}\n",
      "Iteration 78, Losses: {'ner': 51.554398699998956}\n",
      "Iteration 78, Losses: {'ner': 51.73269911502355}\n",
      "Iteration 78, Losses: {'ner': 51.73295600665884}\n",
      "Iteration 78, Losses: {'ner': 59.746286156630305}\n",
      "Iteration 78, Losses: {'ner': 60.245948036199074}\n",
      "Iteration 78, Losses: {'ner': 60.24594803779886}\n",
      "Iteration 78, Losses: {'ner': 64.36806374754636}\n",
      "Iteration 78, Losses: {'ner': 64.37278384009329}\n",
      "Iteration 78, Losses: {'ner': 64.37278394254393}\n",
      "Iteration 78, Losses: {'ner': 64.37414297456367}\n",
      "Iteration 78, Losses: {'ner': 64.37415341658398}\n",
      "Iteration 78, Losses: {'ner': 71.26382666206464}\n",
      "Iteration 78, Losses: {'ner': 71.26384545423518}\n",
      "Iteration 78, Losses: {'ner': 71.72823497820883}\n",
      "Iteration 79, Losses: {'ner': 0.15886038926204293}\n",
      "Iteration 79, Losses: {'ner': 3.533298713741219}\n",
      "Iteration 79, Losses: {'ner': 8.018992255411362}\n",
      "Iteration 79, Losses: {'ner': 8.641829618294695}\n",
      "Iteration 79, Losses: {'ner': 8.641830508408914}\n",
      "Iteration 79, Losses: {'ner': 8.643133861211235}\n",
      "Iteration 79, Losses: {'ner': 8.970741278291216}\n",
      "Iteration 79, Losses: {'ner': 8.970741667025827}\n",
      "Iteration 79, Losses: {'ner': 17.200562402266108}\n",
      "Iteration 79, Losses: {'ner': 20.03203017485235}\n",
      "Iteration 79, Losses: {'ner': 31.910557165507953}\n",
      "Iteration 79, Losses: {'ner': 34.316706036669494}\n",
      "Iteration 79, Losses: {'ner': 35.622638262302665}\n",
      "Iteration 79, Losses: {'ner': 37.76722265795245}\n",
      "Iteration 79, Losses: {'ner': 37.76726131132898}\n",
      "Iteration 79, Losses: {'ner': 37.76738969084754}\n",
      "Iteration 79, Losses: {'ner': 37.810818619066005}\n",
      "Iteration 79, Losses: {'ner': 37.822928757817444}\n",
      "Iteration 79, Losses: {'ner': 39.629713359176705}\n",
      "Iteration 79, Losses: {'ner': 42.50081583663576}\n",
      "Iteration 79, Losses: {'ner': 48.496812744631065}\n",
      "Iteration 79, Losses: {'ner': 53.736446034779675}\n",
      "Iteration 79, Losses: {'ner': 53.73670415895747}\n",
      "Iteration 79, Losses: {'ner': 53.736704164257475}\n",
      "Iteration 79, Losses: {'ner': 53.74759222065963}\n",
      "Iteration 79, Losses: {'ner': 54.2142711005846}\n",
      "Iteration 79, Losses: {'ner': 54.2193666194438}\n",
      "Iteration 79, Losses: {'ner': 54.427842411414865}\n",
      "Iteration 79, Losses: {'ner': 54.42787487958228}\n",
      "Iteration 79, Losses: {'ner': 54.42789114101361}\n",
      "Iteration 79, Losses: {'ner': 54.427892055989034}\n",
      "Iteration 80, Losses: {'ner': 0.0011553363380179785}\n",
      "Iteration 80, Losses: {'ner': 2.807463217041353}\n",
      "Iteration 80, Losses: {'ner': 3.316173811816062}\n",
      "Iteration 80, Losses: {'ner': 3.345506922185973}\n",
      "Iteration 80, Losses: {'ner': 3.425711907635516}\n",
      "Iteration 80, Losses: {'ner': 8.268689765904046}\n",
      "Iteration 80, Losses: {'ner': 8.268904317896759}\n",
      "Iteration 80, Losses: {'ner': 9.38835083734206}\n",
      "Iteration 80, Losses: {'ner': 9.388350837460344}\n",
      "Iteration 80, Losses: {'ner': 10.1131984668554}\n",
      "Iteration 80, Losses: {'ner': 13.171197914977713}\n",
      "Iteration 80, Losses: {'ner': 13.171281254072655}\n",
      "Iteration 80, Losses: {'ner': 13.204058036218049}\n",
      "Iteration 80, Losses: {'ner': 13.20405804143225}\n",
      "Iteration 80, Losses: {'ner': 16.385844658843464}\n",
      "Iteration 80, Losses: {'ner': 22.983353446570725}\n",
      "Iteration 80, Losses: {'ner': 22.98335344659572}\n",
      "Iteration 80, Losses: {'ner': 23.92856399274922}\n",
      "Iteration 80, Losses: {'ner': 31.672983680244613}\n",
      "Iteration 80, Losses: {'ner': 31.677431325382695}\n",
      "Iteration 80, Losses: {'ner': 32.254318815952004}\n",
      "Iteration 80, Losses: {'ner': 46.47393027336802}\n",
      "Iteration 80, Losses: {'ner': 48.010360144663366}\n",
      "Iteration 80, Losses: {'ner': 50.11045448649375}\n",
      "Iteration 80, Losses: {'ner': 51.266519725315725}\n",
      "Iteration 80, Losses: {'ner': 51.30155727905659}\n",
      "Iteration 80, Losses: {'ner': 54.287392563000104}\n",
      "Iteration 80, Losses: {'ner': 54.2890048206112}\n",
      "Iteration 80, Losses: {'ner': 54.2903979332559}\n",
      "Iteration 80, Losses: {'ner': 57.59561772923015}\n",
      "Iteration 80, Losses: {'ner': 57.59561881757024}\n",
      "Iteration 81, Losses: {'ner': 0.00021007546558638544}\n",
      "Iteration 81, Losses: {'ner': 5.929221581266284}\n",
      "Iteration 81, Losses: {'ner': 14.855004237171743}\n",
      "Iteration 81, Losses: {'ner': 14.867760641569744}\n",
      "Iteration 81, Losses: {'ner': 16.756593224573635}\n",
      "Iteration 81, Losses: {'ner': 16.756593224574985}\n",
      "Iteration 81, Losses: {'ner': 22.3598583838546}\n",
      "Iteration 81, Losses: {'ner': 22.898695120677548}\n",
      "Iteration 81, Losses: {'ner': 22.91162713812086}\n",
      "Iteration 81, Losses: {'ner': 22.911627149030906}\n",
      "Iteration 81, Losses: {'ner': 22.92398154865059}\n",
      "Iteration 81, Losses: {'ner': 31.330879968284187}\n",
      "Iteration 81, Losses: {'ner': 31.37381840112531}\n",
      "Iteration 81, Losses: {'ner': 32.67853053091881}\n",
      "Iteration 81, Losses: {'ner': 32.70695567395529}\n",
      "Iteration 81, Losses: {'ner': 32.80611790137243}\n",
      "Iteration 81, Losses: {'ner': 33.70938438250015}\n",
      "Iteration 81, Losses: {'ner': 33.70941088491244}\n",
      "Iteration 81, Losses: {'ner': 33.70972684200637}\n",
      "Iteration 81, Losses: {'ner': 33.77158910364581}\n",
      "Iteration 81, Losses: {'ner': 34.09004263424009}\n",
      "Iteration 81, Losses: {'ner': 34.09013116164322}\n",
      "Iteration 81, Losses: {'ner': 34.0906788130933}\n",
      "Iteration 81, Losses: {'ner': 38.84149898818622}\n",
      "Iteration 81, Losses: {'ner': 44.807385781484406}\n",
      "Iteration 81, Losses: {'ner': 44.80740360995938}\n",
      "Iteration 81, Losses: {'ner': 45.5992974986304}\n",
      "Iteration 81, Losses: {'ner': 45.604347017344566}\n",
      "Iteration 81, Losses: {'ner': 49.64103124951913}\n",
      "Iteration 81, Losses: {'ner': 53.210789332655246}\n",
      "Iteration 81, Losses: {'ner': 53.210870013181214}\n",
      "Iteration 82, Losses: {'ner': 1.1568328968979835}\n",
      "Iteration 82, Losses: {'ner': 3.9752719589544667}\n",
      "Iteration 82, Losses: {'ner': 10.77973733847029}\n",
      "Iteration 82, Losses: {'ner': 10.779745878986253}\n",
      "Iteration 82, Losses: {'ner': 13.949520254357914}\n",
      "Iteration 82, Losses: {'ner': 14.27327383368609}\n",
      "Iteration 82, Losses: {'ner': 16.692016162781627}\n",
      "Iteration 82, Losses: {'ner': 16.72147306800421}\n",
      "Iteration 82, Losses: {'ner': 17.07584103358924}\n",
      "Iteration 82, Losses: {'ner': 17.084694055851166}\n",
      "Iteration 82, Losses: {'ner': 17.084694653740645}\n",
      "Iteration 82, Losses: {'ner': 17.08469952394751}\n",
      "Iteration 82, Losses: {'ner': 17.848578502464253}\n",
      "Iteration 82, Losses: {'ner': 17.85118847139064}\n",
      "Iteration 82, Losses: {'ner': 26.123575760455097}\n",
      "Iteration 82, Losses: {'ner': 26.123576750302636}\n",
      "Iteration 82, Losses: {'ner': 26.125600315374697}\n",
      "Iteration 82, Losses: {'ner': 26.164104636475862}\n",
      "Iteration 82, Losses: {'ner': 29.727075744727305}\n",
      "Iteration 82, Losses: {'ner': 29.72771146484989}\n",
      "Iteration 82, Losses: {'ner': 29.730926347137736}\n",
      "Iteration 82, Losses: {'ner': 29.792128102137042}\n",
      "Iteration 82, Losses: {'ner': 29.79212834365102}\n",
      "Iteration 82, Losses: {'ner': 29.971898583219975}\n",
      "Iteration 82, Losses: {'ner': 29.972703659607355}\n",
      "Iteration 82, Losses: {'ner': 30.17481308398608}\n",
      "Iteration 82, Losses: {'ner': 30.1748584540742}\n",
      "Iteration 82, Losses: {'ner': 33.53371803112134}\n",
      "Iteration 82, Losses: {'ner': 35.19373982438398}\n",
      "Iteration 82, Losses: {'ner': 35.20671300744847}\n",
      "Iteration 82, Losses: {'ner': 46.57353530967118}\n",
      "Iteration 83, Losses: {'ner': 3.879131348936165e-05}\n",
      "Iteration 83, Losses: {'ner': 0.11935336708702929}\n",
      "Iteration 83, Losses: {'ner': 1.5996537220251914}\n",
      "Iteration 83, Losses: {'ner': 1.8951884947864548}\n",
      "Iteration 83, Losses: {'ner': 1.895258303040475}\n",
      "Iteration 83, Losses: {'ner': 1.895258305117815}\n",
      "Iteration 83, Losses: {'ner': 4.956831027706084}\n",
      "Iteration 83, Losses: {'ner': 6.402611147692871}\n",
      "Iteration 83, Losses: {'ner': 11.39001876514579}\n",
      "Iteration 83, Losses: {'ner': 11.390018765633636}\n",
      "Iteration 83, Losses: {'ner': 13.314414849405626}\n",
      "Iteration 83, Losses: {'ner': 13.314414853547968}\n",
      "Iteration 83, Losses: {'ner': 13.83887385016826}\n",
      "Iteration 83, Losses: {'ner': 18.576097796206863}\n",
      "Iteration 83, Losses: {'ner': 18.57616573391115}\n",
      "Iteration 83, Losses: {'ner': 18.781383960715278}\n",
      "Iteration 83, Losses: {'ner': 18.78139015536078}\n",
      "Iteration 83, Losses: {'ner': 22.843052019837415}\n",
      "Iteration 83, Losses: {'ner': 22.84344444973436}\n",
      "Iteration 83, Losses: {'ner': 30.821602357414474}\n",
      "Iteration 83, Losses: {'ner': 30.823385768631983}\n",
      "Iteration 83, Losses: {'ner': 46.81782228113438}\n",
      "Iteration 83, Losses: {'ner': 49.33209576356566}\n",
      "Iteration 83, Losses: {'ner': 49.332099041138335}\n",
      "Iteration 83, Losses: {'ner': 49.33218275114026}\n",
      "Iteration 83, Losses: {'ner': 49.332193634888924}\n",
      "Iteration 83, Losses: {'ner': 49.33558739711431}\n",
      "Iteration 83, Losses: {'ner': 49.33558766952595}\n",
      "Iteration 83, Losses: {'ner': 51.567252655172545}\n",
      "Iteration 83, Losses: {'ner': 51.567334521290206}\n",
      "Iteration 83, Losses: {'ner': 62.063383280786745}\n",
      "Iteration 84, Losses: {'ner': 7.407136162309724e-07}\n",
      "Iteration 84, Losses: {'ner': 2.135943011689896}\n",
      "Iteration 84, Losses: {'ner': 2.136682138857355}\n",
      "Iteration 84, Losses: {'ner': 8.758532380060043}\n",
      "Iteration 84, Losses: {'ner': 8.762174437745653}\n",
      "Iteration 84, Losses: {'ner': 13.149028241492237}\n",
      "Iteration 84, Losses: {'ner': 13.151866256100275}\n",
      "Iteration 84, Losses: {'ner': 13.151866256243299}\n",
      "Iteration 84, Losses: {'ner': 13.344957031483851}\n",
      "Iteration 84, Losses: {'ner': 13.34495722864686}\n",
      "Iteration 84, Losses: {'ner': 19.55949839829419}\n",
      "Iteration 84, Losses: {'ner': 19.559498649720677}\n",
      "Iteration 84, Losses: {'ner': 23.228915349920037}\n",
      "Iteration 84, Losses: {'ner': 25.061865281034912}\n",
      "Iteration 84, Losses: {'ner': 25.13947952542335}\n",
      "Iteration 84, Losses: {'ner': 27.24825338850633}\n",
      "Iteration 84, Losses: {'ner': 27.31866861085701}\n",
      "Iteration 84, Losses: {'ner': 27.318701433893313}\n",
      "Iteration 84, Losses: {'ner': 27.330314286068525}\n",
      "Iteration 84, Losses: {'ner': 28.368913649488036}\n",
      "Iteration 84, Losses: {'ner': 29.93526754478447}\n",
      "Iteration 84, Losses: {'ner': 30.851117391225163}\n",
      "Iteration 84, Losses: {'ner': 44.67276264877996}\n",
      "Iteration 84, Losses: {'ner': 44.67276354455387}\n",
      "Iteration 84, Losses: {'ner': 44.674141241169565}\n",
      "Iteration 84, Losses: {'ner': 44.77836358935344}\n",
      "Iteration 84, Losses: {'ner': 44.778370574600544}\n",
      "Iteration 84, Losses: {'ner': 44.778378520548905}\n",
      "Iteration 84, Losses: {'ner': 46.76030367734208}\n",
      "Iteration 84, Losses: {'ner': 46.76030368221538}\n",
      "Iteration 84, Losses: {'ner': 50.08360378992938}\n",
      "Iteration 85, Losses: {'ner': 5.6558814320838975}\n",
      "Iteration 85, Losses: {'ner': 5.655881530663786}\n",
      "Iteration 85, Losses: {'ner': 7.52734190772367}\n",
      "Iteration 85, Losses: {'ner': 9.462049214387955}\n",
      "Iteration 85, Losses: {'ner': 9.462074006325967}\n",
      "Iteration 85, Losses: {'ner': 10.69377046542236}\n",
      "Iteration 85, Losses: {'ner': 16.709989760697148}\n",
      "Iteration 85, Losses: {'ner': 16.709989765117733}\n",
      "Iteration 85, Losses: {'ner': 16.709990090850972}\n",
      "Iteration 85, Losses: {'ner': 16.71012092243875}\n",
      "Iteration 85, Losses: {'ner': 22.028119418661007}\n",
      "Iteration 85, Losses: {'ner': 26.627728511879905}\n",
      "Iteration 85, Losses: {'ner': 28.547449082386045}\n",
      "Iteration 85, Losses: {'ner': 28.616769386226924}\n",
      "Iteration 85, Losses: {'ner': 35.650593625518574}\n",
      "Iteration 85, Losses: {'ner': 35.880972444719156}\n",
      "Iteration 85, Losses: {'ner': 36.57962305034348}\n",
      "Iteration 85, Losses: {'ner': 36.585179547655535}\n",
      "Iteration 85, Losses: {'ner': 43.89893583109231}\n",
      "Iteration 85, Losses: {'ner': 43.89895312172467}\n",
      "Iteration 85, Losses: {'ner': 44.818263186955534}\n",
      "Iteration 85, Losses: {'ner': 45.7565175066356}\n",
      "Iteration 85, Losses: {'ner': 45.75704956299267}\n",
      "Iteration 85, Losses: {'ner': 47.80401061179042}\n",
      "Iteration 85, Losses: {'ner': 49.95811062629552}\n",
      "Iteration 85, Losses: {'ner': 50.33413393587958}\n",
      "Iteration 85, Losses: {'ner': 50.33416629635569}\n",
      "Iteration 85, Losses: {'ner': 51.401241145662105}\n",
      "Iteration 85, Losses: {'ner': 51.40183937183963}\n",
      "Iteration 85, Losses: {'ner': 51.40203706857134}\n",
      "Iteration 85, Losses: {'ner': 51.40224096897098}\n",
      "Iteration 86, Losses: {'ner': 0.041115928713891074}\n",
      "Iteration 86, Losses: {'ner': 6.064418755810204}\n",
      "Iteration 86, Losses: {'ner': 6.064453654908989}\n",
      "Iteration 86, Losses: {'ner': 6.064469221583951}\n",
      "Iteration 86, Losses: {'ner': 7.900124915156389}\n",
      "Iteration 86, Losses: {'ner': 7.900150867757558}\n",
      "Iteration 86, Losses: {'ner': 24.69589695156342}\n",
      "Iteration 86, Losses: {'ner': 25.971409221778984}\n",
      "Iteration 86, Losses: {'ner': 25.971410717440286}\n",
      "Iteration 86, Losses: {'ner': 30.086476338599674}\n",
      "Iteration 86, Losses: {'ner': 30.08647633864145}\n",
      "Iteration 86, Losses: {'ner': 38.441339931246965}\n",
      "Iteration 86, Losses: {'ner': 38.44134254064818}\n",
      "Iteration 86, Losses: {'ner': 43.20074441651213}\n",
      "Iteration 86, Losses: {'ner': 43.200758012566475}\n",
      "Iteration 86, Losses: {'ner': 43.200758012641096}\n",
      "Iteration 86, Losses: {'ner': 45.187464118577864}\n",
      "Iteration 86, Losses: {'ner': 50.097218180400056}\n",
      "Iteration 86, Losses: {'ner': 50.275309341811486}\n",
      "Iteration 86, Losses: {'ner': 50.5207623944804}\n",
      "Iteration 86, Losses: {'ner': 50.58347684822701}\n",
      "Iteration 86, Losses: {'ner': 50.62558801905624}\n",
      "Iteration 86, Losses: {'ner': 53.33648385660138}\n",
      "Iteration 86, Losses: {'ner': 54.15048076164192}\n",
      "Iteration 86, Losses: {'ner': 56.315206334672325}\n",
      "Iteration 86, Losses: {'ner': 57.80705154080344}\n",
      "Iteration 86, Losses: {'ner': 57.8072660368549}\n",
      "Iteration 86, Losses: {'ner': 61.75491556515024}\n",
      "Iteration 86, Losses: {'ner': 62.44627662416175}\n",
      "Iteration 86, Losses: {'ner': 62.44627663394199}\n",
      "Iteration 86, Losses: {'ner': 62.44673311621122}\n",
      "Iteration 87, Losses: {'ner': 1.8819846748145386}\n",
      "Iteration 87, Losses: {'ner': 1.8823065985267584}\n",
      "Iteration 87, Losses: {'ner': 1.8823069256406004}\n",
      "Iteration 87, Losses: {'ner': 5.410278891544684}\n",
      "Iteration 87, Losses: {'ner': 5.410706969379844}\n",
      "Iteration 87, Losses: {'ner': 8.706148132060855}\n",
      "Iteration 87, Losses: {'ner': 8.706154638477164}\n",
      "Iteration 87, Losses: {'ner': 13.15833064540589}\n",
      "Iteration 87, Losses: {'ner': 13.302893549756458}\n",
      "Iteration 87, Losses: {'ner': 14.027509404999128}\n",
      "Iteration 87, Losses: {'ner': 14.40856265388639}\n",
      "Iteration 87, Losses: {'ner': 24.918689389040516}\n",
      "Iteration 87, Losses: {'ner': 26.718836070461574}\n",
      "Iteration 87, Losses: {'ner': 33.13772410047249}\n",
      "Iteration 87, Losses: {'ner': 44.80044738809423}\n",
      "Iteration 87, Losses: {'ner': 44.80044845258415}\n",
      "Iteration 87, Losses: {'ner': 44.80044872712772}\n",
      "Iteration 87, Losses: {'ner': 44.800449751794346}\n",
      "Iteration 87, Losses: {'ner': 44.80044975184672}\n",
      "Iteration 87, Losses: {'ner': 44.80053917070823}\n",
      "Iteration 87, Losses: {'ner': 47.38541664806891}\n",
      "Iteration 87, Losses: {'ner': 47.38541664808352}\n",
      "Iteration 87, Losses: {'ner': 51.84390613296446}\n",
      "Iteration 87, Losses: {'ner': 52.17629007765663}\n",
      "Iteration 87, Losses: {'ner': 52.17629025166597}\n",
      "Iteration 87, Losses: {'ner': 52.49800395226448}\n",
      "Iteration 87, Losses: {'ner': 52.49873721942472}\n",
      "Iteration 87, Losses: {'ner': 52.49879255604336}\n",
      "Iteration 87, Losses: {'ner': 54.77905190394008}\n",
      "Iteration 87, Losses: {'ner': 54.8993894775146}\n",
      "Iteration 87, Losses: {'ner': 55.274799922222}\n",
      "Iteration 88, Losses: {'ner': 1.135286040204165}\n",
      "Iteration 88, Losses: {'ner': 1.2617866634487065}\n",
      "Iteration 88, Losses: {'ner': 4.060028703982922}\n",
      "Iteration 88, Losses: {'ner': 5.980391753873349}\n",
      "Iteration 88, Losses: {'ner': 5.9805137178626016}\n",
      "Iteration 88, Losses: {'ner': 22.725549856410215}\n",
      "Iteration 88, Losses: {'ner': 22.725550049009207}\n",
      "Iteration 88, Losses: {'ner': 23.854805837248836}\n",
      "Iteration 88, Losses: {'ner': 24.117837036318058}\n",
      "Iteration 88, Losses: {'ner': 25.610057678430014}\n",
      "Iteration 88, Losses: {'ner': 27.439454721022447}\n",
      "Iteration 88, Losses: {'ner': 27.439454753900236}\n",
      "Iteration 88, Losses: {'ner': 29.439392086872125}\n",
      "Iteration 88, Losses: {'ner': 29.43948854415588}\n",
      "Iteration 88, Losses: {'ner': 29.439488656963544}\n",
      "Iteration 88, Losses: {'ner': 36.696199775410555}\n",
      "Iteration 88, Losses: {'ner': 36.70486208874238}\n",
      "Iteration 88, Losses: {'ner': 39.75650409212479}\n",
      "Iteration 88, Losses: {'ner': 39.756504245308285}\n",
      "Iteration 88, Losses: {'ner': 41.49968058307105}\n",
      "Iteration 88, Losses: {'ner': 43.95282258827199}\n",
      "Iteration 88, Losses: {'ner': 45.88471053183079}\n",
      "Iteration 88, Losses: {'ner': 47.30340658369351}\n",
      "Iteration 88, Losses: {'ner': 53.80564414221331}\n",
      "Iteration 88, Losses: {'ner': 53.805644494441275}\n",
      "Iteration 88, Losses: {'ner': 53.80564453157591}\n",
      "Iteration 88, Losses: {'ner': 53.80589120595255}\n",
      "Iteration 88, Losses: {'ner': 63.58386895948067}\n",
      "Iteration 88, Losses: {'ner': 63.58386906195223}\n",
      "Iteration 88, Losses: {'ner': 63.58386918835014}\n",
      "Iteration 88, Losses: {'ner': 65.50704442535809}\n",
      "Iteration 89, Losses: {'ner': 0.002199615693269764}\n",
      "Iteration 89, Losses: {'ner': 0.0021996215168777295}\n",
      "Iteration 89, Losses: {'ner': 0.002494579847882592}\n",
      "Iteration 89, Losses: {'ner': 0.0025921440333150332}\n",
      "Iteration 89, Losses: {'ner': 1.5699713380557172}\n",
      "Iteration 89, Losses: {'ner': 1.5699722406035164}\n",
      "Iteration 89, Losses: {'ner': 5.340014848039328}\n",
      "Iteration 89, Losses: {'ner': 13.282865412434912}\n",
      "Iteration 89, Losses: {'ner': 13.291279916391034}\n",
      "Iteration 89, Losses: {'ner': 15.079596205837364}\n",
      "Iteration 89, Losses: {'ner': 17.18456249646111}\n",
      "Iteration 89, Losses: {'ner': 17.19583603868994}\n",
      "Iteration 89, Losses: {'ner': 19.220409473706145}\n",
      "Iteration 89, Losses: {'ner': 20.633391441907836}\n",
      "Iteration 89, Losses: {'ner': 20.633391455775755}\n",
      "Iteration 89, Losses: {'ner': 20.63537236470168}\n",
      "Iteration 89, Losses: {'ner': 21.004999288607085}\n",
      "Iteration 89, Losses: {'ner': 21.005031776931936}\n",
      "Iteration 89, Losses: {'ner': 26.961537083469356}\n",
      "Iteration 89, Losses: {'ner': 27.803730713004715}\n",
      "Iteration 89, Losses: {'ner': 34.50852699935001}\n",
      "Iteration 89, Losses: {'ner': 40.86873981249513}\n",
      "Iteration 89, Losses: {'ner': 40.86956897969871}\n",
      "Iteration 89, Losses: {'ner': 40.86956898143648}\n",
      "Iteration 89, Losses: {'ner': 40.86956924173791}\n",
      "Iteration 89, Losses: {'ner': 42.64087638684517}\n",
      "Iteration 89, Losses: {'ner': 42.65084260845164}\n",
      "Iteration 89, Losses: {'ner': 42.65084265010681}\n",
      "Iteration 89, Losses: {'ner': 42.650848161184285}\n",
      "Iteration 89, Losses: {'ner': 42.65084882209112}\n",
      "Iteration 89, Losses: {'ner': 42.650848863154536}\n",
      "Iteration 90, Losses: {'ner': 0.003085797035262314}\n",
      "Iteration 90, Losses: {'ner': 0.9007562795027557}\n",
      "Iteration 90, Losses: {'ner': 2.272875183707169}\n",
      "Iteration 90, Losses: {'ner': 2.2782319277439376}\n",
      "Iteration 90, Losses: {'ner': 2.9104623817957838}\n",
      "Iteration 90, Losses: {'ner': 2.910462383418681}\n",
      "Iteration 90, Losses: {'ner': 2.9119651807684805}\n",
      "Iteration 90, Losses: {'ner': 2.911968059302704}\n",
      "Iteration 90, Losses: {'ner': 3.954681809794082}\n",
      "Iteration 90, Losses: {'ner': 8.642389037573201}\n",
      "Iteration 90, Losses: {'ner': 8.642389114363178}\n",
      "Iteration 90, Losses: {'ner': 18.659585612163767}\n",
      "Iteration 90, Losses: {'ner': 18.65959823857262}\n",
      "Iteration 90, Losses: {'ner': 18.65959823894762}\n",
      "Iteration 90, Losses: {'ner': 18.659598880759557}\n",
      "Iteration 90, Losses: {'ner': 18.65959893113947}\n",
      "Iteration 90, Losses: {'ner': 22.679567863220413}\n",
      "Iteration 90, Losses: {'ner': 24.69037786161295}\n",
      "Iteration 90, Losses: {'ner': 27.05297330958387}\n",
      "Iteration 90, Losses: {'ner': 27.075239527031478}\n",
      "Iteration 90, Losses: {'ner': 27.07661949246333}\n",
      "Iteration 90, Losses: {'ner': 28.510935626712225}\n",
      "Iteration 90, Losses: {'ner': 33.593173636690835}\n",
      "Iteration 90, Losses: {'ner': 35.291732538928265}\n",
      "Iteration 90, Losses: {'ner': 37.26928695764045}\n",
      "Iteration 90, Losses: {'ner': 37.26928704490431}\n",
      "Iteration 90, Losses: {'ner': 37.2692878420059}\n",
      "Iteration 90, Losses: {'ner': 37.39927710329912}\n",
      "Iteration 90, Losses: {'ner': 41.53631743949926}\n",
      "Iteration 90, Losses: {'ner': 46.51642588401351}\n",
      "Iteration 90, Losses: {'ner': 46.516426101644726}\n",
      "Iteration 91, Losses: {'ner': 7.642556820990024}\n",
      "Iteration 91, Losses: {'ner': 7.642558393078398}\n",
      "Iteration 91, Losses: {'ner': 7.752131894875999}\n",
      "Iteration 91, Losses: {'ner': 7.75216382527026}\n",
      "Iteration 91, Losses: {'ner': 8.935813423400617}\n",
      "Iteration 91, Losses: {'ner': 20.370238348223307}\n",
      "Iteration 91, Losses: {'ner': 31.72312901287405}\n",
      "Iteration 91, Losses: {'ner': 34.79679874401788}\n",
      "Iteration 91, Losses: {'ner': 41.78851800584226}\n",
      "Iteration 91, Losses: {'ner': 41.78851952354441}\n",
      "Iteration 91, Losses: {'ner': 41.78915899750771}\n",
      "Iteration 91, Losses: {'ner': 42.61915430447476}\n",
      "Iteration 91, Losses: {'ner': 42.619154346043636}\n",
      "Iteration 91, Losses: {'ner': 45.70335873845056}\n",
      "Iteration 91, Losses: {'ner': 45.70399765062121}\n",
      "Iteration 91, Losses: {'ner': 47.637570055543264}\n",
      "Iteration 91, Losses: {'ner': 47.63757209388069}\n",
      "Iteration 91, Losses: {'ner': 50.708566212895}\n",
      "Iteration 91, Losses: {'ner': 50.714051022115946}\n",
      "Iteration 91, Losses: {'ner': 51.00873318538555}\n",
      "Iteration 91, Losses: {'ner': 51.05827232037971}\n",
      "Iteration 91, Losses: {'ner': 51.05840440074867}\n",
      "Iteration 91, Losses: {'ner': 51.065013413328195}\n",
      "Iteration 91, Losses: {'ner': 53.05074531527393}\n",
      "Iteration 91, Losses: {'ner': 57.967339587037216}\n",
      "Iteration 91, Losses: {'ner': 57.96897971946536}\n",
      "Iteration 91, Losses: {'ner': 57.9757885767433}\n",
      "Iteration 91, Losses: {'ner': 57.979992254191586}\n",
      "Iteration 91, Losses: {'ner': 58.16453571132662}\n",
      "Iteration 91, Losses: {'ner': 58.16929544651741}\n",
      "Iteration 91, Losses: {'ner': 58.18652895373744}\n",
      "Iteration 92, Losses: {'ner': 2.3876130970297577e-09}\n",
      "Iteration 92, Losses: {'ner': 2.216445847560636}\n",
      "Iteration 92, Losses: {'ner': 2.2412381284023195}\n",
      "Iteration 92, Losses: {'ner': 2.2432111759679643}\n",
      "Iteration 92, Losses: {'ner': 7.675109589276828}\n",
      "Iteration 92, Losses: {'ner': 14.211086537622203}\n",
      "Iteration 92, Losses: {'ner': 14.21282321064028}\n",
      "Iteration 92, Losses: {'ner': 19.707544875995627}\n",
      "Iteration 92, Losses: {'ner': 19.926308300189778}\n",
      "Iteration 92, Losses: {'ner': 20.64775384951282}\n",
      "Iteration 92, Losses: {'ner': 23.294875077533113}\n",
      "Iteration 92, Losses: {'ner': 26.12564569585221}\n",
      "Iteration 92, Losses: {'ner': 29.192047485063377}\n",
      "Iteration 92, Losses: {'ner': 29.19223511877813}\n",
      "Iteration 92, Losses: {'ner': 29.253537226656817}\n",
      "Iteration 92, Losses: {'ner': 29.25354186327066}\n",
      "Iteration 92, Losses: {'ner': 29.253545608624076}\n",
      "Iteration 92, Losses: {'ner': 29.25354560869418}\n",
      "Iteration 92, Losses: {'ner': 29.253545717539073}\n",
      "Iteration 92, Losses: {'ner': 29.253636878791}\n",
      "Iteration 92, Losses: {'ner': 30.209428265542225}\n",
      "Iteration 92, Losses: {'ner': 30.20943095090496}\n",
      "Iteration 92, Losses: {'ner': 30.20943095143192}\n",
      "Iteration 92, Losses: {'ner': 30.209431103088008}\n",
      "Iteration 92, Losses: {'ner': 50.13040199661562}\n",
      "Iteration 92, Losses: {'ner': 50.13072023422807}\n",
      "Iteration 92, Losses: {'ner': 56.840359604005116}\n",
      "Iteration 92, Losses: {'ner': 56.84052261213917}\n",
      "Iteration 92, Losses: {'ner': 58.802341930254215}\n",
      "Iteration 92, Losses: {'ner': 58.806714453109315}\n",
      "Iteration 92, Losses: {'ner': 58.806759140770694}\n",
      "Iteration 93, Losses: {'ner': 1.517494536155081e-09}\n",
      "Iteration 93, Losses: {'ner': 1.0067974784795383e-07}\n",
      "Iteration 93, Losses: {'ner': 1.6773980818617902}\n",
      "Iteration 93, Losses: {'ner': 3.67182102109212}\n",
      "Iteration 93, Losses: {'ner': 3.740403184977618}\n",
      "Iteration 93, Losses: {'ner': 6.993055990536247}\n",
      "Iteration 93, Losses: {'ner': 6.995162008320583}\n",
      "Iteration 93, Losses: {'ner': 6.9951620097873}\n",
      "Iteration 93, Losses: {'ner': 12.772889660062269}\n",
      "Iteration 93, Losses: {'ner': 12.77301855350115}\n",
      "Iteration 93, Losses: {'ner': 14.349717324871033}\n",
      "Iteration 93, Losses: {'ner': 14.34971732507248}\n",
      "Iteration 93, Losses: {'ner': 14.369354260297076}\n",
      "Iteration 93, Losses: {'ner': 14.369886702456446}\n",
      "Iteration 93, Losses: {'ner': 14.369888434300469}\n",
      "Iteration 93, Losses: {'ner': 15.44026556092168}\n",
      "Iteration 93, Losses: {'ner': 15.440265571948508}\n",
      "Iteration 93, Losses: {'ner': 15.440265664569594}\n",
      "Iteration 93, Losses: {'ner': 16.076131576290248}\n",
      "Iteration 93, Losses: {'ner': 20.37081962981841}\n",
      "Iteration 93, Losses: {'ner': 20.37081967133564}\n",
      "Iteration 93, Losses: {'ner': 24.399505773786238}\n",
      "Iteration 93, Losses: {'ner': 26.858496548275024}\n",
      "Iteration 93, Losses: {'ner': 33.168920505841015}\n",
      "Iteration 93, Losses: {'ner': 36.58833578979467}\n",
      "Iteration 93, Losses: {'ner': 36.58833998139423}\n",
      "Iteration 93, Losses: {'ner': 36.72493740554619}\n",
      "Iteration 93, Losses: {'ner': 36.724937412669924}\n",
      "Iteration 93, Losses: {'ner': 38.27651730414276}\n",
      "Iteration 93, Losses: {'ner': 38.276517599830385}\n",
      "Iteration 93, Losses: {'ner': 39.131137581297125}\n",
      "Iteration 94, Losses: {'ner': 8.54858387769535}\n",
      "Iteration 94, Losses: {'ner': 8.548584028926637}\n",
      "Iteration 94, Losses: {'ner': 8.80142607662912}\n",
      "Iteration 94, Losses: {'ner': 15.087775402281535}\n",
      "Iteration 94, Losses: {'ner': 17.06660931015477}\n",
      "Iteration 94, Losses: {'ner': 17.066609514226077}\n",
      "Iteration 94, Losses: {'ner': 19.64028020179476}\n",
      "Iteration 94, Losses: {'ner': 19.643355523960405}\n",
      "Iteration 94, Losses: {'ner': 21.118376767354462}\n",
      "Iteration 94, Losses: {'ner': 21.118656141581166}\n",
      "Iteration 94, Losses: {'ner': 21.14257122831073}\n",
      "Iteration 94, Losses: {'ner': 22.280390813031943}\n",
      "Iteration 94, Losses: {'ner': 27.491597215123022}\n",
      "Iteration 94, Losses: {'ner': 38.72396187837105}\n",
      "Iteration 94, Losses: {'ner': 40.240278726329485}\n",
      "Iteration 94, Losses: {'ner': 41.27534529771721}\n",
      "Iteration 94, Losses: {'ner': 41.27534529772696}\n",
      "Iteration 94, Losses: {'ner': 47.22893314404071}\n",
      "Iteration 94, Losses: {'ner': 47.51359966297728}\n",
      "Iteration 94, Losses: {'ner': 47.599691605249454}\n",
      "Iteration 94, Losses: {'ner': 47.59970711568734}\n",
      "Iteration 94, Losses: {'ner': 48.39600826357068}\n",
      "Iteration 94, Losses: {'ner': 48.41183837601444}\n",
      "Iteration 94, Losses: {'ner': 48.411838666035365}\n",
      "Iteration 94, Losses: {'ner': 48.412867168460686}\n",
      "Iteration 94, Losses: {'ner': 48.42428108071431}\n",
      "Iteration 94, Losses: {'ner': 48.42428272318914}\n",
      "Iteration 94, Losses: {'ner': 51.57223114991615}\n",
      "Iteration 94, Losses: {'ner': 51.57223115179109}\n",
      "Iteration 94, Losses: {'ner': 53.55763892193857}\n",
      "Iteration 94, Losses: {'ner': 53.55763927821009}\n",
      "Iteration 95, Losses: {'ner': 5.909798697224189e-09}\n",
      "Iteration 95, Losses: {'ner': 2.509790429849049e-06}\n",
      "Iteration 95, Losses: {'ner': 1.896700522878227}\n",
      "Iteration 95, Losses: {'ner': 1.9601541207601294}\n",
      "Iteration 95, Losses: {'ner': 5.586858455438693}\n",
      "Iteration 95, Losses: {'ner': 13.5927013926159}\n",
      "Iteration 95, Losses: {'ner': 14.162021303251645}\n",
      "Iteration 95, Losses: {'ner': 14.698338792367217}\n",
      "Iteration 95, Losses: {'ner': 14.698870260232386}\n",
      "Iteration 95, Losses: {'ner': 14.698870273395698}\n",
      "Iteration 95, Losses: {'ner': 14.698870273775182}\n",
      "Iteration 95, Losses: {'ner': 14.698870339584658}\n",
      "Iteration 95, Losses: {'ner': 14.698893669403368}\n",
      "Iteration 95, Losses: {'ner': 22.77596142021558}\n",
      "Iteration 95, Losses: {'ner': 22.77596179260468}\n",
      "Iteration 95, Losses: {'ner': 25.22990368963315}\n",
      "Iteration 95, Losses: {'ner': 30.96661359832248}\n",
      "Iteration 95, Losses: {'ner': 30.966682752290637}\n",
      "Iteration 95, Losses: {'ner': 30.966683161619944}\n",
      "Iteration 95, Losses: {'ner': 32.71861778480302}\n",
      "Iteration 95, Losses: {'ner': 35.77838722477322}\n",
      "Iteration 95, Losses: {'ner': 35.82971376852073}\n",
      "Iteration 95, Losses: {'ner': 37.879899362727095}\n",
      "Iteration 95, Losses: {'ner': 37.882871691847164}\n",
      "Iteration 95, Losses: {'ner': 37.88288498105121}\n",
      "Iteration 95, Losses: {'ner': 37.88288500117301}\n",
      "Iteration 95, Losses: {'ner': 37.88376274631396}\n",
      "Iteration 95, Losses: {'ner': 37.93396838612546}\n",
      "Iteration 95, Losses: {'ner': 39.86628494634026}\n",
      "Iteration 95, Losses: {'ner': 40.897308864098186}\n",
      "Iteration 95, Losses: {'ner': 41.60474413272324}\n",
      "Iteration 96, Losses: {'ner': 1.1300935779739434}\n",
      "Iteration 96, Losses: {'ner': 1.1359941379839626}\n",
      "Iteration 96, Losses: {'ner': 1.1359945807064349}\n",
      "Iteration 96, Losses: {'ner': 1.9569653126718456}\n",
      "Iteration 96, Losses: {'ner': 1.9571806534498148}\n",
      "Iteration 96, Losses: {'ner': 3.4858005775831034}\n",
      "Iteration 96, Losses: {'ner': 3.486173225964175}\n",
      "Iteration 96, Losses: {'ner': 14.540849800251472}\n",
      "Iteration 96, Losses: {'ner': 15.672852975474656}\n",
      "Iteration 96, Losses: {'ner': 15.677982605148497}\n",
      "Iteration 96, Losses: {'ner': 15.677982605321612}\n",
      "Iteration 96, Losses: {'ner': 20.68186171907517}\n",
      "Iteration 96, Losses: {'ner': 20.68870087619538}\n",
      "Iteration 96, Losses: {'ner': 20.688709802790303}\n",
      "Iteration 96, Losses: {'ner': 21.46024080065521}\n",
      "Iteration 96, Losses: {'ner': 21.460241889828193}\n",
      "Iteration 96, Losses: {'ner': 21.972594437111976}\n",
      "Iteration 96, Losses: {'ner': 21.973976054965423}\n",
      "Iteration 96, Losses: {'ner': 24.35978600376218}\n",
      "Iteration 96, Losses: {'ner': 24.359786692852296}\n",
      "Iteration 96, Losses: {'ner': 27.412546094826364}\n",
      "Iteration 96, Losses: {'ner': 27.4125460958457}\n",
      "Iteration 96, Losses: {'ner': 32.74516325807182}\n",
      "Iteration 96, Losses: {'ner': 35.405945403660354}\n",
      "Iteration 96, Losses: {'ner': 40.04962231616702}\n",
      "Iteration 96, Losses: {'ner': 40.04962232383488}\n",
      "Iteration 96, Losses: {'ner': 46.90069721355174}\n",
      "Iteration 96, Losses: {'ner': 46.90069731389709}\n",
      "Iteration 96, Losses: {'ner': 47.16786824127285}\n",
      "Iteration 96, Losses: {'ner': 49.15928247050419}\n",
      "Iteration 96, Losses: {'ner': 49.16010082114096}\n",
      "Iteration 97, Losses: {'ner': 0.16955123258407012}\n",
      "Iteration 97, Losses: {'ner': 0.1695514504613243}\n",
      "Iteration 97, Losses: {'ner': 0.18421106815434787}\n",
      "Iteration 97, Losses: {'ner': 0.18500180632224592}\n",
      "Iteration 97, Losses: {'ner': 0.1865592076770802}\n",
      "Iteration 97, Losses: {'ner': 0.1866849569725396}\n",
      "Iteration 97, Losses: {'ner': 0.18668499113205034}\n",
      "Iteration 97, Losses: {'ner': 3.066262721477176}\n",
      "Iteration 97, Losses: {'ner': 3.066282361332483}\n",
      "Iteration 97, Losses: {'ner': 3.06633728005311}\n",
      "Iteration 97, Losses: {'ner': 3.0663372839779997}\n",
      "Iteration 97, Losses: {'ner': 3.0663373708050448}\n",
      "Iteration 97, Losses: {'ner': 3.0706196200545124}\n",
      "Iteration 97, Losses: {'ner': 3.4504628172042557}\n",
      "Iteration 97, Losses: {'ner': 11.348790530652503}\n",
      "Iteration 97, Losses: {'ner': 11.348791207810685}\n",
      "Iteration 97, Losses: {'ner': 11.3547917769554}\n",
      "Iteration 97, Losses: {'ner': 11.354792088217826}\n",
      "Iteration 97, Losses: {'ner': 11.472478890429555}\n",
      "Iteration 97, Losses: {'ner': 15.416057301121766}\n",
      "Iteration 97, Losses: {'ner': 22.236749385840174}\n",
      "Iteration 97, Losses: {'ner': 22.23798086919549}\n",
      "Iteration 97, Losses: {'ner': 23.760279090917475}\n",
      "Iteration 97, Losses: {'ner': 24.355358367021793}\n",
      "Iteration 97, Losses: {'ner': 24.355358672516154}\n",
      "Iteration 97, Losses: {'ner': 26.704283594470372}\n",
      "Iteration 97, Losses: {'ner': 26.94206204818705}\n",
      "Iteration 97, Losses: {'ner': 36.74233044501473}\n",
      "Iteration 97, Losses: {'ner': 43.270447557776336}\n",
      "Iteration 97, Losses: {'ner': 44.39778229446809}\n",
      "Iteration 97, Losses: {'ner': 45.98028375723688}\n",
      "Iteration 98, Losses: {'ner': 2.2292513405038817e-09}\n",
      "Iteration 98, Losses: {'ner': 5.242368024378746e-06}\n",
      "Iteration 98, Losses: {'ner': 4.068933795302374}\n",
      "Iteration 98, Losses: {'ner': 10.712063380137796}\n",
      "Iteration 98, Losses: {'ner': 10.712063990440024}\n",
      "Iteration 98, Losses: {'ner': 10.718082962208468}\n",
      "Iteration 98, Losses: {'ner': 10.718083033602031}\n",
      "Iteration 98, Losses: {'ner': 10.871082009266324}\n",
      "Iteration 98, Losses: {'ner': 11.13830421049662}\n",
      "Iteration 98, Losses: {'ner': 11.388739464765134}\n",
      "Iteration 98, Losses: {'ner': 18.291061520859685}\n",
      "Iteration 98, Losses: {'ner': 18.29106153374965}\n",
      "Iteration 98, Losses: {'ner': 18.291061544530514}\n",
      "Iteration 98, Losses: {'ner': 20.418710974035584}\n",
      "Iteration 98, Losses: {'ner': 20.418711007280045}\n",
      "Iteration 98, Losses: {'ner': 20.418788929001277}\n",
      "Iteration 98, Losses: {'ner': 20.41881818990131}\n",
      "Iteration 98, Losses: {'ner': 20.48899337903792}\n",
      "Iteration 98, Losses: {'ner': 24.686731016983295}\n",
      "Iteration 98, Losses: {'ner': 24.686735109661036}\n",
      "Iteration 98, Losses: {'ner': 24.68858014921323}\n",
      "Iteration 98, Losses: {'ner': 24.68858724251293}\n",
      "Iteration 98, Losses: {'ner': 24.688587559538345}\n",
      "Iteration 98, Losses: {'ner': 27.147908459802615}\n",
      "Iteration 98, Losses: {'ner': 27.765340823572213}\n",
      "Iteration 98, Losses: {'ner': 27.820412594996814}\n",
      "Iteration 98, Losses: {'ner': 27.84810604882631}\n",
      "Iteration 98, Losses: {'ner': 29.199996137376285}\n",
      "Iteration 98, Losses: {'ner': 29.199996375805295}\n",
      "Iteration 98, Losses: {'ner': 29.200000421527395}\n",
      "Iteration 98, Losses: {'ner': 31.204437947128792}\n",
      "Iteration 99, Losses: {'ner': 0.00024266180259950175}\n",
      "Iteration 99, Losses: {'ner': 0.531613919800404}\n",
      "Iteration 99, Losses: {'ner': 0.6934621223800476}\n",
      "Iteration 99, Losses: {'ner': 0.6934621228998642}\n",
      "Iteration 99, Losses: {'ner': 0.6934839326834736}\n",
      "Iteration 99, Losses: {'ner': 0.6962678517327976}\n",
      "Iteration 99, Losses: {'ner': 0.6962930532114633}\n",
      "Iteration 99, Losses: {'ner': 0.6962970138787657}\n",
      "Iteration 99, Losses: {'ner': 4.054350073997849}\n",
      "Iteration 99, Losses: {'ner': 4.054351421309718}\n",
      "Iteration 99, Losses: {'ner': 4.466647042210424}\n",
      "Iteration 99, Losses: {'ner': 8.252892996062974}\n",
      "Iteration 99, Losses: {'ner': 14.33636921355056}\n",
      "Iteration 99, Losses: {'ner': 20.708244980268006}\n",
      "Iteration 99, Losses: {'ner': 20.708245028884303}\n",
      "Iteration 99, Losses: {'ner': 20.876020277196176}\n",
      "Iteration 99, Losses: {'ner': 20.87663289867796}\n",
      "Iteration 99, Losses: {'ner': 20.876655532238406}\n",
      "Iteration 99, Losses: {'ner': 30.432498000690682}\n",
      "Iteration 99, Losses: {'ner': 30.665874799641575}\n",
      "Iteration 99, Losses: {'ner': 30.665874943446486}\n",
      "Iteration 99, Losses: {'ner': 37.86048279210507}\n",
      "Iteration 99, Losses: {'ner': 37.86060572656662}\n",
      "Iteration 99, Losses: {'ner': 42.927419826949425}\n",
      "Iteration 99, Losses: {'ner': 45.14954691032458}\n",
      "Iteration 99, Losses: {'ner': 46.56838759458291}\n",
      "Iteration 99, Losses: {'ner': 55.773045611411604}\n",
      "Iteration 99, Losses: {'ner': 56.78282466165828}\n",
      "Iteration 99, Losses: {'ner': 58.8075831943577}\n",
      "Iteration 99, Losses: {'ner': 58.838170754243166}\n",
      "Iteration 99, Losses: {'ner': 58.83817078153028}\n"
     ]
    }
   ],
   "source": [
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    try:\n",
    "        optimizer = nlp.begin_training()\n",
    "        logging.info(\"Training started.\")\n",
    "        for itn in range(100):\n",
    "            random.shuffle(train_data)\n",
    "            losses = {}\n",
    "            for text, annotations in train_data:\n",
    "                example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "                nlp.update([example], losses=losses, drop=0.5, sgd=optimizer)\n",
    "                print(f\"Iteration {itn}, Losses: {losses}\")\n",
    "            logging.info(f\"Iteration {itn}, Losses: {losses}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during training: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"C:/Users/syadav18/Desktop/Ml tasks/Task 5\"\n",
    "try:\n",
    "    nlp.to_disk(output_dir)\n",
    "    logging.info(f\"Model saved to {output_dir}.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving model to disk: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"ner_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(nlp, f)\n",
    "    logging.info(\"Model serialized using pickle.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error serializing model with pickle: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nlp = spacy.load(output_dir)\n",
    "    logging.info(\"Model loaded successfully for testing.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities in 'While bismuth compounds (Pepto-Bismol) decreased the number of bowel movements in those with travelers' diarrhea, they do not decrease the length of illness.[91] Anti-motility agents like loperamide are also effective at reducing the number of stools but not the duration of disease.[8] These agents should be used only if bloody diarrhea is not present.[92]\n",
      "\n",
      "Diosmectite, a natural aluminomagnesium silicate clay, is effective in alleviating symptoms of acute diarrhea in children,[93] and also has some effects in chronic functional diarrhea, radiation-induced diarrhea, and chemotherapy-induced diarrhea.[45] Another absorbent agent used for the treatment of mild diarrhea is kaopectate.\n",
      "\n",
      "Racecadotril an antisecretory medication may be used to treat diarrhea in children and adults.[86] It has better tolerability than loperamide, as it causes less constipation and flatulence.'\n",
      "bismuth compounds 6 23 MEDICINE\n",
      "Pepto-Bismol 25 37 MEDICINE\n",
      "diarrhea 104 112 MEDICALCONDITION\n",
      "loperamide 188 198 MEDICINE\n",
      "Diosmectite 360 371 MEDICINE\n",
      "aluminomagnesium silicate 383 408 MEDICINE\n",
      "diarrhea 461 469 MEDICALCONDITION\n",
      "diarrhea 535 543 MEDICALCONDITION\n",
      "diarrhea 563 571 MEDICALCONDITION\n",
      "chemotherapy 577 589 MEDICINE\n",
      "kaopectate 679 689 MEDICINE\n",
      "Racecadotril 692 704 MEDICINE\n",
      "diarrhea 754 762 MEDICALCONDITION\n",
      "loperamide 823 833 MEDICINE\n",
      "constipation 853 865 MEDICALCONDITION\n"
     ]
    }
   ],
   "source": [
    "test_text = \"While bismuth compounds (Pepto-Bismol) decreased the number of bowel movements in those with travelers' diarrhea, they do not decrease the length of illness.[91] Anti-motility agents like loperamide are also effective at reducing the number of stools but not the duration of disease.[8] These agents should be used only if bloody diarrhea is not present.[92]\\n\\nDiosmectite, a natural aluminomagnesium silicate clay, is effective in alleviating symptoms of acute diarrhea in children,[93] and also has some effects in chronic functional diarrhea, radiation-induced diarrhea, and chemotherapy-induced diarrhea.[45] Another absorbent agent used for the treatment of mild diarrhea is kaopectate.\\n\\nRacecadotril an antisecretory medication may be used to treat diarrhea in children and adults.[86] It has better tolerability than loperamide, as it causes less constipation and flatulence.\"\n",
    "try:\n",
    "    doc = nlp(test_text)\n",
    "    logging.info(\"Test text processed successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error processing test text: {e}\")\n",
    "    raise\n",
    "\n",
    "logging.info(\"Extracting entities from test text.\")\n",
    "print(\"Entities in '%s'\" % test_text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nlp = spacy.load(output_dir)\n",
    "    logging.info(\"SpaCy model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading SpaCy model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training.example import Example\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "# nlp = spacy.load(output_dir)\n",
    "\n",
    "test_data = [\n",
    "    {\n",
    "        \"text\": \"\"\"Although viruses cause disruption of healthy homeostasis, resulting in disease, they may exist relatively harmlessly within an organism. An example would include the ability of the herpes simplex virus, which causes cold sores, to remain in a dormant state within the human body. \n",
    "        This is called latency[153] and is a characteristic of the herpes viruses, including Epstein–Barr virus, which causes glandular fever, and varicella zoster virus, which causes chickenpox and shingles. Most people have been infected with at least one of these types of herpes virus.\n",
    "        [154] These latent viruses might sometimes be beneficial, as the presence of the virus can increase immunity against bacterial pathogens, such as Yersinia pestis.[155]\"\"\",\n",
    "        \"entities\": [\n",
    "                     (471, 479, 'MEDICALCONDITION'),\n",
    "                     (419, 441, 'PATHOGEN'),\n",
    "                     (365, 383, 'PATHOGEN'),\n",
    "                     (707, 722, 'PATHOGEN'),\n",
    "                     (181, 201, 'PATHOGEN'),\n",
    "                     (456, 467, 'MEDICALCONDITION')]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"\"\"Examples of common human diseases caused by viruses include the common cold, influenza, chickenpox, and cold sores. Many serious diseases such as rabies, Ebola virus disease, AIDS (HIV), avian influenza, and SARS are caused by viruses. \n",
    "        The relative ability of viruses to cause disease is described in terms of virulence. Other diseases are under investigation to discover if they have a virus as the causative agent, such as the possible connection between human herpesvirus 6 (HHV6) and neurological diseases such as multiple sclerosis and chronic fatigue syndrome.\n",
    "        [151] There is controversy over whether the bornavirus, previously thought to cause neurological diseases in horses, could be responsible for psychiatric illnesses in humans.[152]\"\"\",\n",
    "        \"entities\": [(518, 536, 'MEDICALCONDITION'),\n",
    "                     (154, 165, 'PATHOGEN'),\n",
    "                     (708, 729, 'MEDICALCONDITION'),\n",
    "                     (463, 476, 'PATHOGEN'),\n",
    "                     (77, 86, 'MEDICALCONDITION'),\n",
    "                     (88, 98, 'MEDICALCONDITION'),\n",
    "                     (187, 202, 'MEDICALCONDITION'),\n",
    "                     (610, 620, 'PATHOGEN')]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"\"\"All medical applications known so far involve not pure adamantane, but its derivatives. The first adamantane derivative used as a drug was amantadine – first (1967) as an antiviral drug against various strains of flu[50] and then to treat Parkinson's disease.\n",
    "        [51][52] Other drugs among adamantane derivatives include adapalene, adapromine, bromantane, carmantadine, chlodantane, dopamantine, memantine, rimantadine, saxagliptin, tromantadine, and vildagliptin. Polymers of adamantane have been patented as antiviral agents against HIV.[53]\"\"\",\n",
    "        \"entities\": [(239, 258, 'MEDICALCONDITION'),\n",
    "                     (55, 65, 'MEDICINE'),\n",
    "                     (531, 534, 'PATHOGEN'),\n",
    "                     (416, 427, 'MEDICINE'),\n",
    "                     (379, 390, 'MEDICINE'),\n",
    "                     (352, 364, 'MEDICINE'),\n",
    "                     (139, 149, 'MEDICINE')]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"\"\"Buprenorphine has been shown experimentally (1982–1995) to be effective against severe, refractory depression\"\"\",\n",
    "        \"entities\": [(88, 109, 'MEDICALCONDITION'),\n",
    "                     (0, 14, 'MEDICALCONDITION')]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"\"\"Gabapentin, approved for treatment of seizures and postherpetic neuralgia in adults, has side-effects which are useful in treating bipolar disorder1, \n",
    "        essential tremor, hot flashes, migraine prophylaxis, neuropathic pain syndromes, phantom limb syndrome, and restless leg syndrome.[11]\"\"\",\n",
    "        \"entities\": [(203, 229, 'MEDICALCONDITION'),\n",
    "                     (258, 279, 'MEDICALCONDITION'),\n",
    "                     (181, 201, 'MEDICALCONDITION'),\n",
    "                     (51, 73, 'MEDICALCONDITION'),\n",
    "                     (0, 10, 'MEDICINE'),\n",
    "                     (38, 46, 'MEDICALCONDITION')]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"\"\"Bupropion (Wellbutrin), an anti-depressant, is also used as a smoking cessation aid; this indication was later approved, and the name of the smoking cessation product is Zyban. \n",
    "        In Ontario, Canada, smoking cessation drugs are not covered by provincial drug plans; elsewhere, Zyban is priced higher than Wellbutrin, despite being the same drug. Therefore, some physicians prescribe Wellbutrin for both indications.[\"\"\",\n",
    "        \"entities\": [(274, 279, 'MEDICINE'),\n",
    "                     (11, 21, 'MEDICINE'),\n",
    "                     (302, 312, 'MEDICINE'),\n",
    "                     (380, 390, 'MEDICINE'),\n",
    "                     (170, 175, 'MEDICINE'),\n",
    "                     (0, 9, 'MEDICINE')]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"\"\"Carbamazepine is an approved treatment for bipolar disorder and epileptic seizures, but it has side effects useful in treating attention-deficit hyperactivity disorder (ADHD), \n",
    "        schizophrenia, phantom limb syndrome, paroxysmal extreme pain disorder, neuromyotonia, and post-traumatic stress disorder.[8]\"\"\",\n",
    "        \"entities\": [(267, 288, 'MEDICALCONDITION'),\n",
    "                     (248, 261, 'MEDICALCONDITION'),\n",
    "                     (43, 59, 'MEDICALCONDITION'),\n",
    "                     (145, 167, 'MEDICALCONDITION'),\n",
    "                     (0, 14, 'MEDICALCONDITION'),\n",
    "                     (176, 189, 'MEDICALCONDITION'),\n",
    "                     (64, 82, 'MEDICALCONDITION'),\n",
    "                     (191, 212, 'MEDICALCONDITION')]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"\"\"The antiviral drugs amantadine and rimantadine inhibit a viral ion channel (M2 protein), thus inhibiting replication of the influenza A virus.\n",
    "        [86] These drugs are sometimes effective against influenza A if given early in the infection but are ineffective against influenza B viruses, which lack the M2 drug target.[160] Measured resistance to amantadine and rimantadine in American isolates of H3N2 has increased to 91% in 2005.[161] This high level of resistance may be due to the easy availability of amantadines as part of over-the-counter cold remedies in countries such as China and Russia,[162] and their use to prevent outbreaks of influenza in farmed poultry.\n",
    "        [163][164] The CDC recommended against using M2 inhibitors during the 2005–06 influenza season due to high levels of drug resistance.[165]\"\"\",\n",
    "        \"entities\": [(639, 648, 'MEDICALCONDITION'),\n",
    "                     (35, 46, 'MEDICINE'),\n",
    "                     (712, 725, 'MEDICINE'),\n",
    "                     (20, 30, 'MEDICINE')]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"\"\"The two classes of antiviral drugs used against influenza are neuraminidase inhibitors (oseltamivir, zanamivir, laninamivir and peramivir) and M2 protein inhibitors (adamantane derivatives)\"\"\",\n",
    "        \"entities\": [(128, 137, 'MEDICINE'),\n",
    "                     (101, 110, 'MEDICINE'),\n",
    "                     (112, 124, 'MEDICALCONDITION'),\n",
    "                     (48, 57, 'MEDICALCONDITION'),\n",
    "                     (88, 99, 'MEDICINE')]\n",
    "    },\n",
    "     {\n",
    "        \"text\": \"\"\"Influenza, commonly known as \"the flu\", is an infectious disease caused by an influenza virus.[1] Symptoms can be mild to severe.\n",
    "        [5] The most common symptoms include: high fever, runny nose, sore throat, muscle and joint pain, headache, coughing, and feeling tired.\n",
    "        [1] These symptoms typically begin two days after exposure to the virus and most last less than a week.[1] The cough, however, may last for more than two weeks.\n",
    "        [1] In children, there may be diarrhea and vomiting, but these are not common in adults.[6] Diarrhea and vomiting occur more commonly in gastroenteritis, which is an unrelated disease and sometimes inaccurately referred to as \"stomach flu\" or the \"24-hour flu\".\n",
    "        [6] Complications of influenza may include viral pneumonia, secondary bacterial pneumonia, sinus infections, and worsening of previous health problems such as asthma or heart failure.[2][5]\"\"\",\n",
    "        \"entities\": [(191, 202, 'MEDICALCONDITION'),\n",
    "                     (0, 9, 'MEDICALCONDITION'),\n",
    "                     (845, 852, 'MEDICALCONDITION'),\n",
    "                     (756, 775, 'PATHOGEN'),\n",
    "                     (468, 476, 'MEDICALCONDITION'),\n",
    "                     (227, 235, 'MEDICALCONDITION'),\n",
    "                     (237, 245, 'MEDICALCONDITION'),\n",
    "                     (777, 793, 'MEDICALCONDITION'),\n",
    "                     (855, 868, 'MEDICALCONDITION'),\n",
    "                     (215, 225, 'MEDICALCONDITION'),\n",
    "                     (652, 663, 'MEDICALCONDITION'),\n",
    "                     (455, 464, 'MEDICALCONDITION'),\n",
    "                     (251, 264, 'MEDICALCONDITION'),\n",
    "                     (78, 93, 'PATHOGEN')]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Although viruses cause disruption of healthy homeo...\" with entities \"[(471, 479, 'MEDICALCONDITION'), (419, 441, 'PATHO...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Examples of common human diseases caused by viruse...\" with entities \"[(518, 536, 'MEDICALCONDITION'), (154, 165, 'PATHO...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"All medical applications known so far involve not ...\" with entities \"[(239, 258, 'MEDICALCONDITION'), (55, 65, 'MEDICIN...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Buprenorphine has been shown experimentally (1982–...\" with entities \"[(88, 109, 'MEDICALCONDITION'), (0, 14, 'MEDICALCO...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Gabapentin, approved for treatment of seizures and...\" with entities \"[(203, 229, 'MEDICALCONDITION'), (258, 279, 'MEDIC...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Bupropion (Wellbutrin), an anti-depressant, is als...\" with entities \"[(274, 279, 'MEDICINE'), (11, 21, 'MEDICINE'), (30...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Carbamazepine is an approved treatment for bipolar...\" with entities \"[(267, 288, 'MEDICALCONDITION'), (248, 261, 'MEDIC...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The antiviral drugs amantadine and rimantadine inh...\" with entities \"[(639, 648, 'MEDICALCONDITION'), (35, 46, 'MEDICIN...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The two classes of antiviral drugs used against in...\" with entities \"[(128, 137, 'MEDICINE'), (101, 110, 'MEDICINE'), (...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syadav18\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Influenza, commonly known as \"the flu\", is an infe...\" with entities \"[(191, 202, 'MEDICALCONDITION'), (0, 9, 'MEDICALCO...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "try:\n",
    "    for item in test_data:\n",
    "        text = item[\"text\"]\n",
    "        annotations = {\"entities\": item[\"entities\"]}\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        examples.append(example)\n",
    "    logging.info(\"Converted test data to spaCy examples successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error converting test data to spaCy examples: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.scorer import Scorer\n",
    "scorer = Scorer()\n",
    "try:\n",
    "    scores = scorer.score(examples)\n",
    "    logging.info(\"Scoring completed successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during scoring: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
